#!/usr/bin/python -u
#
# Driver script for building rpms from a configuration specified in CMSDIST.
#

from os.path import abspath, join, exists, isdir, basename, dirname
from os import popen, getenv, symlink, listdir, readlink, unlink, getpid
from os import chdir, getcwd, environ, walk, sep, kill
from getpass import getuser
from tempfile import mkdtemp, mkstemp, NamedTemporaryFile
from commands import getstatusoutput
from urllib2 import urlopen, URLError
from time import strftime
import sys
import copy
from ConfigParser import ConfigParser
from ConfigParser import InterpolationMissingOptionError
import re, os
import traceback
from optparse import OptionParser, OptionGroup
import fnmatch
from shutil import rmtree
import urllib2
from glob import glob
import itertools
import pickle
from hashlib import sha256
from sys import platform

logLevel = 10 
NORMAL=10
DEBUG=20
TRACE=30
DEFAULT_CVS_SERVER=":pserver:anonymous@cmscvs.cern.ch:2401/local/reps/CMSSW"
DEFAULT_CVS_PASSWORD="AA_:yZZ3e"
DEFAULT_SPEC_REPOSITORY_MODULE="CMSDIST"
CMSPKG_CMD="cmspkg"
SERVER_TMP_UPLOAD_DIRECTORY=None
rpmEnvironmentScript = "true"
pip_package_env_script = ""

removeInitialSpace = re.compile ("^[ ]*", re.M)
cmsBuildFilename = abspath(__file__)

def fatal(message):
  print "ERROR: " + message
  sys.exit(1)

def die(message):
  fatal(message)

# Minimal string sanitization.
def sanitize(s):
  return re.sub("[^a-zA-Z_0-9*./-]", "", s)

def log (message, level=0):
    """ Asynchronous printouts method. Level should be NORMAL when a message 
is intended to be seen by the user, DEBUG, when it's intended to be seen only 
by the developer, and TRACE when it's a message that is describing state 
of the action scheduler/worker during the build.
    """
    if callable (message):
        message = message ()
    if level <= logLevel:
        message = removeInitialSpace.sub ("", message)
        print message

def setLogLevel (options):
    global logLevel
    if options.trace:
        logLevel = TRACE
    elif options.debug:
        logLevel = DEBUG
    else:
        logLevel = NORMAL

#Check of online arch
def isOnline(arch):
    if 'onl' in arch: return True
    return False

def isDefaultRevision(rev):
    if rev == '1' or rev.startswith('1.'): return True
    return False

# We have our own version rather than using the one from os
# because the latter does not work seem to be thread safe.
def makedirs(path):
  returncode, out = getstatusoutput("mkdir -p %s" % (path,))
  if returncode != 0:
    raise OSError("makedirs() failed (return: %s):\n%s" % (returncode, out)) 

rpm_db_cache = {}
    
def downloadUrllib2(source, destDir, options, cmscache=False):
    try:
      dest = "/".join([destDir.rstrip("/"), basename(source)])
      req = urllib2.Request(source, headers={"Cache-Control": "no-cache"})
      s = urllib2.urlopen(req)
      f = file(dest+".tmp","w")
      # Read in blocks to avoid using too much memory.
      block_sz = 8192*16
      while True:
        buffer = s.read(block_sz)
        if not buffer:
          break
        f.write(buffer)
      f.close()
      os.rename(dest+".tmp",dest)
    except URLError, e:
      if cmscache:
        log("Internal cached file not available %s: %s" % (source, e), DEBUG)
      else:
        log("Error while downloading %s: %s" % (source, e))
      return False
    except Exception, e:
      log("Error while downloading %s: %s" % (source, e))
      return False
    return True

def parseUrl (url, requestedKind=None, defaults={}, required=[]):
    match = re.match("([^+:]*)([^:]*)://([^?]*)(.*)", url)
    if not match:
      raise MalformedUrl (url)
    parts = match.groups()
    protocol, deliveryProtocol, server, arguments = match.groups()
    arguments = arguments.strip("?")
    # In case of urls of the kind:
    # git+https://some.web.git.repository.net
    # we consider "https" the actual protocol and
    # "git" merely the request kind.
    if requestedKind and not protocol == requestedKind:
      raise MalformedUrl(url)
    if deliveryProtocol:
      protocol = deliveryProtocol.strip("+")
    arguments.replace ("&amp;", "&")
    args = defaults.items ()
    parsedArgs = re.split ("&", arguments)
    parsedArgs = [ x.split ("=") for x in parsedArgs ]
    parsedArgs = [(len (x) != 2 and [x[0], True]) or x for x in parsedArgs]
    args.extend (parsedArgs)
    argsDict = dict(args)
    missingArgs = [arg for arg in required if arg not in argsDict]
    if missingArgs:
      raise MalformedUrl (url, missingArgs)
    return protocol, server, argsDict

def parseTcUrl (url):
    scheme, server, args = parseUrl (url, requestedKind="cmstc",
                                     defaults={"cvsroot": DEFAULT_CVS_SERVER,
                                               "passwd": DEFAULT_CVS_PASSWORD},
                                     required=["tag", "output"])
    return scheme, server, args

def parseCvsUrl (url):
    scheme, cvsroot, args = parseUrl (url, requestedKind="cvs",
                                      defaults={"strategy": "export",
                                                "tag": "HEAD",
                                                "passwd": DEFAULT_CVS_PASSWORD},
                                      required=["module", "output"])
    if not cvsroot:
        cvsroot = DEFAULT_CVS_SERVER
    cvsroot = cvsroot.replace (":/", ":2401/")
    args["tag"] = re.sub (re.compile ("^-r"), "", args["tag"])
    if "export" not in args:
        args["export"] = args["module"]
    args["cvsroot"] = cvsroot
    return (scheme, cvsroot, args)

def parseSvnUrl (url):
  scheme, root, args = parseUrl(url, requestedKind="svn",
                                defaults={"strategy": "export",
      			            "revision": "HEAD"},
                                required=["module", "output"])
  if "export" not in args:
    args["export"] = args["module"]
  if "scheme" in args:
    scheme=args["scheme"]
  if not scheme in ["svn", "http", "https", "file"] and (not scheme.startswith('svn+')):
    scheme = "svn+" + scheme
  args["svnroot"] = "%(scheme)s://%(root)s" % {"scheme": scheme, "root": root}
  return (scheme, root, args)

def parseGitUrl(url):
  protocol, gitroot, args = parseUrl(url, requestedKind="git",
                                     defaults={"obj": "master/HEAD"})
  parts = args["obj"].rsplit("/", 1)                                                                                                                                                                                                                                                              
  if len(parts) != 2:
    parts += ["HEAD"]
  args["branch"], args["tag"] = parts

  if not "export" in args:
    args["export"] = basename(re.sub("\.git$", "", re.sub("[?].*", "",gitroot)))
    if args["tag"] != "HEAD":
      args["export"] += args["tag"]
    else:
      args["export"] += args["branch"]

  if not "output" in args:
    args["output"] = args["export"] + ".tar.gz"
    args ["gitroot"] = gitroot
  if not "filter" in args:
    args["filter"] = "*"
  args["filter"] = sanitize(args["filter"]);
  return protocol, gitroot, args

def createTempDir (workDir, subDir):
    tempdir = join (workDir, subDir) 
    if not exists (tempdir):
        makedirs (tempdir)
    tempdir = mkdtemp (dir=tempdir)
    return tempdir

def executeWithErrorCheck (command, errorMessage):
    log (command, DEBUG)
    error, output = getstatusoutput (command)
    if error:
        log (errorMessage + ":")
        log ("")
        log (command)
        log ("")
        log ("resulted in:")
        log (output)
        return False
    log (output, DEBUG)
    return True

def packCheckout (tempdir, dest, *exports):
    """ Use this helper method when download protocol is like cvs/svn/git
        where the code is checked out in a temporary directory and then tarred 
        up.
    """
    export = " ".join(['"%s"' % x for x in exports])
    packCommand ="""cd %(tempdir)s; tar -zcf "%(dest)s" %(export)s """
    packCommand = packCommand % locals ()
    errorMessage = "Error while creating a tar archive for checked out area"
    return executeWithErrorCheck (packCommand, errorMessage)


def downloadSvn (source, dest, options):
    scheme, svnroot, args = parseSvnUrl (source)
    tempdir = createTempDir (options.workDir, options.tempDirPrefix)
    exportDir = join (tempdir, "checkout", args["export"])
    if not exists (exportDir):
        makedirs (exportDir)
    args["dest"] = join (dest, args["output"].lstrip("/"))
    args["tempdir"] = tempdir
    args["exportdir"] = exportDir.rsplit("/", 1)[1]
    args["exportpath"] = exportDir.rsplit("/", 1)[0]
    if not args["revision"].isdigit():
      args["revision"] = '"' + args["revision"] + '"' 
    command = """cd %(exportpath)s ; svn %(strategy)s --force --non-interactive --trust-server-cert -r%(revision)s "%(svnroot)s" "%(exportdir)s" """
    command = command % args
    message = "Error while downloading files from subversion repository"
    ok = executeWithErrorCheck (command, message)
    return ok and packCheckout (args["exportpath"], args["dest"], args["export"])

def downloadCvs (source, dest, options):
    protocol, cvsroot, args = parseCvsUrl (source)
    tempdir = createTempDir (options.workDir, options.tempDirPrefix)
    pserverUrlRe = re.compile (":pserver:.*")
    isPserver = pserverUrlRe.match (cvsroot)
    cvspassFilename = None
    if args.has_key ("passwd") and isPserver:
        cvspassFilename = join (tempdir, "cvspass")
        f=open (join (tempdir, "cvspass"), "w")
        f.write ("/1 %(cvsroot)s %(passwd)s\n" % args)
        f.close ()
    exportDir = join (tempdir, "checkout")
    if not exists (exportDir):
        makedirs (exportDir)
    args["dest"] = join (dest, args["output"].lstrip("/"))
    args["tempdir"] = tempdir
    args["exportdir"] = exportDir
    args["passexport"] = (cvspassFilename and "CVS_PASSFILE=%s" % cvspassFilename) or ""
    command ="""cd %(exportdir)s ; %(passexport)s cvs -z6 -Q -d"%(cvsroot)s" %(strategy)s -d"%(export)s" -r"%(tag)s" "%(module)s" """
    command = command % args
    message = "Error while executing a %(strategy)s from CVS:" % args
    ok = executeWithErrorCheck (command, message)
    return ok and packCheckout (exportDir, args["dest"], args["export"])

def downloadTc (source, dest, options):
  protocol, tagsSource, args = parseTcUrl (source)
  tempdir = createTempDir (options.workDir, options.tempDirPrefix)
  args["tempdir"] = tempdir
  args["dest"] = join(dest, args["output"].lstrip("/"))
  args["pmLocation"] = abspath(join (dirname(cmsBuildFilename), 'cmspm'))
  if "extratags" in args:
    args["extratags"] = "--additional-tags " + args["extratags"]
  else:
    args["extratags"] = ""

  if 'baserel' not in args:
    command="""cd %(tempdir)s && %(pmLocation)s corel %(tag)s """
  else:
    command='. '+options.workDir+"""/cmsset_default.sh && cd %(tempdir)s && %(pmLocation)s frombase %(tag)s %(baserel)s %(baserelver)s """
  command +=""" %(extratags)s -e -o src/PackageList.cmssw"""
  command=command % args
  log("Downloading %(tag)s from cmsTC." % args, DEBUG)
  message = "Error while downloading sources using tag collector information."
  ok = executeWithErrorCheck (command, message)
  dirs = ["src"]
  if exists("/".join([args["tempdir"], "poison"])): dirs.append("poison")
  return ok and packCheckout (args["tempdir"], args["dest"], *dirs)

# Download a files from a git url.  We do not clone the remote reposiotory, but
# we simply pull the branch we are interested in and then we drop all the git
# information while creating a tarball.  The syntax to define a repository is
# the following:
#
# git:/local/repository?obj=BRANCH/TAG
# git://remote-repository?obj=BRANCH/TAG
# git+https://remote-repository-over-http/foo.git?obj=BRANCH/TAG
#
# If "obj" does not contain a "/", it's value will be considered a branch and TAG will be "HEAD".
# If "obj" is not specified, it will be "master/HEAD" by default.
# By default export is the <basename of the url without ".git">-TAG unless it is HEAD,
# in which case it will be  <basename of the url without .git>-BRANCH.
# One can specify an additional parameter
#
#     filter=<some-path>
#
# which will be used to pack only a subset of the checkout.
def downloadGit(source, dest, options):
  protocol, gitroot, args = parseGitUrl(source)
  tempdir = createTempDir(options.workDir, options.tempDirPrefix)

  exportpath = join(tempdir, args["export"])
  if protocol:
    protocol += "://"
  if not protocol and not gitroot.endswith(".git"):
    gitroot = join(gitroot, ".git")

  dest = join(dest, args["output"].lstrip ("/"))
  args.update({"protocol": protocol, "tempdir": tempdir,
               "gitroot": gitroot, "dest": dest,
               "exportpath": exportpath})
  makedirs(exportpath)
  command = format("cd %(exportpath)s &&"
                   "git init &&"
                   "git pull --tags %(protocol)s%(gitroot)s refs/heads/%(branch)s &&"
                   "git reset --hard %(tag)s &&"
                   "find . ! -path '%(filter)s' -delete &&"
                   "rm -rf .git .gitattributes .gitignore", **args)
  error, output = getstatusoutput(command % args)
  if error:
    log("Error while downloading sources from %s using git.\n\n"
        "%s\n\n"
        "resulted in:\n%s" % (gitroot, command % args, output))
    return False
  return packCheckout(args["tempdir"], args["dest"], args["export"])

def downloadPip(source, dest, options):
# Valid PIP URL formats are
# pip://package/version?[pip_options=options&]output=/tarbalname
# pip://package/version/tarbalname
  url_parts = source.split("pip://",1)[1].split("?",1)
  opts = []
  if len(url_parts)>1: opts = url_parts[1].split("&")
  pkg  = url_parts[0].split("/")
  pack=pkg[0].strip()
  if len(pkg)>1: pack=pack+'=='+pkg[1].strip()
  tarball=source.rsplit("/",1)[1]
#newer pip will need this (but untested)
#  comm = 'which pip; pip download --no-deps ' + dest + ' ' + pack
  tempdir = createTempDir (options.workDir, options.tempDirPrefix)
  pip_opts = "--no-deps --no-binary=:all:"

  for opt in opts:
    if opt[:12] == "pip_options=":
      pip_optsT = opt[12:].replace("+"," ").replace("%20"," ").replace("%3D","=")
      #hack here a alternative source location
      pip_opts=''
      spSrc=pip_optsT.split()
      for i in range(len(spSrc)):
        if 'ALTSRC' in spSrc[i]:
          pack=spSrc[i+1]
          i=i+1
        else:
          pip_opts=pip_opts+' '+spSrc[i]
      break
  comm = ""
  if pip_package_env_script: comm = ". %s; " % pip_package_env_script
  comm = comm + ' which pip; pip download ' + pip_opts + ' -d ' + tempdir + ' ' + pack+'; /bin/ls '+tempdir+'| grep -v files.list > '+tempdir+'/files.list'
  error, output = getstatusoutput(comm)
  if error:
    log("Error while downloading sources from %s using pip.\n\n %s \n %s \n  %s \n " % (source, comm, error, output) )
    return False

  comm2='cd '+tempdir+'; tar cfz '+dest+'/'+tarball+' files.list `cat files.list`'
  error, output = getstatusoutput(comm2)
  if error:
    log("Error while downloading sources from %s using pip.\n\n %s \n %s \n  %s \n " % (source, comm, error, output) )
    return False

  return True

downloadHandlers = {'cvs': downloadCvs,
                    'cmstc': downloadTc,
                    'http': downloadUrllib2,
                    'https': downloadUrllib2,
                    'ftp': downloadUrllib2,
                    'ftps': downloadUrllib2,
                    'git': downloadGit,
                    'svn': downloadSvn,
                    'pip': downloadPip}

    
def getUrlChecksum (s):
    m = md5adder (s)
    return m.hexdigest ()

def isProcessRunning(pid):
  running = False
  try:
    os.kill(pid, 0)
    running = True
  except:
    pass
  return running

class cmsLock (object):
  def __init__ (self, dirname):
    self.piddir  = join(dirname,".cmsLock")
    self.pidfile = join(self.piddir,"pid")
    self.pid     = str(getpid())
    self._hasLock = False
    self._hasLock = self._get()

  def __del__(self):
    self._release ()    

  def __nonzero__(self):
    return self._hasLock

  def _release (self, force=False):
    if (self._hasLock or force):
      try:
        if exists (self.piddir): getstatusoutput ("rm -rf %s" % self.piddir)
      except:
        pass
    self._hasLock = False

  def _get(self, count=0):
    if count >= 5: return False
    pid = self._readPid()
    if pid:
      if pid == self.pid: return True
      if isProcessRunning(int(pid)): return False
    self._create()
    sleep(0.0001)
    return self._get(count+1)

  def _readPid(self):
    pid = None
    try:
      pid = open(self.pidfile).readlines()[0]
    except:
      pid = None
    return pid

  def _create(self):
    self._release(True)
    try:
      makedirs(self.piddir)
      lock = open (self.pidfile, 'w')
      lock.write(self.pid)
      lock.close()
    except:
      pass

# Helper class which contains only the options that are
# relevant for download.
class DownloadOptions(object):
  def __init__ (self, options):
    self.workDir = options.workDir 
    self.tempDirPrefix = options.tempDirPrefix
    self.cmsdist = options.cmsdist 

def download (source, dest, options):
    # Syntactic sugar for git:/some/path to be equal to git+:///some/path
    if source.startswith("git:") and not source.startswith("git://"):
      source = "git+://" + source[4:]
    # Syntactic sugar to allow the following urls for tag collector:
    #
    # cmstc:[base.]release[.tagset[.tagset[...]]]/src.tar.gz
    #
    # in place of:
    #
    # cmstc://?tag=release&baserel=base&extratag=tagset1,tagset2,..&module=CMSSW&export=src&output=/src.tar.gz
    if source.startswith("cmstc:") and not source.startswith("cmstc://"):
      url = source.split(":", 1)[1]
      desc, output = url.rsplit("/", 1)
      parts = desc.split(".")
      releases = [x for x in parts if not x.isdigit()]
      extratags = [x for x in parts if x.isdigit()]
      if extratags:
        extratags = "&extratags=" + ",".join(extratags)
      if len(releases) == 1:
        baserel=""
        release="tag="+ releases[0]
      elif len(releases) == 2:
        baserel="&baserel=" + releases[0]
        release=releases[1]
      else:
        raise MalformedUrl(source)
      source = "cmstc://?%s%s%s&module=CMSSW&export=src&output=/%s" % (release,baserel,extratags,output)
      
    cacheDir=abspath (join (options.workDir, "SOURCES/cache")) 
    urlTypeRe = re.compile ("([^:+]*)([^:]*)://.*")
    match = urlTypeRe.match (source)
    if not urlTypeRe.match (source):
        raise MalformedUrl (source)
    downloadHandler = downloadHandlers[match.group (1)]
    checksum = getUrlChecksum (source)
    filename = source.rsplit("/", 1)[1]
    downloadDir = join (cacheDir, checksum[0:2], checksum)
    try:
      makedirs (downloadDir)
    except OSError, e:
      if not exists(downloadDir):
        raise downloadDir 

    realFile = join (downloadDir,filename)
    if exists (realFile):
      if not exists (join (dest, filename)):
        symlink (realFile, join (dest, filename))
      return True
    cachedFile = "%s/SOURCES/%s/%s/%s" % (options.server.rstrip ("/"), options.repository, checksum, filename)
    downloadOptions = DownloadOptions(options)
    log ("Trying to fetch cached file: %s" % cachedFile, DEBUG)
    getstatusoutput ("rm -f %s" % join(downloadDir, ".no-cmsrep-upload"))
    success = downloadHandlers["http"] (cachedFile, downloadDir, downloadOptions, True)
    if not success:
      log ("Trying to fetch source file: %s" % source, DEBUG)
      success = downloadHandler (source, downloadDir, downloadOptions)
    if success:
        #if '/github.com/' in source:
        #    r=open (join (downloadDir, ".no-cmsrep-upload"), 'w')
        #    r.close ()
        f=open (join (downloadDir, "url"), 'w')
        f.write ("%s\n" % source)
        f.close ()
        if exists (realFile) and not exists (join (dest, filename)):
            symlink (realFile, join (dest, filename))        
    return success

class MalformedUrl (Exception):
    def __init__ (self, url, missingParams=[]):
        if not missingParams:
            self.args = ["ERROR: The following url is malformed: %(url)s." % locals ()]
        else:
            self.args = ["ERROR: The following parameters are missing from url %(url)s: %(missingParams)s" % locals ()]

class MalformedSpec (Exception):
    pass

class RpmBuildFailed (Exception):
    def __init__ (self, package):
        self.args = ["Failed to build package %s." % package.name] 
        self.pkg = package

class UnexpectedFile (Exception):
    def __init__ (self, filename):
        self.args = ["""Unexpected file:\n %s\n
Please remove it and start again.""" % filename]

class RpmInstallFailed (Exception):
    def __init__ (self, package, why=""):
        self.args = ["Failed to install package %s. Reason:\n%s" % (package.name, why)]
        self.pkg = package
        self.why = why

class UnableToDownload (Exception):
    pass

class FileNotFound (Exception):
    def __init__ (self, filename):
        log (filename)
        self.filename = filename
    def __repr__ (self):
        log ("Unable to find file %s" % self.filename)

class NotCorrectlyBootstrapped (Exception):
    def __init__ (self, why):
        self.why = why

class UnknownCompiler (Exception):
    pass

# The initial id for a given tag. Change to 1 if you always want to have -cms.
INITIAL_ID = 0
    
def tagToId (tag, origTag):
    return int ((tag or 0) and (tag.replace (origTag, "") or 1))

def idToTag (tagId, origTag):
    if not tagId:
        return ""
    elif tagId == 1:
        return origTag
    else:
        return "%s%s" % (origTag, tagId)

# Parses the `### RPM <group> <package> <realversion>` header.
# Such a header defines the package name, group and real version
# for a given package.
# Notice that for a package which matches the compiler
# name we allow the overriding of its version with the one specified 
# in the `compilerVersion` settings.
# Notice also that the one can specify /bin/sh commands in backticks
# for the version, so that stuff like the date can be added to the
# version (useful for IB and alikes).
# FIXME: notice that for compatibility with old packages, which were
# specifying a -CMSXYZ tag by hand, we remove such a suffix from 
# the version. This is probably not needed anymore and can go.
def parseRPMLine (specLines, opts):
  findRpmRe = re.compile ("^### RPM[ ]*([^ ]*)\s*([^ ]*)\s*(.*)")
  for line in specLines:
    match = findRpmRe.match (line)
    if not match:
      continue
    results = [x.strip (" ") for x in match.groups ()]
    results[2] = re.sub ("-CMS.*","",results[2])
    group, name, version = results
    error, output = getstatusoutput("echo %s" % version)
    if error:
      raise MalformedSpec
    version = output.split("\n")[0]
    if opts.compilerVersion and name == opts.compilerName:
      version = opts.compilerVersion
    return (group, name, version)
  raise MalformedSpec

def parseNoCompilerLine(specLines):

    findNoCompilerRe = re.compile ("^## NOCOMPILER")
    for line in specLines:
        if findNoCompilerRe.match(line):
            return True
    return False

def parseBuildRequireToolfileLine(specLines):

    findBRToolfileRe = re.compile ("^## BUILDREQUIRE-TOOLFILE")
    for line in specLines:
        if findBRToolfileRe.match(line):
            return True
    return False

class PkgInfo (object):
    """ Minimal information about a package.
    """
    def __init__ (self, pkg):
        self.name = pkg.name
        self.realVersion = pkg.realVersion
        self.group = pkg.group
        self.checksum = pkg.checksum
        self.cmsplatf = pkg.cmsplatf

    def id (self):
        return "%(group)s+%(name)s+%(realVersion)s" % self.__dict__

def getPkgName (filename):
    return re.match ("(.*)-1-[1-9]+[.].*", basename(filename)).group (1)
  
def getPkgChecksumFile (officialRpmLocation, buildOptions=None):
    try:
        link = readlink (officialRpmLocation)
    except OSError:
        log ("""ERROR! File %(officialRpmLocation)s is not a link!?!? 
                Are you running in an old cmsBuild.sh/install.sh area?
                If so, please remove the old package by doing:

                rm -rf %(officialRpmLocation)s

                and try again.
                """ % locals ())
        sys.exit (1)
    if not exists (link):
        packageName = getPkgName (officialRpmLocation)
        cmsBuildExec = sys.argv[0]
        workdir = buildOptions.workDir and "--work-dir %s"% buildOptions.workDir or ""
        doNotBootstrap = buildOptions.bootstrap and "" or "--do-not-bootstrap"
        architecture = "--architecture %s" % buildOptions.architecture
        cmsdist = "--cmsdist %s" % buildOptions.cmsdist
        brokenLink = join(buildOptions.workDir, officialRpmLocation) 
        log ("""ERROR: File
        
                %(brokenLink)s 
        
                links to 
                
                %(link)s 
                
                but the latter does not exists. Please run:
                
                # %(cmsBuildExec)s %(cmsdist)s %(architecture)s %(workdir)s %(doNotBootstrap)s deprecate-local %(packageName)s
            
                to fix the problem and then try again.
            """ % locals ())
        sys.exit (1)
    checksum = re.match (".*/(.*)/.*/.*", link).groups ()[0]
    if not checksum:
        log ("""ERROR: malformed link found: %(link)s.""" % locals ())
        sys.exit (1)
    return checksum

class TagCacheAptImpl (object):
    """ Concrete implementation of the tag cache which relies on the
        apt repository information and locally found packages. Consistency
        is enforced by policy (only one person is allowed to upload packages 
        for a given tag) and by checking at upload time that packages are not
        already in the repository. 
    """
    def __init__ (self, options):
        self.options = options
    
    def update (self):
      if self.options.bootstrap:
        error, output = getstatusoutput ("%s update" % CMSPKG_CMD)
        if error:
          die("Error while executing cmspkg update.\n%s" % output)
        error, output = getstatusoutput("%s search" % CMSPKG_CMD)
        if error:
          die("Error while executing cmspkg search.\n%s" % output)
        lines = [line for line in output.split("\n") if line]
        chksumRE = re.compile("\s+-\s+.*?SpecChecksum:")
        pairs = [chksumRE.sub(' ',line).split() for line in lines]
        try:
          self.cache = dict(pairs)
        except:
          die("Malformed cmspkg search output.")
       
    def requestTag (self, pkgInfo, tag):
        """ requestTag returns a unique tag (i.e. the mnemonic suffix at the 
            end of the package name) based on what is found in the online 
            database and in the local build area.
            
            @a pkgInfo is the structure which holds the information about a 
               tag.
            @a tag the mnemonic tag to be used to keep track of different 
               package builds. E.g. "cms" or "ge"
            @return a unique tag (ie cmsXXX) which can be used for the package.
        """
        tags = {}
        if self.options.bootstrap:
            matchingPackages = [(n, rpm_db_cache[n][1]) for n in rpm_db_cache if (pkgInfo.id() in n) and (not n in self.cache)]
            matchingPackages += [(n, self.cache[n]) for n in self.cache if pkgInfo.id() in n]
            for name, checksum in matchingPackages:
                tempTag = name.replace(pkgInfo.id (), "").strip ("-")
                tags[tempTag] = checksum
        for package in listdir (join ("RPMS", pkgInfo.cmsplatf)): 
            if pkgInfo.id() not in package:
                continue
            linkName = join ("RPMS", pkgInfo.cmsplatf, package)
            checksum = getPkgChecksumFile (linkName, self.options)
            tempTag = getPkgName(package).replace (pkgInfo.id (), "").strip ("-")
            tags[tempTag] = checksum
        for i in itertools.count(INITIAL_ID):
            finalTag = idToTag (i, tag)
            if finalTag not in tags:
                break
        return finalTag
    
    def getTag (self, pkg):
        """ getTag looks up for a tag associated to an md5 sum the following way.
        1) Look up in the cache cmspkg search results.
        2) Looks up in RPMS/cache/<checksum> to see if a package is already there.
        """
        output = ""
        if self.options.bootstrap:
          matchingPackages = [n for n in self.cache if self.cache[n]==pkg.checksum]
          matchingPackages +=[n for n in rpm_db_cache if rpm_db_cache[n][1]==pkg.checksum]
          if len(matchingPackages)>1:
            orderedPackages = []
            for n in matchingPackages:
              if exists("%s/RPMS/cache/" % self.options.workDir + "%(checksum)s/%(cmsplatf)s/" % pkg.__dict__ + n + "-%(rpmVersion)s-%(pkgRevision)s.%(cmsplatf)s.rpm" % pkg.__dict__):
                orderedPackages.insert(0,n)
              else:
                orderedPackages.append(n)
            matchingPackages = orderedPackages
          log ("Matching Packages all %s: %s" % (pkg.checksum, ",".join(matchingPackages)), DEBUG)
          if len(matchingPackages):
            output = matchingPackages[0]
          else:
            return None
        else:
            try:
                assert (pkg.cmsplatf and pkg.cmsplatf != "%cmsplatf")
                assert (pkg.checksum and pkg.checksum != "%checksum" and pkg.checksum != "%{nil}")
                rpmCachePath = join (abspath ("RPMS"), 
                                     "cache/%(checksum)s/%(cmsplatf)s" % pkg.__dict__)
                if "%{" in rpmCachePath:
                    print "ERROR: you seem to be using an old rpm-preamble.file in your CMSDIST."
                    print "Please make sure you update it to revision 1.20 at least."
                    sys.exit(1)
                files = listdir (rpmCachePath % pkg.__dict__)
                if len (files) > 1 + len(pkg.subpackages):
                    log ("""ERROR: %s structure is hoosed. You might want to do:
                            cmsBuild remove %s""" % (rpmCachePath, 
                                                     getPkgName(files[0])))
                    sys.exit (1)
                elif not len (files):
                    return None
                output = getPkgName(files[0])
            except OSError:
                return None
        
        if not output:
            return None
        fullVersion = output.rsplit("+", 1)[1]
        if "-" not in fullVersion:
            return ""
        tag = fullVersion.rsplit("-", 1)[1]
        # Return tag if it is not part of realVersion
        if not pkg.realVersion.endswith("-"+tag):
            return tag
        return ""
    
    def packageChecksums (self, package):
        """ 
        """
        assert (False and "Not implemented for the time being.")

global tags_cache        
tags_cache = None

# FIXME: write a more valuable description
DEFAULT_SECTIONS = {"": """
""",
                    "%%description": """
No description
""",
                  "%prep": """
%%setup -n %n-%realversion
""",
                  "%build": """
%initenv
./configure --prefix=%i
make
""",
                "%install": """
%initenv
make install
""",
                "%pre": """
if [ X"$(id -u)" = X0 ]; then
  if [ ! -f /etc/cms-root-install-allowed ]; then
    echo "*** CMS SOFTWARE INSTALLATION ABORTED ***"
    echo "CMS software cannot be installed as the super-user."
    echo "(We recommend reading a unix security guide)."
    exit 1
  fi
fi
""",
                "%post": """
if [ "X$CMS_INSTALL_PREFIX" = "X" ] ; then CMS_INSTALL_PREFIX=$RPM_INSTALL_PREFIX; export CMS_INSTALL_PREFIX; fi
%{relocateConfig}etc/profile.d/init.sh
%{relocateConfig}etc/profile.d/init.csh
""",
                "%preun": """
""",
                "%postun": """
if [ "X$CMS_INSTALL_PREFIX" = "X" ] ; then CMS_INSTALL_PREFIX=$RPM_INSTALL_PREFIX; export CMS_INSTALL_PREFIX; fi
""",
                "%files": """
%{i}/
%dir %{instroot}/
%dir %{instroot}/%{cmsplatf}/
%dir %{instroot}/%{cmsplatf}/%{pkgcategory}/
%dir %{instroot}/%{cmsplatf}/%{pkgcategory}/%{pkgname}/
"""}


COMPILER_DETECTION = { "gcc": "gcc -v 2>&1 | grep version | sed -e \'s|.*\\([0-9][.][0-9][.][0-9]\\).*|\\1|\'",
"icc": "echo no detection callback for icc."}


# Preambles. %dynamic_path_var is defined in rpm-preamble.

INITENV_PREAMBLE = [
("CMD_SH", "if", "[ -f %i/etc/profile.d/dependencies-setup.sh ]; then . %i/etc/profile.d/dependencies-setup.sh; fi"),
("CMD_CSH", "if", "( -f %i/etc/profile.d/dependencies-setup.csh ) source %i/etc/profile.d/dependencies-setup.csh; endif"),
("SETV", "%(uppername)s_ROOT", "%i"),
("SETV", "%(uppername)s_VERSION", "%v"),
("SETV", "%(uppername)s_REVISION", "%pkgrevision"),
("SETV", "%(uppername)s_CATEGORY", "%pkgcategory"),
("+PATH", "PATH", "%i/bin"),
("+PATH", "%%{dynamic_path_var}", "%i/lib")]

if sys.platform == 'darwin' : DEFAULT_PREAMBLE = """
AutoReqProv: no
"""
else: DEFAULT_PREAMBLE = """
"""

DEFAULT_DESCRIPTION_PREAMBLE = """
"""

DEFAULT_PREP_PREAMBLE = """
%initenv
[ -d %i ] && chmod -R u+w %i
rm -fr %i
"""

DEFAULT_BUILD_PREAMBLE = """
%initenv
"""

DEFAULT_INSTALL_PREABLE = """
mkdir -p %i
mkdir -p %_rpmdir
mkdir -p %_srcrpmdir
%initenv
"""

DEFAULT_PRE_PREAMBLE = """
if [ X"$(id -u)" = X0 ]; then
    echo "*** CMS SOFTWARE INSTALLATION ABORTED ***"
    echo "CMS software cannot be installed as the super-user."
    echo "(We recommend reading a unix security guide)."
    exit 1
fi
"""
DEFAULT_POST_PREAMBLE = """
if [ "X$CMS_INSTALL_PREFIX" = "X" ] ; then CMS_INSTALL_PREFIX=$RPM_INSTALL_PREFIX; export CMS_INSTALL_PREFIX; fi
%{relocateConfig}etc/profile.d/init.sh
%{relocateConfig}etc/profile.d/init.csh
"""


if sys.platform == "darwin": DEFAULT_POST_POSTAMBLE = """
re_rpath() 
   {
       chmod +w ${1}
       for RP in `otool -l ${1} | grep -A2 LC_RP | grep path | awk '{print $2}'`;do
          if [ -z "${RP##/*/%{cmsplatf}/}" ]; then
            install_name_tool -delete_rpath $RP ${1} || true
          fi
       done   
       rpathnew="@loader_path/."
       install_name_tool -add_rpath $rpathnew ${1} 2>/dev/null || true
       rpathnew="@executable_path/."
       install_name_tool -add_rpath $rpathnew ${1} 2>/dev/null || true
       rpathnew="@loader_path/../../lib/%{cmsplatf}"
       install_name_tool -add_rpath $rpathnew ${1} 2>/dev/null || true
       rpathnew="@executable_path/../../lib/%{cmsplatf}"
       install_name_tool -add_rpath $rpathnew ${1} 2>/dev/null || true
       rpathold=${1%%/%{cmsplatf}/*}/%{cmsplatf}/
       curpath=`dirname ${1}`
       relpath=`perl -e 'use File::Spec; print File::Spec->abs2rel(@ARGV);' $rpathold $curpath`
       rpathnew="@loader_path/"$relpath
       install_name_tool -add_rpath $rpathnew ${1} 2>/dev/null || true
       install_name_tool -add_rpath $CMS_INSTALL_PREFIX/%{cmsplatf} ${1} 2>/dev/null || true
       chmod -w ${1}
   }
for x in `find $RPM_INSTALL_PREFIX/%{pkgrel}/ -type f -perm -u+x | grep -v -e "[.]pyc"`; do 
  filestr=`file $x | tail -1 | cut -d: -f2 `
  if [ -z "${filestr##*Mach-O*dynamically*}" ]; then
     re_rpath $x
  fi
  if [ -z "${filestr##*Mach-O*bundle*}" ]; then 
     re_rpath $x
  fi
  if [ -z "${filestr##*Mach-O*binary*}" ]; then
     re_rpath $x
  fi
  if [ -z "${filestr##*Mach-O*executable*}" ]; then
     re_rpath $x
  fi
done
"""
else: DEFAULT_POST_POSTAMBLE = ""

DEFAULT_PREUN_PREAMBLE = """
"""
DEFAULT_POSTUN_PREAMBLE = """
if [ "X$CMS_INSTALL_PREFIX" = "X" ] ; then CMS_INSTALL_PREFIX=$RPM_INSTALL_PREFIX; export CMS_INSTALL_PREFIX; fi
"""

DEFAULT_FILES_PREAMBLE = """
%%defattr(-, root, root)
"""
DEFAULT_RPATH_PREAMBLE = "\n%{?post_initenv:%post_initenv}\n%{?add_rpath:%add_rpath}\n"

COMMANDS_SH = {"SETV":      """%(var)s="%(value)s"\n""",
               "SET":       """export %(var)s="%(value)s";\n""",
               "+PATH":     """[ ! -d %(value)s ] || export %(var)s="%(value)s${%(var)s:+:$%(var)s}";\n""",
               "UNSET":     """unset %(var)s || true\n""",
               "CMD":       """%(var)s %(value)s\n""",
               "CMD_SH":    """%(var)s %(value)s\n""",
               "CMD_CSH":   "",
               "ALIAS":     """alias %(var)s="%(value)s"\n""",
               "ALIAS_CSH": "",
               "ALIAS_SH":  """alias %(var)s="%(value)s"\n"""}

COMMANDS_CSH = {"SETV":     """set %(var)s="%(value)s"\n""",
                "SET":      """setenv %(var)s "%(value)s"\n""",
                "+PATH":    """if ( -d %(value)s ) then\n"""
                            """  if ( ${?%(var)s} ) then\n"""
                            """    setenv %(var)s "%(value)s:$%(var)s"\n"""
                            """  else\n"""
                            """    setenv %(var)s "%(value)s"\n"""
                            """  endif\n"""
                            """endif\n""",
                "UNSET":    """unset %(var)s || true\n""",
                "CMD":      """%(var)s %(value)s\n""",
                "CMD_SH":   "",
                "CMD_CSH":  """%(var)s %(value)s\n""",
                "ALIAS":    """alias %(var)s "%(value)s"\n""",
                "ALIAS_SH": "",
                "ALIAS_CSH":"""alias %(var)s "%(value)s"\n"""}

SPEC_HEADER = """
%%define pkgname        %(name)s
%%define pkgversion     %(version)s
%%define pkgcategory    %(group)s
%%define cmsroot        %(workDir)s
%%define instroot       %(workDir)s/%(tempDirPrefix)s/BUILDROOT/%(checksum)s%(installDir)s
%%define realversion    %(realVersion)s
%%define gccver         %(compilerRealVersion)s
%%define compilerRealVersion %(compilerRealVersion)s
%%define pkgrevision    %(pkgRevision)s
%%define pkgreqs        %(pkgreqs)s
%%define directpkgreqs	%(directpkgreqs)s
%%define specchecksum   %(checksum)s
%%define cmscompiler	%(compilerName)s
%%define cmsbuildApiVersion 1
%%define installroot    %(installDir)s
%%define tempprefix     %(tempDirPrefix)s
Name: %(group)s+%(name)s+%(version)s
Group: %(group)s
Version: %(rpmVersion)s
Release: %(pkgRevision)s
License:  "As required by the orginal provider of the software."
Summary: %(summary)s SpecChecksum:%(checksum)s
%(requiresStatement)s
Packager: CMS <hn-cms-sw-develtools@cern.ch>
Distribution: CMS
Vendor: CMS
Provides: %(group)s+%(name)s+%(version)s
Obsoletes: %(group)s+%(name)s+%(version)s
Prefix: %(installDir)s
"""

if not sys.platform == "darwin": DEFAULT_INSTALL_POSTAMBLE="""
# Avoid pkgconfig dependency.  Notice you still need to keep the rm statement
# to support architectures not being build with cmsBuild > V00-19-XX
%if "%{?keep_pkgconfig:set}" != "set"
if [ -d "%i/lib/pkgconfig" ]; then rm -rf %i/lib/pkgconfig; fi
%endif

# Do not package libtool and archive libraries, unless required.
%if "%{?keep_archives:set}" != "set"
# Don't need archive libraries.
rm -f %i/lib/*.{l,}a
%endif

# Strip executable / paths which were specified in the strip_files macro.
%if "%{?strip_files:set}" == "set"
for x in %strip_files
do
  if [ -e $x ]
  then
    find $x -type f -perm -a+x -exec %strip {} \;
  fi 
done
%endif

# remove files / directories which were specified by the drop_files macro.
%if "%{?drop_files:set}" == "set"
for x in %drop_files
do
  if [ -e $x ]; then rm -rf $x; fi
done
%endif

for x in `find %{i} -type f -perm -u+x | grep -v -e "[.]pyc"`; 
do 
    if [ "X`file --mime $x | sed -e 's| ||g' | cut -d: -f2 | cut -d\; -f1`" = Xapplication/octet-stream ]
    then
      chmod +w $x
      old_install_name=`otool -D $x | tail -1 | sed -e's|:$||'`
      new_install_name=`basename $old_install_name`
      install_name_tool -change $old_install_name $new_install_name -id $new_install_name $x
      # Make sure also dependencies do not have an hardcoded path.
      for dep in `otool -L $x | sed -e"s|[^\\t\\s ]*%{instroot}|%{instroot}|" | grep -e '^/' | sed -e's|(.*||'`
      do
        install_name_tool -change $dep `basename $dep` $x
      done
      chmod -w $x
    fi
done
"""
else: DEFAULT_INSTALL_POSTAMBLE="""
# Avoid pkgconfig dependency.  Notice you still need to keep the rm statement
# to support architectures not being build with cmsBuild > V00-19-XX
%if "%{?keep_pkgconfig:set}" != "set"
if [ -d "%i/lib/pkgconfig" ]; then rm -rf %i/lib/pkgconfig; fi
%endif

# Do not package libtool and archive libraries, unless required.
%if "%{?keep_archives:set}" != "set"
# Don't need archive libraries.
rm -f %i/lib/*.{l,}a
%endif

# Strip executable / paths which were specified in the strip_files macro.
%if "%{?strip_files:set}" == "set"
for x in %strip_files
do
  if [ -e $x ]
  then
    find $x -type f -perm -a+x -exec %strip {} \;
  fi 
done
%endif

# remove files / directories which were specified by the drop_files macro.
%if "%{?drop_files:set}" == "set"
for x in %drop_files
do
  if [ -e $x ]; then rm -rf $x; fi
done
%endif

case %{cmsplatf} in
    osx* )
        relocate_dylib()
            {
              chmod +w ${1}
              new_install_name="@rpath/"${1#*%{cmsplatf}/}
              install_name_tool -id $new_install_name ${1} || install_name_tool -id `basename ${1}` ${1}
              # Change dependencies hardcoded path to new install path.
              for dep in `otool -L ${1} | sed -e's|(.*||' | grep -v -e':$' | grep -v -e'^/usr/lib'| grep -v '/Frameworks/'`
              do
                 libname=`basename $dep`
                 if [ -z "${dep##/*/%{cmsplatf}/*$libname}" ]
                 then
                   newdep="@rpath/"${dep#/*/%{cmsplatf}/}
                   install_name_tool -change $dep $newdep ${1} || true
                 fi
                 if [ -z "${dep##$libname}" ];then
                   newdep="@loader_path/"$libname
                   install_name_tool -change $dep $newdep ${1} || true
                 fi
                 if [ -z "${dep##@rpath/$libname}" ]; then
                   newdep="@loader_path/"$libname
                   install_name_tool -change $dep $newdep ${1} || true
                 fi
              done
              chmod -w ${1}
             }
        for x in `find %{i} -type f -perm -u+x | grep -v -e "[.]pyc" `; do
          filestr=`file $x | tail -1 | cut -d: -f2 `
          if [ -z "${filestr##*Mach-O*dynamically*}" ];then 
            relocate_dylib $x
          fi
          if [ -z "${filestr##*Mach-O*bundle}" ];then
            relocate_dylib $x
          fi
          if [ -z "${filestr##*Mach-O*binary*}" ];then
            relocate_dylib $x
          fi
          if [ -z "${filestr##*Mach-O*executable*}" ];then 
              chmod +w $x
              # Change dependencies hardcoded path to new install path.
              for dep in `otool -L $x | sed -e's|(.*||' | grep -v -e':$'`
              do
                libname=`basename $dep`
                if [ -z "${dep##/*/%{cmsplatf}/*$libname}" ]
                then 
                  newdep="@rpath/"${dep#/*/%{cmsplatf}/}
                  install_name_tool -change $dep $newdep $x || true 
                fi
              done
              chmod -w $x
           fi
        done
    ;;
    * )
    ;;
esac
"""

DEFAULT_PREP_POSTAMBLE="""
"""

DEFAULT_BUILD_POSTAMBLE="""

# make sure that at least an empty file list does exist
touch %_builddir/files
"""

class CacheProxy (object):
    def __init__ (self, cache, decorator):
        """ This object is responsible for caching object but keeping in mind the fact that
            different architectures will
        """
        self.__cache = cache
        self.__decorator = decorator

    def __getitem__ (self, name):
        return self.__cache.__getitem__ (self.__decorator (name))
        
    def __setitem__ (self, name, item):
        self.__cache.__setitem__ (self.__decorator (name), item)

    def has_key (self, name):
        return self.__cache.has_key (self.__decorator (name))
        
class ArchitectureDecorator (object):
    def __init__ (self, architecture):
        self.__architecture = architecture
    def __call__ (self, name):
        return self.__architecture + name

global checksums_cache
checksums_cache = {}

# Silence the deprecation warning until we move completely to 2.6.X
import warnings
warnings.filterwarnings("ignore",category=DeprecationWarning)
try:
  from md5 import new as md5adder
except ImportError:
  from hashlib import md5 as md5adder

def calculateHumanReadableVersion (pkg):
    # This takes care of converting a checksum to something human-readable.
    #  * If the package has a revision different than 1, we assume that it is
    #    an old style one and we return the realVersion as version.
    #  * If the checksum is available in the DB, we use the tag, rather than 
    #    the checksum.
    #  * If the checksum is not in the DB, but an official tag is requested, 
    #    we associate the checksum to the tag, possibly adding an incremental 
    #    number to it if a given package/version already uses it.

    if not isDefaultRevision(pkg.pkgRevision):
# lange - 080727 -- to get a revision the user will just have to specify the full
# version including the tag. Otherwise we get the tag no matter what..
#
#        if pkg.options.tag:
#            return "%s-%s" % (pkg.realVersion, pkg.options.tag)
        return pkg.realVersion
    log ("%s has checksum %s" % (pkg.name, pkg.checksum), DEBUG)
    tag = tags_cache.getTag (pkg)
    if tag != None:
        log ("%s is aliased to \'%s\', using \'%s\'" % (pkg.checksum, tag, tag), DEBUG)
    elif pkg.options.tag:
        pkgInfo = PkgInfo (pkg)
        tag = tags_cache.requestTag (pkgInfo, pkg.options.tag)
        log ("Attempt to assign %s to \'%s\'" % (pkg.checksum, tag), DEBUG)
    else:
        tag = pkg.checksum
    if not tag:
        return "%s" % pkg.realVersion
    else:
        return "%s-%s" % (pkg.realVersion , tag)

def specFilename (opts, pkgName):
    return join (abspath (opts.cmsdist), "%s.spec" % pkgName)

def redefineMacro (name, value, maxLength=8000, initCount=0):
    exSpec = ""
    value  = re.sub("\s+", " ",value.strip())
    values = splitMacroLine(value, maxLength)
    if len(values)>1:
        value = ""
        for v in values:
            exSpec += "%%define %s%d %s\n" % (name, initCount, v)
            value += "%%{%s%d} " % (name, initCount)
            initCount += 1
        subexSpec, value =  redefineMacro(name, value, maxLength, initCount)
        exSpec += subexSpec
    return (exSpec, value)
    
def splitMacroLine (value, maxLength=8000):
    nvalue = [ value ]
    if len(value)>maxLength:
        nvalue = []
        while len(value) > maxLength:
            xIndex = value.find(" ",maxLength)
            if xIndex == -1: break
            nvalue.append(value[0:xIndex])
            value  = value[xIndex+1:]
        nvalue.append(value)
    return nvalue

class ReadOnlyDict (dict):
    class PermissionError (Exception):
        def __init__ (self):
            Exception.__init__ (self, "Read only dict, cannot set its items")
    def __setitem__ (self, key, value):
        raise ReadOnlyDict.PermissionError ()

class HeaderMatchingRegexps (object):
    def __init__ (self):
        self.REQUIRES_REGEXP = re.compile ("^Requires: (.*)")
        self.REMOTE_SOURCE_REGEXP = re.compile ("^[Ss]ource[0-9]*: (.*:.*/.*)")
        self.REMOTE_PATCH_REGEXP = re.compile ("^[Pp]atch[0-9]*: (.*:.*/.*)")
        self.LOCAL_SOURCE_REGEXP = re.compile ("^[Ss]ource[0-9]*: (.*)")
        self.LOCAL_PATCH_REGEXP = re.compile ("^[Pp]atch[0-9]*: (.*)")
        self.BUILD_REQUIRES_REGEXP = re.compile ("^BuildRequires: (.*)")

class CmsOSDumper (object):
    def __init__ (self, cmsdistPath):
        cmsosFilename = join (abspath (cmsdistPath), "cmsos.file")
        cmsosFile = open (cmsosFilename)
        self.__cmsos = cmsosFile.read ()
        cmsosFile.close ()

    def dump (self, sourcedir):
        destFilename = join (sourcedir, "cmsos")
        log ("Copying cmsos.file to %s" % destFilename, DEBUG)
        destFile = file (destFilename, 'w')
        destFile.write (self.__cmsos)
        destFile.close ()

class PackageFactory (object):
    def __init__ (self, options, cmsosDumperClass=CmsOSDumper):
        self.__package_cache = {}
        self.__requires_cache = {}
        self.__syntax = MetaSpecSyntax ()
        self.__options = options
        self.__cacheKeyDecorator = ArchitectureDecorator (options.architecture)
        self.__preamble = self.__getPreamble ()
        self.__sectionOptions = ReadOnlyDict ({"": "",
                        "%%description": "",
                        "%prep": "",
                        "%build": "",
                        "%install": "",
                        "%pre": "",
                        "%post": "",
                        "%preun": "",
                        "%postun": "",
                        "%files": "-f %_builddir/files"})
        self.__sectionPreambles = ReadOnlyDict ({"": DEFAULT_PREAMBLE,
                        "%%description": DEFAULT_DESCRIPTION_PREAMBLE,
                        "%prep": DEFAULT_PREP_PREAMBLE,
                        "%build": DEFAULT_BUILD_PREAMBLE,
                        "%install": DEFAULT_INSTALL_PREABLE,
                        "%pre": DEFAULT_PRE_PREAMBLE,
                        "%post": DEFAULT_POST_PREAMBLE,
                        "%preun": DEFAULT_PREUN_PREAMBLE,
                        "%postun": DEFAULT_POSTUN_PREAMBLE,
                        "%files": DEFAULT_FILES_PREAMBLE})

        self.__sectionPostambles = {"": "",
                        "%%description": "",
                        "%prep": DEFAULT_PREP_POSTAMBLE,
                        "%build": DEFAULT_BUILD_POSTAMBLE,
                        "%install": DEFAULT_INSTALL_POSTAMBLE,
                        "%pre": "",
                        "%post": DEFAULT_POST_POSTAMBLE,
                        "%preun": "",
                        "%postun": "",
                        "%files": ""}
        self.__postprocessingRules = [(re.compile ("%\{n\}"), "%{pkgname}"),
                                       (re.compile ("%\{v\}"), "%{pkgversion}"),
                                       (re.compile ("%\{i\}"), "%{pkginstroot}"),
                                       (re.compile ("%n$"), "%{pkgname}"),
                                       (re.compile ("%v$"), "%{pkgversion}"),
                                       (re.compile ("%i$"), "%{pkginstroot}"),
                                       (re.compile ("%n([^_A-Za-z0-9])"), "%{pkgname}\\1"),
                                       (re.compile ("%v([^_A-Za-z0-9])"), "%{pkgversion}\\1"),
                                       (re.compile ("%i([^_A-Za-z0-9])"), "%{pkginstroot}\\1"),
                                       (re.compile ("^Source:"), "Source0:"),
                                       (re.compile ("^Patch:"), "Patch0:")]
        self.__cmsosDumper = cmsosDumperClass (options.cmsdist)
        self.__headerMatchingRegexp = HeaderMatchingRegexps ()

    def __getPreamble (self):
        try:
            filename = join (self.__options.cmsdist, "rpm-preamble.file")
            return open (filename).read ()
        except:
            raise FileNotFound (filename)
            
    def create (self):
        pkg = Package (self.__options)
        pkg._Package__syntax = self.__syntax
        pkg._Package__packageCache = CacheProxy (self.__package_cache, 
                                                 self.__cacheKeyDecorator)
        pkg._Package__requiresCache = CacheProxy (self.__requires_cache, 
                                                  self.__cacheKeyDecorator)
        pkg._Package__preamble = self.__preamble
        pkg._Package__sectionOptions = self.__sectionOptions
        pkg._Package__sectionPreambles = self.__sectionPreambles
        pkg._Package__sectionPostambles = copy.deepcopy (self.__sectionPostambles)
        pkg._Package__cmsosDumper = self.__cmsosDumper
        pkg._Package__headerMatchingRegexp = self.__headerMatchingRegexp
        pkg._Package__factory = self
        return pkg

    def createWithSpec (self, pkgName):
        pkg = self.create ()
        filename = specFilename (self.__options, pkgName)
        log ("Creating package using spec file: %s" % filename, DEBUG)
        try:
            specLines = open (filename).readlines ()
        except IOError, e:
            raise FileNotFound (filename)            
        pkg.initWithSpec (specLines)
        if pkg.name != pkgName:
          log ("FATAL: Package name '%s' and spec name '%s' does not match" % (pkg.name, pkgName))
          raise MalformedSpec
        return pkg

    def postProcessSpec (self, spec):
        for regexp, subst in self.__postprocessingRules:
            spec = regexp.sub (subst, spec)
        return spec

    def expandSubpackages (self, packages):
        """ Expand the packages (and their dependencies)'s subpackages.
        """
        out = set()
        for pkg in packages:
            out.add(pkg)
            out.update(pkg.subpackages)
        return sorted(out)

class MetaSpecSyntax (object):
    SPEC_HEADER = property (lambda self : self.__SPEC_HEADER)
    IMPORT      = property (lambda self : self.__IMPORT)
    BUILDIF     = property (lambda self : self.__BUILDIF)
    INITENV     = property (lambda self : self.__INITENV)
    REVISION    = property (lambda self : self.__REVISION)
    SUBPACKAGE  = property (lambda self : self.__SUBPACKAGE)

    def __init__ (self):
        self.__SPEC_HEADER = re.compile ("^### RPM[ ]*([^ ]*)\s*([^ ]*)\s*(.*)")
        self.__IMPORT      = re.compile ("^## IMPORT (.*)")
        self.__BUILDIF     = re.compile ("^## BUILDIF (.*)")
        self.__REVISION    = re.compile ("^## REVISION (.*)")
        self.__SUBPACKAGE  = re.compile (r'^##\s+SUBPACKAGE\s+([\w+-]+)(\s+IF\s+(%[\w+-]+))?\s*$', re.M)

        commands = "|".join (COMMANDS_SH.keys ()).strip ("|").replace ("+", 
                                                                       "[+]")
        initenvStr = "^## INITENV\s+(%s)\s+([^\s]*)\s+(.*)" % commands
        self.__INITENV = re.compile (initenvStr)

class BuilderAction (object):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        """ This is a base class for an action performed by the builder.
            pkg is the payload for the action.
            parent is an action to be completed/completable before being able 
            to execute this one.
            prevAlternative is an alternative action that has precedence on
            this one.
        """
        self.pkg = pkg
        self.prevAlternative = prevAlternative
        self.parent = parent
        self.__cachedRun = None
        self.__cachedExpectedResults = None
        self.__safeRecursion = 0
    
    def run (self):
        """ Actually run a command.
        """
        assert (False)
        
    def dryRun (self):
        """ Returns True if the action should been executed, False if not.
        """
        # If we already have checked this, do not run the check again.
        if self.__cachedRun:
            return self.__cachedRun
        self.__safeRecursion += 1
        if self.__safeRecursion > 100:
            traceback.print_stack ()
            sys.exit (1)

        actionName = self.actionName
        pkgName = self.pkg.pkgName ()
        # Run the check and cache the results but actually return the correct
        # value only if prerequisites are fulfilled and there is no better 
        # alternative.
        self.__cachedRun = self.doDryRun ()

        # Make sure that all the prerequisites can be executed.
        log ("Checking prerequisites for %(actionName)s %(pkgName)s" % locals (), 
             DEBUG)
        tmpParent = self.parent
        assert (tmpParent != self)
        while tmpParent:
            parentName = tmpParent.actionName
            if tmpParent.dryRun () == False:
                self.cannotRun ("""Cannot run '%(actionName)s' for package %(pkgName)s because 
                    dependending on action '%(parentName)s' which will not be executed.""" % locals ())                
                self.__cachedRun = False
                return False
            tmpParent = tmpParent.parent
        log ("All the prerequisites for %(actionName)s %(pkgName)s are there" % locals (), DEBUG)

        # Make sure that none of the better alternatives can be executed
        log ("Checking altenatives to %(actionName)s %(pkgName)s" % locals (), 
             DEBUG)
        tmpAlternative = self.prevAlternative
        assert (tmpAlternative != self)
        while tmpAlternative:
            if tmpAlternative.dryRun () == True:
                alternativeName = tmpAlternative.actionName
                self.cannotRun ("""Cannot run '%(actionName)s' for package %(pkgName)s because 
                                   alternative action '%(alternativeName)s' has priority.""" % locals ())
                self.__cachedRun = False
                return False
            tmpAlternative = tmpAlternative.prevAlternative
        log ("No better alternative to %(actionName)s for %(pkgName)s." % locals (), DEBUG)
        return self.__cachedRun

    def cannotRun (self, message, level=NORMAL):
        """ Use to specify why you couldn't dryRun something.
        """
        self.cannotRunMessage = message
        self.level = level

    def expectedResults (self):
        if not self.__cachedExpectedResults:
            self.__cachedExpectedResults = self.doExpectedResults ()
        return self.__cachedExpectedResults
        
    def doExpectedResults (self):
        """ Returns True if the command could run as expected with the correct
            outputs being produced, False otherwise.
        """
        assert (False and "Please implement doExpectedResults in derived class.")
        
    def nonExpectedExecution (self):
        """ Return a string to be printed when the execution should have not
            happened, but it did.
        """
        assert (False)
    def missingExecution (self):
        """ Returns a string to be printed when the execution should have
            happened, but it did not.
        """
        assert (False)

    def producesStuffToUpload (self):
        """ Can be overridden to return True if the execution of the action 
            will produce stuff that is then uploaded.
        """
        return False
    actionName = property (lambda self : self._actionName)

class SourcesDownload (BuilderAction):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__ (self, pkg, parent, prevAlternative)
        self._actionName = "Download sources"

    def doDryRun (self):
        return True
    
    def doExpectedResults (self):
        remoteSourcesRE = re.compile (".*:.*/.*")
        self.files = []
        for source in self.pkg.sources:
            if remoteSourcesRE.match (source):
                self.files.append (join ("SOURCES", self.pkg.pkgdir, 
                                         source.rsplit("/", 1)[1]))
            else:
                self.files.append (join ("SOURCES", self.pkg.pkgdir,
                                         basename(source).rsplit(".", 1)[0]))
        self.missingFiles = [ abspath (filename)
                              for filename in self.files
                              if not exists (filename) ]
        return self.missingFiles == []
    
    def nonExpectedExecution (self):
        unexpectedFiles = "\n".join ([ filename
                                       for filename in self.files
                                       if exists (filename)])
        return "I was not expecting to find the following files:\n %(unexpectedFiles)s" % locals ()
    
    def missingExecution (self):
        missingFiles = "\n".join (self.missingFiles)
        return "I was expecting the following files: \n %(missingFiles)s" % locals ()
    
class InstallFromLocalArea (BuilderAction):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__ (self, pkg, parent, prevAlternative)
        self._actionName = "Install from local area"

    def doDryRun (self):
        """ Return True if there are the rpms ready to be installed.
        """
        # If the area is not bootstrapped, this should not run.
        self.cachedRpmName = join (self.pkg.rpmdir, self.pkg.rpmfilename)
        self.officialRpmName = join (abspath ("RPMS"), self.pkg.rpmfilename)
        if not self.pkg.options.bootstrap:
            return False
        # Otherwise make sure that the packages are there.
        filesExist = exists (self.cachedRpmName) and exists (self.officialRpmName)
        return filesExist 
        
    def doExpectedResults (self):
        """We expect to see the rpm installed in the database, and the files in RPMS"""
        # If we ran this action, we expected rpms to be installed in the db and files 
        # to be there.
        if not self.dryRun ():
            return False 
        pkgName = self.pkg.pkgName ()
        error, output = getstatusoutput ("%s ; rpm -q %s" % (rpmEnvironmentScript, pkgName))
        # Not all the rpm commands set the error correctly.
        if error or "error:" in output:
            return False
        filesExists = exists (self.cachedRpmName) and exists (self.officialRpmName)
        lines = output.strip ("\n").split ("\n")
        tooManyLines = len (lines) != 1
        if tooManyLines and filesExists:
            return False
        firstLine = lines[0].strip ()
        if not firstLine:
            return False
        if firstLine and firstLine.replace (pkgName, "")[0] != "-" and filesExists:
            return False
        return True
    
    def nonExpectedExecution (self):
        pkgName = self.pkg.pkgName ()
        officialRpmName = self.officialRpmName 
        return "%(pkgName)s was installed from %(officialRpmName)s although no installation can happen from the local area." % locals ()
    
    def missingExecution (self):
        pkgName = self.pkg.pkgName ()
        officialRpmName = self.officialRpmName 
        return "I was expecting %(pkgName)s to be installed using %(officialRpmName)s but it was not." % locals ()
        

class InstallFromServer (BuilderAction):
    def __init__ (self, pkg, parent, prevAlternative):
        BuilderAction.__init__ (self, pkg, parent, prevAlternative)
        self.called = False
        self._actionName = 'Install from server'
          
    def doDryRun (self):
        """ Return True if the package is on server
        """
        if not self.pkg.options.bootstrap:
            return False
        self.called = True
        pkgName     = self.pkg.pkgName ()
        pkgInfo     = PkgInfo (self.pkg)
        pkgRealName = pkgInfo.id()
        pkgsWithSameHash = [p for (p,h) in tags_cache.cache.iteritems() if (h == pkgInfo.checksum) and p.startswith(pkgRealName) and (pkgName != p) ]

        # If a file exists on server we return True
        cmsPkgCmd = CMSPKG_CMD
        rpmenv =  rpmEnvironmentScript
        pkgRev = self.pkg.pkgRevision
        searchCommand = """%(cmsPkgCmd)s showpkg %(pkgName)s; %(rpmenv)s ; rpm -q %(pkgName)s-1-%(pkgRev)s""" % locals ()
        error, output = getstatusoutput (searchCommand)
        self.output = output.split("\n")
        if error: return False
        def evalExistsOnServer ():
            for line in self.output[2:]:
               if line.startswith("1-%s." % pkgRev): return True
            return False
        return pkgsWithSameHash or evalExistsOnServer ()
    
    def doExpectedResults (self):
        # In order for a download to be successful we expect:
        # 1) to find it on server
        # 2) to find it on client
        # 3) not to find the rpm in RPMS
        if not self.called:
            return False
        
        def onServerAndLocal ():
            if not self.output[0].startswith(self.pkg.pkgName()+' - CMS Experiment package'): return False
            return self.output[-1].startswith("%s-1-%s." % (self.pkg.pkgName(),self.pkg.pkgRevision))
        rpmInstalled = onServerAndLocal ()
        rpmFilename = join (abspath (self.pkg.rpmdir), self.pkg.rpmfilename)
        return rpmInstalled and not exists (rpmFilename) 
    
    def nonExpectedExecution (self):
        pkgName = self.pkg.pkgName ()
        return """I was not expecting to download %(pkgName)s from server 
                  but it looks like I can.
                  Probably you need to run:
                  
                  cmsBuild deprecate-local %(pkgName)s """ % locals ()
   
    def missingExecution (self):
       pkgName = self.pkg.pkgName ()
       return """ I was expecting to be able to download %(pkgName)s from server, 
                  but I can't. Are you sure you don't need to rebuild it?""" % locals ()


class BuildPackage (BuilderAction):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__ (self, pkg, parent, prevAlternative)
        self._actionName = 'Build Package'
        
    def doDryRun (self):
        """ The only requirement for a package to be built apart from sources 
            being there and no other alternatives (installing from sever) is that
            the specfile for it exists.
            For a subpackage, check the parent's specfile.
        """
        pkg = self.pkg
        if pkg.name == "system-compiler":
            return False
        if pkg.parent:
            specfilename = join (pkg.parent.options.cmsdist, "%s.spec" % pkg.parent.name)
        else:
            specfilename = join (pkg.options.cmsdist, "%s.spec" % pkg.name)
        return exists (specfilename)
    
    def doExpectedResults (self):
        if self.pkg.name == "system-compiler":
            return False
        cachedRpmName = join (self.pkg.rpmdir, self.pkg.rpmfilename)
        return exists (cachedRpmName)
    
    def nonExpectedExecution (self):
        pkgName = self.pkg.pkgName ()
        return "I would have not expected %(pkgName)s to be built, but it was." % locals ()
    
    def missingExecution (self):
        pkgName = self.pkg.pkgName ()
        return "I would have expected a local build of %(pkgName)s but that did not happen." % locals ()
    
    def producesStuffToUpload (self):
        """ A package that gets built will always produce stuff to upload.
        """
        return True

class BuildSystemCompiler (BuilderAction):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__ (self, pkg, parent, prevAlternative)
        self._actionName = 'Build system compiler'
        
    def doDryRun (self):
        """ The only case we build the system compiler is the case in which the 
            name matches the dummy package.
        """
        if self.pkg.name != "system-compiler":
            return False
        return self.pkg.options.systemCompiler
    
    def doExpectedResults (self):
        return self.pkg.name == "system-compiler" 
    
    def nonExpectedExecution (self):
        return "I was not expecting to use the system compiler."
    
    def missingExecution (self):
        return "I was expecting to use the system compiler."

class LinkPackageFromCache (BuilderAction):
    def __init__ (self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__ (self, pkg, parent=None, prevAlternative=None)
        self._actionName = 'Create links for rpm'
        self.called = False
        
    def doDryRun (self):
        """ We always expect to be able to run the link, if the building
            was possible. Since the building is actually performed by a 
            parent action we always return True and make sure we have a
            BuildAction as parent.
        """
        self.cachedRpmName = join (self.pkg.rpmdir, self.pkg.rpmfilename)
        self.officialRpmName = join (abspath ("RPMS"), self.pkg.rpmfilename)
        self.called = True
        if not exists (self.cachedRpmName):
            return False
        return True
    
    def doExpectedResults (self):
        """ We expect the link to exists, to be readable, and to point to a
            an RPM which has the same checksum as the package associated to
            this action.
        """
        if not self.called:
            return False
        if not exists (self.officialRpmName):
            return False
        checksum = getPkgChecksumFile (self.officialRpmName, self.pkg.options)
        return self.pkg.checksum == checksum

    def nonExpectedExecution (self):
        officialRpmName = self.officialRpmName
        cachedRpmName = self.cachedRpmName
        return """A link was found in %(officialRpmName)s but it points to the
                  wrong rpm %(cachedRpmName)s""" % locals ()
               
    def missingExecution (self):
        officialRpmName = self.officialRpmName
        cachedRpmName = self.cachedRpmName
        return """A link was expected from %(officialRpmName)s to %(cachedRpmName)s, but it not found. """ % locals ()

def detectCompilerVersion (compilerName):
    (error, version) = getstatusoutput(COMPILER_DETECTION[compilerName])
    if error:
        raise UnknownCompiler ()
    return version.strip ("\n")

class ChecksumCalculator (object):
    def __init__ (self):
        self.__adder = md5adder ()
        self.__checksums = {}
    
    def addString (self, string):
        self.__adder.update (string)
    
    def addStrings (self, stringList):
        self.__adder.update ("".join (stringList))

    def addFile (self, filename):
        assert (filename[0] == "/")
        if checksums_cache.has_key (filename):
            self.__checksums[filename] = checksums_cache[filename]
            return
        if not exists (filename):
            raise FileNotFound (filename)
        f = open (filename)
        m = md5adder (f.read ())
        f.close ()
        checksum = m.hexdigest ()
        checksums_cache[filename] = checksum
        self.__checksums[filename] = checksum
        
    def addPkg (self, pkg):
        if pkg.name == "system-compiler":
            filename = pkg.name
        else:
            filename = specFilename (pkg.options, pkg.name)
        self.__checksums[filename] = pkg.checksum
        
    def getChecksum (self):
        items = self.__checksums.items ()
        items.sort ()
        for key, value in items:
            self.__adder.update (value)
        return self.__adder.hexdigest ()

class SubPackage (object):
    def __init__ (self, parent, name):
        self.subname        = name
        self.parent         = parent
        self.subpackages    = []
        self.sources        = []
        #self.updateFromParent()

    def updateFromParent (self):
        self.name           = '%s-%s' % (self.parent.name, self.subname)
        self.group          = self.parent.group
        self.version        = self.parent.version
        self.realVersion    = self.parent.realVersion
        self.pkgRevision    = self.parent.pkgRevision
        self.pkgrel         = self.parent.pkgrel
        self.pkgdir         = self.parent.pkgdir
        self.options        = self.parent.options
        self.cmsplatf       = self.parent.cmsplatf
        self.workDir        = self.parent.workDir
        self.installDir     = self.parent.installDir
        self.tempDirPrefix  = self.parent.tempDirPrefix
        self.builddir       = self.parent.builddir
        self.sourcedir      = self.parent.sourcedir
        self.specdir        = self.parent.specdir
        self.checksum       = self.parent.checksum
        self.requires       = [ self.parent.pkgName() ]
        self.dependencies   = [ self.parent ] + self.parent.dependencies
        self.origDependencies = [ self.parent ] + self.parent.origDependencies
        self.buildDependencies = [ self.parent ] + self.parent.buildDependencies
        self.origBuildDependencies = [ self.parent ] + self.parent.origBuildDependencies
        self.fullDependencies = [ self.parent ] + self.parent.fullDependencies
        self.dependentCounter = 0
        self.patches        = self.parent.patches
        self.rpmdir         = self.parent.rpmdir
        self.rpmfilename    = '%s/%s+%s+%s-%s-%s.%s.rpm' % (self.cmsplatf, self.group, self.name, self.version, '1', self.pkgRevision, self.cmsplatf)
        self.srpmfilename   = self.parent.srpmfilename
        self.pkginstroot    = self.parent.pkginstroot

    def dumpSpecFragment(self, computeSpecChecksum = True):
        importName = 'subpackage-%s.file' % self.subname
        importFilename = join (self.options.cmsdist, importName)
        spec = open (importFilename, 'r').read()
        if computeSpecChecksum:
          spec = re.compile(r'^(Summary:.*?)( SpecChecksum:.*|)$', re.M).sub(r'\g<1> SpecChecksum:%s' % self.checksum, spec)
        return spec

    def pkgName (self):
        return "%(group)s+%(name)s+%(version)s" % self.__dict__

    def rpmLocation(self):
        # make sure all the information is available, otherwise update from the parent package
        if not self.rpmdir or not self.rpmfilename:
            self.updateFromParent()
        return join(self.rpmdir, self.rpmfilename)

    def dumpCmsos (self):
        self.parent.dumpCmsos()

    def __repr__ (self):
        return "<SubPackage name=%(name)s>" % self.__dict__
    
    def __eq__ (self, other):
        """ Two (sub)packages are the same if they have the same name"""
        return type (other) == SubPackage and self.name == other.name
    
    def __ne__ (self, other):
        return not self.__eq__ (other)

    # FIXME write a single implementation for both Package and SubPackage    
    def __cmp__ (self, other):
        """ Subpackage A is greater than package B if A is a subpackage of B.
            Two subpackages of the same package are sorted by name, 
            while two subpackages of different packages have the same 
            ordering as their parent packages.
            A subpackage and an unrelated package have the same order as the
            subpackage's parent and the other package.
        """
        if self.parent == other:
            return 1
        elif self.parent == other.parent:
            return cmp(self.name, other.name)
        elif other.parent is None:
            return cmp(self.parent, other)
        else:
            return cmp(self.parent, other.parent)


class Package (object):
    tmpspec = property (lambda self : self.__getTmpSpecName ())
    preamble = property (lambda self : self.__preamble)
    sectionOptions = property (lambda self : self.__sectionOptions)
    sectionPreambles = property (lambda self : self.__sectionPreambles)
    sectionPostambles = property (lambda self : self.__sectionPostambles)
    sourcedir = property (lambda self : self.__getSourcedir ())
    specdir = property (lambda self : self.__getSpecdir ())
    pkgdir = property (lambda self : self.__getPkgdir ())

    def __init__ (self, options):
        self.workDir = options.workDir
        self.installDir = options.installDir
        self.tempDirPrefix = options.tempDirPrefix
        # FIXME: actually detect gcc.
        self.compilerRealVersion = ""
        self.name = ""
        self.realVersion = ""
        self.group = ""
        self.version = ""
        self.summary = "CMS Experiment package"
        self.license = "As defined by package owner"
        self.subname = ""
        self.parent = None
        self.subpackages = []
        self.env = ""
        self.urls = []
        self.requires = []
        self.imports = []
        self.buildrequires = []
        self.sources = []
        self.patches = []
        self.pkgreqs = "%{nil}"
        self.directpkgreqs = "%{nil}"
        self.buildCondition = None
        self.builddir = None
        self.pkginstroot = None
        self.pkgrel = None
        self.__specdir = None
        self.cmsplatf = options.architecture 
        self.rpmdir = None
        self.rpmfilename = None
        self.srpmfilename = None
        self.pkgRevision = '1'
        self.specPreHeader = ""
        #For online: pkgRevision is always architecture
        if isOnline(self.cmsplatf): self.pkgRevision += '.'+self.cmsplatf
        self.rpmVersion = "1"
        self.requiresStatement = "Requires: gcc"
#  PG This could eventually be use to allow system clang as the default compiler
#        if sys.platform == 'darwin': self.requiresStatement = ""
        self.sections = {}
        self.dependentCounter = 0 
        self.__sectionOptions = None
        self.__sectionPreambles = None
        self.__sectionPostambles =  None

        self.dependencies = []
        self.origDependencies = []
        self.buildDependencies = []
        self.origBuildDependencies = []
        self.fullDependencies = []
        self.origSpec = []
        self.spec = []
        self.checksum = "%{nil}"
        self.options = options
        self.status = None
        self.__packageCache = None 
        self.__requiresCache = None
        self.__syntax = None
        self.__preamble = ""
        self.buildRequireToolfile = False
   
    def rpmLocation(self):
        return join(self.rpmdir, self.rpmfilename)
    
    def createDefaultSections (self):
        if self.options.skipPreInstall == True:
            log  ("Skip preinstall check: " + str(self.options.skipPreInstall), DEBUG)
            replacement="""
# Built with an option to skip CMS default pre-install checks
"""
            DEFAULT_SECTIONS['%pre']=replacement
        for section in DEFAULT_SECTIONS.keys ():
            self.sections[section] = {}
            self.sections[section][''] = DEFAULT_SECTIONS[section]
            #FIXME: This is to avoid trigger a rebuild. This overrides the %files section
            #For any release series which is going to trigger a rebuild please fix DEFAULT_SECTIONS[%file]
            #to have only %{installroot}/ and remove next 2 lines.
            if section == "%files":
                self.sections[section][''] = '%{installroot}/'
            self.sections[section][''] += self.sectionPostambles[section]
            if section=="%post" and self.options.buildWithRpath: self.sections[section][''] += DEFAULT_RPATH_PREAMBLE
    
    def initWithSpec (self, specLines):
        """ This parses the spec files and creates a structure with its contents.
        """
        self.origSpec = specLines
        self.group, self.name, self.realVersion = parseRPMLine (self.origSpec, self.options)
        self.version = self.realVersion
        self.parseRevision ()
        compilerName = self.options.compilerName
        self.compilerName = compilerName
        self.expandSpec ()
        if self.name == compilerName:
            self.requiresStatement = ""
            self.compiler = self
        else:
            if self.__packageCache.has_key (compilerName):
                self.compiler = self.__packageCache[compilerName]
            else:
                if self.options.systemCompiler == True:
                    self.compiler = self.__factory.create ()
                    self.compiler.name = "system-compiler"
                    version = detectCompilerVersion (compilerName)
                    self.compilerRealVersion = version
                    self.compiler.realVersion = version
                else:
                    self.compiler = self.__factory.createWithSpec (compilerName)
                    self.compilerRealVersion = self.compiler.realVersion
                self.__packageCache[compilerName] = self.compiler
            if self.options.systemCompiler == False and parseNoCompilerLine(self.spec) == False:
                self.dependencies.append (self.compiler)
                self.origDependencies.append (self.compiler)
        self.buildRequireToolfile = parseBuildRequireToolfileLine(self.spec)
        self.fullDependencies += self.dependencies
        self.compilerRealVersion = self.compiler.realVersion
        self.generateInitEnv ()
        self.createDefaultSections ()
        self.parseSections ()
        self.dumpSpec ()
        self.dumpCmsos ()
        self.origRequires, self.sources, self.patches, self.origBuildRequires = self.getRequiresAndSources ()
        self.parseRequires ()
        self.dumpSpec ()
        # FIXME: saveSpec should really be done once.
        createDirs (architecture=self.cmsplatf)
        self.calculateChecksum ()
        self.rewriteRequires ()
        self.dumpSpec ()
        prepareSaveSpec (self)
        saveSpec (self)
        result = self.rpmEvalStrings ("%pkgrel", 
            "%pkginstroot", 
            "%_builddir", 
            "%_specdir",
            "%_rpmdir", 
            "%_rpmfilename",
            "%_srpmfilename")
        assert (result)
        try:
            [self.pkgrel, self.pkginstroot, self.builddir, 
             self.__specdir, self.rpmdir, 
             self.rpmfilename, self.srpmfilename ] = result
        except ValueError, e:
            log ("FATAL: Error unpacking results: \n%s" % result)
            raise e
        # update subpackages
        for subpackage in self.subpackages:
            subpackage.updateFromParent()
        
    def parseRevision (self):
        for line in self.origSpec:
            match = self.__syntax.REVISION.match (line)
            if match:
                self.pkgRevision = match.group(1)
                if isOnline(self.cmsplatf): self.pkgRevision += '.'+self.cmsplatf
                return True
        return False

    def expandSpec (self):
        """This function is responsible for finding and parsing all the IMPORT and SUBPACKAGE directives for a given spec.
        """
        imports = []
        subpackages = {}
        self.subpackages = []
        for line in self.origSpec:
            imatch = self.__syntax.IMPORT.match (line)
            smatch = self.__syntax.SUBPACKAGE.match (line)
            if imatch:
                imports.append (imatch.group (1).strip (" \n") + ".file")
            elif smatch:
                subpackages[smatch.group(1)] = smatch.group(3)
            else:
                self.spec.append (line)
        try:
            for importName in imports:
                importFilename = join (self.options.cmsdist, importName)
                self.spec.extend (open (importFilename).readlines ())
                self.imports.append (importFilename) 
        except IOError, e:
            raise FileNotFound (importFilename)

        # Check for sub-packages after all processing all the imports
        for subpackageName in subpackages:
            condition = subpackages[subpackageName]
            if not condition or self.isSymbolDefined(condition):
                self.subpackages.append( SubPackage(self, subpackageName) )

    def isSymbolDefined(self, symbol):
        """This function checks if a symbol is defined in the current spec file. That is, if rpmbuild evaluates %symbol to a non-empty string. 
        Note: I *think* that only the symbols defined in the main section are visible here.
        """
        tmp = copy.copy(self)
        tmp.createDefaultSections()
        tmp.parseSections()
        value = tmp.rpmEvalStrings(symbol)
        isDefined = (value != symbol)
        return isDefined

    def parseSections (self):
        """ This helper method is responsible for parsing the spec and create subdivide sections found inside it.
        """
        currentSection = ''
        currentSubSection = ''
        SECTION_MATCH="(%s)[$\s]+(.*)" % "|".join (self.sections.keys ()).strip ('|')
        sectionRe = re.compile (SECTION_MATCH)
        for line in self.spec:
            match = sectionRe.match (line)
            if match:
                # Close the previous section and open a new one.
                self.sections[currentSection][currentSubSection] += self.sectionPostambles[currentSection]
                currentSection, currentSubSection = match.groups ()
                self.sections[currentSection][currentSubSection] = self.sectionPreambles[currentSection]
            else:
                self.sections[currentSection][currentSubSection] += line
        self.sections[currentSection][currentSubSection] += self.sectionPostambles[currentSection]
        if "%post" in self.sections and self.options.buildWithRpath: self.sections["%post"][''] += DEFAULT_RPATH_PREAMBLE
        
        # If no BUILDIF conditions we are done. 
        # Otherwise insert the build condition everywhere, so that sections 
        # are not actually executed.
        if not self.buildCondition:
            return
        
        for section in ["%install", "%build"]:
            for subsection in self.sections[section].keys ():
                old = self.sections[section][subsection]
                self.sections[section][subsection] = old.replace ("%initenv", 
                                                                  "%s || exit 0\n%%initenv\n" % self.buildCondition)
        for section in ["%pre", "%post", "%preun", "%postun"]:
            for subsection in self.sections[section].keys ():
                old = self.sections[section][subsection]
                self.sections[section][subsection] = "%s || exit 0\n" % self.buildCondition + old

    def calculateChecksum (self):
        """ 
        """
        checksumCalculator = ChecksumCalculator ()
        
        if self.checksum != "%{nil}":
            return
        # In the case --use-system-compiler option is specified, the compiler itself
        # is called "system-compiler" and the checksum is given by its version rather
        # than the spec.
        # FIXME: add more sensible stuff to the checksum, besides the version (maybe the 
        # gcc specfile???) 
        if self.name == "system-compiler":
            checksumCalculator.addString (self.compilerRealVersion)
            self.checksum = checksumCalculator.getChecksum ()
            self.version = calculateHumanReadableVersion (self)
            return 

        checksumCalculator.addStrings (self.origSpec)
        checksumCalculator.addStrings (DEFAULT_SECTIONS.values ())
        checksumCalculator.addStrings (self.sectionOptions.values ())    
        checksumCalculator.addStrings (self.sectionPreambles.values ())    
        checksumCalculator.addStrings (self.sectionPostambles.values ())
        if self.options.buildWithRpath: checksumCalculator.addStrings (DEFAULT_RPATH_PREAMBLE)
        
            
        for filename in self.imports:
            checksumCalculator.addFile (abspath (filename))

        for subpackage in self.subpackages:
            checksumCalculator.addString( subpackage.dumpSpecFragment(not self.options.repository.split('.')[0] == "comp") )

        for pkg in self.dependencies:
            checksumCalculator.addPkg (pkg)
        for pkg in self.buildDependencies:
            checksumCalculator.addPkg (pkg)
        remotefileRE = re.compile (".*:.*/.*")
        for patch in self.patches:
            if remotefileRE.match (patch):
               continue
            filename = join (abspath (self.options.cmsdist), patch)
            checksumCalculator.addFile (filename)
        for source in self.sources:
            if remotefileRE.match (source):
               continue 
            filename = join (abspath (self.options.cmsdist), source)
            if exists (filename):
                checksumCalculator.addFile (filename)
        # FIXME: should we add downloaded sources checksums to the global checksum? This is actually
        #        tricky because at the moment the sources are downloaded *after* the checksums
        #        are calculated and they are put in a directory which has the global checksum in
        #        the name. We could fetch sources first and drop the global checksum from the 
        #        sources download dir, but this means that we will be using always the same 
        #        directory for the sources, even if they might be different (for example when downloading them from cvs). 
        self.checksum = checksumCalculator.getChecksum ()
        self.version = calculateHumanReadableVersion (self)
        if self.name == self.options.pipPackage:
          global pip_package_env_script
          pip_package_env_script = join(self.options.workDir,self.cmsplatf,self.group,self.name,self.version,"etc/profile.d/init.sh")

    def generateRequires (self, dependencies, origDependencies):
        requiresPkgs = [ "%s+%s+%s" % (pkg.group, pkg.name, pkg.version) 
                         for pkg in dependencies
                         if pkg.name != "system-compiler" ]
        pkgreqsPkgs = [ "%s/%s/%s " % (pkg.group, pkg.name, pkg.version) 
                        for pkg in dependencies
                        if pkg.name != "system-compiler" ]
        directpkgreqsPkgs = [ "%s/%s/%s " % (pkg.group, pkg.name, pkg.version) 
                        for pkg in origDependencies
                        if pkg.name != "system-compiler" ]
        requiredtoolsPkgs = [ pkg.name
                              for pkg in dependencies
                              if pkg.name != "system-compiler" ]
        requires = " ".join (requiresPkgs)
        pkgreqs = " ".join (pkgreqsPkgs)
        directpkgreqs = " ".join (directpkgreqsPkgs)
        requiredtools = " ".join (requiredtoolsPkgs)
        if not pkgreqs:       pkgreqs       = "%{nil}"
        if not directpkgreqs: directpkgreqs = "%{nil}"
        if not requiredtools: requiredtools = "%{nil}"
        return (requires, pkgreqs, directpkgreqs, requiredtools)

    def rewriteRequires (self):
        """ This rewrites both the Requires line to specify dependencies and
            sets the pkgreq to point to their path.
        """
        requires, pkgreqs, directpkgreqs, requiredtools = self.generateRequires(self.dependencies, self.origDependencies)
        bldrequires, bldpkgreqs, blddirectpkgreqs, bldrequiredtools = self.generateRequires(self.origBuildDependencies, self.origBuildDependencies)
        allDepsPkgs = " ".join([ "%s/%s/%s " % (pkg.group, pkg.name, pkg.version) 
                        for pkg in self.fullDependencies
                        if pkg.name != "system-compiler" ])
        if not allDepsPkgs: allDepsPkgs = "%{nil}"
        #After rewrite of Requires we split pkgeqs and directpkgreqs to avoid RPM macro length limit
        specPre1, pkgreqs          = redefineMacro("pkgreqs",           pkgreqs)
        specPre2, requiredtools    = redefineMacro("requiredtools",     requiredtools)
        specPre3, directpkgreqs    = redefineMacro("directpkgreqs",     directpkgreqs)
        specPre4, bldpkgreqs       = redefineMacro("buildpkgreqs",      bldpkgreqs)
        specPre5, bldrequiredtools = redefineMacro("buildrequiredtools",bldrequiredtools)
        specPre6, blddirectpkgreqs = redefineMacro("builddirectpkgreqs",blddirectpkgreqs)
        specPre7, allDepsPkgs      = redefineMacro("allpkgreqs",        allDepsPkgs)

        requires      = "\nRequires: ".join(splitMacroLine(requires))
        bldrequires   = "\nBuildRequires: ".join(splitMacroLine(bldrequires))
        reqStatement  = "%%define requiredtools %(requiredtools)s\n%%define buildrequiredtools %(bldrequiredtools)s\n" 
        reqStatement += "%%define buildpkgreqs %(bldpkgreqs)s\n%%define builddirectpkgreqs %(blddirectpkgreqs)s\n"
        reqStatement += "%%define allpkgreqs   %(allDepsPkgs)s\n"
        if requires:
            reqStatement += "Requires: %(requires)s\n"
        if bldrequires:
            reqStatement += "BuildRequires: %(bldrequires)s\n"
        self.pkgreqs           = pkgreqs
        self.directpkgreqs     = directpkgreqs
        self.requiresStatement = reqStatement % locals()
        self.specPreHeader     = specPre1 + specPre2 + specPre3 + specPre4 + specPre5 + specPre6 + specPre7
        
    def updateChildDependencies (self, pkg, dependencies, pkgdeps):
        if not pkg in dependencies: dependencies.insert (0, pkg)
        for subdep in pkgdeps:
            if not subdep in dependencies: dependencies.insert (0, subdep)
        return

    def updateDependencies (self, require, origDependencies, dependencies, buildRequires=False):
        if self.__packageCache.has_key (require):
            pkg = self.__packageCache[require]
        else:
            pkg = self.__factory.createWithSpec (require)
            self.__packageCache[require] = pkg
        origDependencies.insert (0, pkg)
        self.updateChildDependencies(pkg, dependencies, pkg.dependencies)
        if buildRequires:
            self.updateChildDependencies(pkg, dependencies, pkg.buildDependencies)

    def parseRequires (self):
        """This function is responsible for finding all the required dependencies for a given spec.
           We recursively create dependend Packages or we pick them from the package_cache if needed.
           The dependencies of the dependent Packages are added to the dependency list of the parent,
           so that each Package has the full list of dependent packages. If a dependency is already there
           in the list, it gets "bubbled", so that more fundamental dependencies will come first in the
           list.
        """
        for require in self.origRequires:
            self.updateDependencies(require, self.origDependencies, self.dependencies)
        if self.buildRequireToolfile:
            deps = self.dependencies[:]
            for pkg in deps:
                dep = pkg.name
                if not dep.endswith("-toolfile"):  continue
                if not self.__packageCache.has_key(dep.replace("-toolfile","")): continue
                if not dep in self.origBuildRequires: self.origBuildRequires.append(dep)
                if pkg in self.origDependencies: self.origDependencies.remove(pkg)
                self.dependencies.remove(pkg)
        for require in self.origBuildRequires:
            self.updateDependencies(require, self.origBuildDependencies, self.buildDependencies, True)
        for dep in self.dependencies:
            if dep in self.origBuildDependencies: self.origBuildDependencies.remove(dep)
            if dep in self.buildDependencies:     self.buildDependencies.remove(dep)
        self.fullDependencies = self.dependencies + self.buildDependencies
        for dep in self.fullDependencies:
            dep.dependentCounter += 1
        self.dependencies.sort()
        self.origDependencies.sort()
        self.buildDependencies.sort()
        self.origBuildDependencies.sort()
        self.fullDependencies.sort()

    def dumpSpec (self, saveScripts=False):
        self.spec = "\n".join([self.specPreHeader, 
                               SPEC_HEADER % self.__dict__, 
                               self.preamble])
        for section in self.sections.keys ():
            for subsection in self.sections[section].keys ():
                sectionContents = self.sections[section][subsection].strip ("\n ")
                if sectionContents:
                  if saveScripts and (section in ["%build","%install","%prep"]) and (subsection==""):
                    secScript="cmsdist-%s.sh" % section[1:]
                    sectionContents = "cat $0 | grep -v '%%_builddir/%s' > %%_builddir/%s\n%s" % (secScript,secScript,sectionContents)
                  self.spec += "\n\n%s %s %s\n" % (section, subsection, self.sectionOptions[section])
                  self.spec += sectionContents
        self.spec = self.__factory.postProcessSpec (self.spec)

        for subpackage in self.subpackages:
            subpackage.updateFromParent()
            self.spec += '\n\n' + subpackage.dumpSpecFragment()

    def __getTmpSpecName (self):
        # FIXME: make this static? Should not change over the whole period.
        return join (abspath (self.tempDirPrefix), "tmpspec-%s" % self.name)
        
    def rpmEvalStrings (self, *strings):
        self.spec = "\n".join ([self.specPreHeader,
                                SPEC_HEADER % self.__dict__,
                                self.preamble,
                                self.sections[''][''],
                                "%description"] + list (strings)) 
        f = file (self.tmpspec, "w")
        f.write (self.__factory.postProcessSpec (self.spec).replace('%%', '%'))
        f.close ()
        commandPrefix = getCommandPrefix (self.options)
        evalCommand = "%s ; %s rpm -q --specfile %s --info %s" % (rpmEnvironmentScript, commandPrefix,
                                                      self.tmpspec, self.options.rpmQueryDefines)
        log (evalCommand, DEBUG)
        error, output = getstatusoutput (evalCommand)
        if error:
            log ("FATAL: malformed spec found while quering it. Command: ")
            log (evalCommand)
            log ("Resulted in:\n\n%s" % output)
            raise MalformedSpec (self.tmpspec)
        log (output, DEBUG)
        #This allows us to build packages which have 'Description' as a part of their name.
        description = re.split ("Description\s*:",output,1)[1]
        results = [line for line in description.split ("\n")][1:]
        return (len (results) == 1 and results[0]) or results

    def __getPkgdir (self):
        return join (self.group, self.name, self.version)
    
    def __getSourcedir (self):
        return join (abspath ("SOURCES"), self.pkgdir)

    def __getSpecdir (self):
        return join (abspath ("SPECS"), self.pkgdir)
    
    def specFilename (self):
        return join (self.specdir, "spec")

    def finalSpecFilename (self):
        return join (abspath ("SPECS"), self.pkgdir, "spec")

    def pkgName (self):
        return "%(group)s+%(name)s+%(version)s" % self.__dict__

    def rpmCachePath (self):
        return join (abspath ("RPMS/cache"), self.checksum, self.rpmfilename)

    def generateInitEnv (self):
        """ Parses the spec file and generates the code for init.sh/init.csh
        """
        self.initSh = """cat <<\EOF_INIT_SH > %i/etc/profile.d/init.sh\n"""        
        self.initCsh = """cat <<\EOF_INIT_CSH > %i/etc/profile.d/init.csh\n"""

        upperNameDict = {"uppername": self.name.upper ().replace ("-", "_")}

        if self.name == "gcc":
            self.initSh += COMMANDS_SH["+PATH"] % {"var": "PATH", "value": "%{i}/bin-real"}
            self.initCsh += COMMANDS_CSH["+PATH"] % {"var": "PATH", "value": "%{i}/bin-real"}
        for command, var, value in INITENV_PREAMBLE:
            self.initSh += COMMANDS_SH[command] % {"var": var % upperNameDict, "value": value}
            self.initCsh += COMMANDS_CSH[command] % {"var": var % upperNameDict, "value": value}            
            
        for line in self.spec:
            match = self.__syntax.INITENV.match (line)
            if match:
                command, var, value = [x.strip (" \t") for x in match.groups ()]
                self.initSh += COMMANDS_SH[command] % {"var": var, "value": value}
                self.initCsh += COMMANDS_CSH[command] % {"var": var, "value": value}
            buildifMatch = self.__syntax.BUILDIF.match (line)
            if not self.buildCondition and buildifMatch:
                self.buildCondition = buildifMatch.group (1)
        self.initSh += "\nEOF_INIT_SH\n"
        self.initCsh += "\nEOF_INIT_CSH\n"
        self.__createProfileDScript = "mkdir -p %i/etc/profile.d\n"
        self.sectionPostambles["%install"] += "\n".join ([self.__createProfileDScript,
                                                          self.initSh,
                                                          self.initCsh])

    def getFinalSpec (self):
        self.dumpSpec (saveScripts=True)
        return self.spec
    
    def dumpCmsos (self):
        if not exists (self.sourcedir):
            makedirs (self.sourcedir)
        self.__cmsosDumper.dump (self.sourcedir)
    
    def __repr__ (self):
        return "<Package name=%(name)s>" % self.__dict__
    
    def __eq__ (self, other):
        """ Two packages are the same if they have the same name"""
        return type (other) == Package and self.name == other.name
    
    def __ne__ (self, other):
        return not self.__eq__ (other)
    
    def __cmp__ (self, other):
        """ Package A is greater than package B if
            Package A depends on package B.
            Moreover, if A does not depend B and viceversa, the one with less dependent
            packages greater first. If they have the same number of dependent packages, the
            one with less dependencies is said to be greater. 
        """
        moredeps = cmp (len (self.fullDependencies), len (other.fullDependencies))
        lessdependent = cmp (other.dependentCounter, self.dependentCounter)
        if self in other.fullDependencies:
            return -1
        elif other in self.fullDependencies:
            return 1
        elif lessdependent:
            return lessdependent
        elif moredeps:
            return moredeps
        else:
            return cmp (self.name, other.name)
    
    def getRequiresAndSources (self, subpackage=''):
        if self.__requiresCache.has_key (self.name):
            return self.__requiresCache[self.name]
        spec = file (self.tmpspec, "w")
        text = "\n".join([self.specPreHeader,
                          SPEC_HEADER % self.__dict__,
                          self.__factory.postProcessSpec (self.preamble),
                          "%%description",
                          self.__factory.postProcessSpec (self.sections[''][subpackage])])
        spec.write (text)
        spec.close ()
        deps = []; sources = [] ; patches = []
        localSources = []
        localPatches = []
        buildDeps    = []
        queryCommand = "%s ; %s rpm -q --info --specfile %s %s 2>/dev/null" % (rpmEnvironmentScript, getCommandPrefix (self.options),
                                                                  self.tmpspec, self.options.rpmQueryDefines)
        regexps = self.__headerMatchingRegexp
        matchers = [(regexps.REQUIRES_REGEXP, deps),
                    (regexps.REMOTE_SOURCE_REGEXP, sources),
                    (regexps.REMOTE_PATCH_REGEXP, patches),
                    (regexps.LOCAL_SOURCE_REGEXP, localSources),
                    (regexps.LOCAL_PATCH_REGEXP, localPatches),
                    (regexps.BUILD_REQUIRES_REGEXP, buildDeps)]
        for line in popen (queryCommand).readlines ():
            line = re.sub ("[\s]+", " ", line).strip ("\n\t ")
            for rule, target in matchers:
                match = rule.match (line)
                if not match:
                    continue
                target.extend ([element 
                                for element in match.group (1).split ()])
                break
        cmsdistPath = abspath (self.options.cmsdist)
        # If no site is set, simply returns the original dependency name.
        # If site is set, return "site-dep" as a dependency if site-dep.spec
        # exists.
        def siteSpecific(d):
          if not self.options.site:
            return d
          siteDep = self.options.site + "-" + d
          siteSpec = join(cmsdistPath, siteDep + ".spec")
          if exists(join(cmsdistPath, siteDep + ".spec")):
            log("Site specific spec %s preferred for %s." % (siteSpec, d), DEBUG)
            return siteDep
          return d
        if self.options.pipPackage:
          if [ s for s in sources if s.startswith("pip://") ]:
            if not self.options.pipPackage in deps+buildDeps:
              buildDeps.append(self.options.pipPackage)
        deps = [siteSpecific(d) for d in deps]
        sources.extend ([join (cmsdistPath, source + ".file")
                         for source in localSources])
        patches.extend ([join (cmsdistPath, patch + ".patch") 
                        for patch in localPatches])
        self.__requiresCache[self.name] = (deps, sources, patches, buildDeps)
        return (deps, sources, patches, buildDeps)

def parseOptions():
    parser = OptionParser(usage="""
  cmsBuild [<additional-options>] [--no-bootstrap] -a <architecture> -c <cmsdist-dir> build <package> [<package2> .. <packageN>]
  cmsBuild [<additional-options>] [--sync-back] [--no-bootstrap] -a <architecture> -c <cmsdist-dir> upload <package> [<package2> .. <packageN>]""")
    deprecatedOptions = [("--compiling-processes", "--jobs / -j"),
                         ("--workers-pool-size", "--builders")]
    for deprecated, new in deprecatedOptions:
      if deprecated in sys.argv:
        parser.error("Deprecated option name %s. Please use %s." % (deprecated, new))
    
    # FIXME add the relevant options.
    parser.add_option("-c", "--cmsdist", 
                      dest="cmsdist",
                      help="the location of the CMSDIST directory",
                      metavar="PATH",
                      default=None)
    parser.add_option("--cmsdist-tag",
                       dest="cmsdistTag",
                       default="",
                       metavar="TAG",
                       help="Tag to fetch for CMSDIST.")
    parser.add_option("--architecture", "-a",
                      dest="architecture",
                      default=None,
                      help="Architecture to be used.")
    parser.add_option("-i", "--work-dir",
                      dest="workDir",
                      default=getcwd(),
                      metavar="PATH",
                      help="the location where the build happens")
    parser.add_option("--jobs", "-j",
                      dest="compilingProcesses",
                      metavar="N",
                      help="The number of processes to be used to compile a given package.",
                      default=1)
    parser.add_option("--repository",
                      dest="repository",
                      metavar="NAME",
                      help="Name of the repository directory on server. E.g. 'cms'.",
                      default="cms")
    parser.add_option("--tag",
                      dest="tag",
                      metavar="NAME",
                      help="Name of the tag. Default is constructed from the --repository <repo>.",
                      default="")
    parser.add_option("--builders",
                      dest="workersPoolSize",
                      metavar="N",
                      default=1,
                      help="Maximum number of packages to be build in parallel.",
                      type="int")
    parser.add_option("--sync-back",
                      dest="syncBack",
                      action="store_true",
                      help="When uploading, copy the temporary directory to the production one.",
                      default=False)
    advancedBuildOptions = OptionGroup(parser, "Advanced build options")
    advancedBuildOptions.add_option("--use-system-compiler",
                                    dest="systemCompiler",
                                    action="store_true",
                                    help="""Use the system compiler rather than the one specified in CMSDIST""",
                                    default=None)
    advancedBuildOptions.add_option("--ignore-compile-errors",
                                    "-k",
                                    dest="ignoreCompileErrors",
                                    help="Ignores CMSSW compilation errors.",
                                    action="store_true",
                                    default=False)
    advancedBuildOptions.add_option("--no-bootstrap",
                                    dest="bootstrap",
                                    action="store_false",
                                    help="Do not bootstrap area and ignore packages on the remote repository.",
                                    default=True)
    advancedBuildOptions.add_option("--skip-pre-install-checks",
                                    action="store_true",
                                    dest="skipPreInstall",
                                    default=None,
                                    help="Skip execution of default CMS pre-install scriplet")
    advancedBuildOptions.add_option("--build-command-prefix",
                                    dest="buildCommandPrefix",
                                    default="",
                                    metavar="COMMAND",
                                    help="String to prepend to any rpmbuild command")
    advancedBuildOptions.add_option("--pretend",
                                    dest="pretend",
                                    action="store_true",
                                    help="Do not actually build",
                                    default=False)
    advancedBuildOptions.add_option("--server",
                                    dest="server",
                                    metavar="URL",
                                    help="URL of cmspkg cgi-script e.g. 'http://cmsrep.cern.ch/cgi-bin/cmspkg'",
                                    default="http://cmsrep.cern.ch/cgi-bin/cmspkg")
    advancedBuildOptions.add_option("--use-dev",
                                    action="store_true",
                                    dest="useDev",
                                    default=None,
                                    help="Use development cmspkg instead of production.")
    advancedBuildOptions.add_option("--pip-package",
                                    dest="pipPackage",
                                    metavar="NAME",
                                    help="Name of the cmsdist pip package",
                                    default="py2-pip")
    advancedBuildOptions.add_option("--check-pkg-deps",
                                    dest="checkPackageDeps",
                                    action="store_true",
                                    help="Run extra checks after the build to make sure package dependencies are fully satisfied",
                                    default=False)
    advancedBuildOptions.add_option("--build-with-rpath",
                                    dest="buildWithRpath",
                                    action="store_true",
                                    help="""Added rpath to the executables. This is done at post install time.""",
                                    default=None)
    advancedBuildOptions.add_option("--new-scheduler", dest="newScheduler", action="store_true",
                                    default=False, help="Use the new scheduler to install / build packages")
    # FIXME: change option to --no-deprecate and do the deprecation 
    #        automatically by default.
    #parser.add_option ("--deprecate-local",
    #                   dest="doDeprecate",
    #                   action="store_true",
    #                   default=False)
    uploadGroup = OptionGroup(parser, "Upload Options",
                        "Options to fine-tune the upload to repository process.")
    uploadGroup.add_option("--upload-server",
                           dest="uploadServer",
                           metavar="HOSTNAME",
                           help="The hostname of the server where the repository is physically located.",
                           default="cmsrep.cern.ch")
    uploadGroup.add_option("--upload-user",
                           dest="uploadUser",
                           metavar="USERNAME",
                           help="The username by which connect to the server where the repository is located.",
                           default="cmsbuild")
    uploadGroup.add_option("--upload-port",
                           dest="uploadPort",
                           metavar="<0-65535>",
                           help="The port on which the repository sshd is listening to (default 22).",
                           default="22")
    uploadGroup.add_option("--upload-root-directory",
                           dest="uploadRootDirectory",
                           metavar="PATH",
                           default="/data/cmssw",
                           help="The base directory where the repository is located. E.g. /data/cmssw.")
    uploadGroup.add_option("--upload-tmp-repository",
                           dest="uploadTmpRepository",
                           help="Name of temporary repository to use during upload. Default=cms.<username> (Deleted/recreated for each upload request)",
                           default=getuser())

    uploadGroup.add_option("--server-apt-env",
                           dest="serverAptEnv",
                           default="/data/cmssw/apt/etc/profile.d/init.sh",
                           metavar="FILENAME",
                           help="Server side location of the apt environment script to be sourced.")
    
    debugGroup = OptionGroup(parser, "Debug options")
    debugGroup.add_option("--debug",
                          dest="debug",
                          action="store_true",
                          help="Print out debug information.",
                          default=False)
    debugGroup.add_option("--no-cleanup",
                          dest="noCleanup",
                          default=False,
                          action="store_true",
                          help="Do not automatically clean-up stale files.")
    debugGroup.add_option("--specs-only",
                          dest="specsOnly",
                          help="Do not build. Only write out RPM spec files.",
                          action="store_true",
                          default=False)
    debugGroup.add_option("--trace",
                          dest="trace",
                          action="store_true",
                          help="Show activity of builders and scheduler.",
                          default=False)
    debugGroup.add_option("--progress",
                          dest="progress",
                          action="store_true",
                          help="Show progress",
                          default=False)
    parser.add_option_group(advancedBuildOptions)
    parser.add_option_group(uploadGroup)
    parser.add_option_group(debugGroup)
    opts, args = parser.parse_args (None, None)
    
    #if cmsdist is not set then look for cmsdist/CMSDISTin local directory    
    if not opts.cmsdist:
      if exists("cmsdist"):
        opts.cmsdist = abspath("./cmsdist")
      else:
        opts.cmsdist = abspath("./CMSDIST")

    # Setup some default values.
    # FIXME: use an OptionParser callback.
    # FIXME: exclusive --cmsdist and --cmsdist-tag options.
    # FIXME: change site to "variant" and extract it from the architecture.
    opts.workDir = abspath(opts.workDir)
    opts.site = ""
    if "://" not in opts.cmsdist:
        opts.cmsdist = abspath (opts.cmsdist)
    
    if opts.cmsdistTag:
       opts.cmsdist = "cvs://?tag=%s" % opts.cmsdistTag 
    
    if not opts.architecture:
      parser.error("Please specify the architecture you want to build for.")

    # Check for weird characters in workdir
    if "/." in opts.workDir:
      parser.error("Hidden directories not allowed as --work-dir path.")
      
    if re.match(".*[\\\+[*$].*", opts.workDir):
      parser.error("Please avoid '\\+[*$' in --work-dir path.")
    
    # If --tag is not provided via command line then tag will always match the
    # repository (minus the various .pre bits, like for comp.pre)
    if not opts.tag:
      opts.tag = opts.repository.split(".")[0]
    
    setLogLevel (opts)
    if len(args) < 2:
      parser.error("Please build or upload action. Use --help to see additional options.")

    opts.installDir = opts.workDir
    if (opts.repository == "cms") or opts.repository.startswith("cms."):
        opts.installDir = "/opt/cmssw"

    opts.tempDirPrefix = "tmp"
    if opts.workDir.split(sep)[1] == opts.tempDirPrefix:
        opts.tempDirPrefix += "X"

    if len(args) < 2:
      fatal("Wrong number of arguments.")
    
    if not args[0] in ["build", "upload", "deprecate-local"]:
      fatal("Unknown command %s. Alternatives are build, upload." % args[0])
    
    if opts.syncBack and args[0] != "upload":
      fatal("--sync-back option is available only when uploading.")

    if not re.match("^[a-zA-Z0-9_.]+$",opts.repository):
      fatal("Repository name '%s' contains invalid characters. Allowed characters are: a-zA-Z0-9_." % opts.repository)

    if not re.match("^[a-zA-Z0-9_]+$",opts.uploadTmpRepository):
      fatal("Tmp upload repository name '%s' contains invalid characters. Allowed characters are: a-zA-Z0-9_" % opts.uploadTmpRepository)

    return opts, args
    
def createDirs (architecture, dest="./"):
    dirs = ["SPECS", join ("RPMS", architecture), 
            "SRPMS", join ("BUILD", architecture), "SOURCES", "BUILDROOT", "WEB"]
    for d in dirs:
        try:
            makedirs (join (abspath (dest), d))
        except:
            pass

def prepareSaveSpec (p):
    for directory in [p.specdir, p.sourcedir]:
        log ("Creating directory %s" % directory, DEBUG)
        if not exists (directory): makedirs (directory)
    p.dumpCmsos ()

def saveSpec (p):
    f = file (p.finalSpecFilename (), 'w')
    # Removes the "Requires:"
    spec = re.sub ("Requires:[^+\n]*\n", "\n", re.sub ("BuildRequires:[^+\n]*\n", "\n", p.getFinalSpec ()))
    f.write (spec)
    #Fix for RPM 4.4.: We need to add something at the end of the spec file otherwise
    #any multiline macro in the %post section does not expant properly if it is not followed
    #by any other command/comment.
    f.write ("\n#\n");
    f.close ()

def packageList (pkg):
    pkgListCreator = lambda finalString, pkg: "%s, %s" % (finalString, pkg.name)
    pkgList = reduce (pkgListCreator, pkg.dependencies, "")
    pkgList = reduce (pkgListCreator, [pkg], pkgList)
    return pkgList.strip (",")
    
def fetchLocal (pkg, sourceFilename):
    assert (sourceFilename[0] == "/")
    try:
        if not exists (pkg.sourcedir):
            makedirs (pkg.sourcedir)
        destFilename = join (pkg.sourcedir, 
                             basename(sourceFilename.rsplit(".", 1)[0]))
        log ("Copying %s to %s" % (sourceFilename, destFilename), DEBUG)
        source = open (sourceFilename)
        dest = file (destFilename, 'w')
        dest.write (source.read ())
        dest.close ()
        source.close ()
        return (sourceFilename, True)
    except Exception, e:
        return (sourceFilename, False)

def fetchSources(pkg, scheduler):
  scheduler.log("Fetching sources for %s" % pkg.name)
  sourcedir = pkg.sourcedir
  downloadables = pkg.sources + pkg.patches
  if not downloadables:
    scheduler.log("No sources to be downloaded found for packages %s." % pkg.name)
    return
  urlRe = re.compile (".*:.*/.*")

  # No need to create the download directory
  # not to dump the cmsos, because it was already
  # done.
  for url in downloadables:
    if urlRe.match(url):
      try:
        success = download(url, sourcedir, pkg.options)
      except MalformedUrl, e:
        return str(e)
    else:
      output, success = fetchLocal(pkg, url)
    if not success:
      return "Unable to download %s" % url
    scheduler.log("Done fetching %s" % url)

def checkIfInstalled (pkg):
    """ Check if a given rpm is already in the db.
    """
    if not pkg.pkgName() in rpm_db_cache:
        return False
    
    if not isDefaultRevision(pkg.pkgRevision):
        revision = rpm_db_cache[pkg.pkgName()][0]
        if revision >= pkg.pkgRevision:
            log("RPM %s found in RPM db with Revision %s (bigger than pkgRevision = %s)" % ( pkg.pkgName (),revision,pkg.pkgRevision), DEBUG)
            return True
        return False
    log ("RPM %s found in RPM db." % pkg.pkgName (), DEBUG)
    return True

def checkIfOnServer (pkg):
    """ Check if the rpm associated to pkg can be downloaded from the apt
        server.
    """
    log ("Checking if package %s can be downloaded from apt servers" % pkg.pkgName(), DEBUG)
    if tags_cache.cache.has_key(pkg.pkgName()) and isDefaultRevision(pkg.pkgRevision):
        return True
    error, output = getstatusoutput ("%s -f show %s" % (CMSPKG_CMD, pkg.pkgName()))
    if error or not output:
        log ("RPM %s not found in apt repository." % pkg.pkgName (), DEBUG)
        return False
    pkgName = None
    pkgRevision = None
   
    lines = [line for line in output.split("\n") if line]
    assert(lines)
    for line in lines:
        key, value = [l.strip() for l in line.split(":", 1)]
        log ("Parsing cmspkg show. key: %s,i value: %s." % (key,value), DEBUG)
        if key == "Package":
            pkgName = value
        if key == "Version":
            pkgRevision = value.split("-",1)[1]
        if key == "Description":
            break
    if pkg.pkgRevision <= pkgRevision and pkgName == pkg.pkgName ():
        log ("RPM %s found in apt repository with a revision greater than the current one. Accepting package." % pkg.pkgName (), DEBUG)
        return True
    log("""RPM %s is found in the apt repository, but it has a earlier revision (%s)
than the current one(%s). Building current package.""" % (pkg.pkgName(), pkgRevision, pkg.pkgRevision), DEBUG)
    return False

def checkCanInstallRpm (pkg):
    officialRpmLocation = pkg.rpmLocation()
    uniqueRpmLocation = join (abspath ("RPMS/cache"), pkg.checksum, pkg.rpmfilename)
    if exists (officialRpmLocation):
        return True
    elif exists (uniqueRpmLocation):
        log ("""No rpm found at:
                %(officialRpmLocation)s 
                but original is actually there at:
                %(uniqueRpmLocation)s""" % locals ())
        symlink (uniqueRpmLocation, officialRpmLocation)
        return True
    return False

def getScriptlets(pkg, relocation, original):
    """Gets the scriptlet associated to an rpm.
    """
    command = "%s ; rpm -qp --scripts %s" % (rpmEnvironmentScript , pkg.rpmLocation())
    error, output = getstatusoutput(command)
    if error:
        log ("Command: %(command)s failed with the following message: %(output)s." % locals(), DEBUG)
        raise RpmInstallFailed (pkg, output)
    capture = None
    scripts = {}
    secEXP = ""
    for sec in "pre", "post", "postun", "preun":
        scripts[sec] = 'RPM_INSTALL_PREFIX="%s"; export RPM_INSTALL_PREFIX\n' % relocation
        secEXP += sec+"|"
    secPattern = re.compile("^("+secEXP.strip("|")+")install\s+scriptlet\s+")
    for line in output.split("\n"):
        m = secPattern.match(line)
        if m:
            capture = m.group(1)
        elif capture:
            scripts[capture] += line+"\n"
    return scripts

def installRpm (pkg, bootstrap):
    """ Installs an rpm
    """
    error = 1; output = ""; command = "#No command"
    if bootstrap:
        command = "%s ; rpm -Uvh --prefix %s %s" % (rpmEnvironmentScript, pkg.options.workDir, pkg.rpmLocation())
        error, output = getstatusoutput (command)
    else:
        workDir = pkg.workDir
        tmpDir  = join(workDir, pkg.tempDirPrefix, pkg.checksum)
        tmpInstall  = join(tmpDir, pkg.installDir.strip(sep))
        rpmLoc  = pkg.rpmLocation()
        command  = "mkdir -p %(tmpInstall)s; rm -rf %(tmpInstall)s; ln -s %(workDir)s %(tmpInstall)s;"
        command += "cd %(tmpDir)s; rpm2cpio %(rpmLoc)s | cpio -idmv; cd %(workDir)s; rm -rf %(tmpDir)s"
        command = command % locals()
        error, output = getstatusoutput(command)
        if not error:
            scripts = getScriptlets(pkg, pkg.options.workDir, "")
            log ("Scriptlets: %s" % scripts, DEBUG)
            postScript = NamedTemporaryFile()
            postScript.write (scripts["post"])
            postScript.flush()
            error, output = getstatusoutput("cat %s; sh -e -x %s" % (postScript.name, postScript.name))
    if error:
        e, o = getstatusoutput ("rm -rf %s %s/%s" % (pkg.rpmdir, abspath ("RPMS"),pkg.rpmfilename))
        log ("Command:\n %(command)s failed with the following message: %(output)s" % locals (), DEBUG)
        raise RpmInstallFailed (pkg, output)
    log ("Done installing via rpm.", DEBUG)

def installApt (pkg, scheduler):
    command = "%s -f -j 1 install %s" % (CMSPKG_CMD, pkg.pkgName ())
    error, output = getstatusoutput (command)
    log ("About to install %s using cmspkg..." % pkg.pkgName (), DEBUG)
    if error:
        log ("Command:\n %(command)s failed with the following message: %(output)s" % locals (), DEBUG)
        raise RpmInstallFailed (pkg, output)
    log ("Done installing via cmspkg.", DEBUG)
    for dep in pkg.dependencies:
      scheduler.forceDone("check-%s" % dep.pkgName())
      scheduler.forceDone("install-%s" % dep.pkgName())

def scheduleInstallPackage(pkg, scheduler):
  if pkg.name == "system-compiler":
    return False

  bootstrapped = pkg.options.bootstrap
  
  instDir = join(pkg.options.workDir, pkg.pkgrel)
  if not bootstrapped and exists(join(instDir, ".package-checksum")):
    scheduler.log("Package already built into %s. Not building." % instDir)
    # subpackages were already built as part of the main package, but the RPMs still need to be symlinked
    return checkCanInstallRpm(pkg)
  
  if not bootstrapped:
    return False

  scheduler.log("Checking if %s is cached." % pkg.name)
  actionName = "install-%s" % pkg.pkgName()
  if checkIfInstalled(pkg):
    scheduler.log("%s already in rpm database. Not building." % pkg.name)
    scheduler.serial(actionName, [], installDoneDummy)
    return True
  if checkCanInstallRpm(pkg):
    scheduler.log("%s is available from local RPMS area. Not building. Installing..." % pkg.pkgName())
    scheduler.serial(actionName, [], installRpm, pkg, bootstrapped)
    return True
  if checkIfOnServer (pkg):
    scheduler.log("%s is available from remote repository \"%s\". Not building. Downloading and installing..." % (pkg.name, pkg.options.repository))
    scheduler.serial(actionName, [], installApt, pkg, scheduler)
    return True
  return False
  
def getCommandPrefix (options):
    linux32RE = "slc[^_]+_ia32_gcc[^_]+"
    returnString=""
    if re.match (linux32RE, options.architecture):
        returnString = "linux32 %s" % options.buildCommandPrefix
    elif options.buildCommandPrefix:
        returnString = options.buildCommandPrefix
    return returnString.strip ()

def handleStaleFiles (files, noCleanup):
    for staleFile in [f for f in files if exists(f)]:
        if noCleanup:
             raise UnexpectedFile (staleFile)
        log ("Removing stale file " + staleFile, DEBUG)
        unlink (staleFile)

def buildPackage(pkg, scheduler):
  """ This helper function is responsible for building/installing a given spec and it's associated rpm.
      What it does is the following (TODO):
      * Checks if the rpm is already installed in the RPM DB. If yes, exits.
      * Checks if the rpm is already available in the local area. If yes, installs it.
      * Checks if the rpm is already available on the apt server. If yes, downloads, installs and returns.
      If any of the above is true it:
      * Builds the rpm, if it fails, it aborts.
      * Installs the rpm in the local db, if it fails, it aborts."""
  if pkg.name == "system-compiler":
    return
  
  # if this is a subpackge do not try to build it, it should have been built as part of its parent
  if pkg.parent:
    scheduler.log("Not building Subpackage %s, it should have been built as part of Package %s." % (pkg.name, pkg.parent.name))
    return

  scheduler.log("Creating directory %s if not existing." % pkg.builddir)
  if not exists (pkg.builddir):
    makedirs (pkg.builddir)
  logfile = "%s/log" % pkg.builddir
  
  scheduler.log("Building %s. Log can be found in %s." % (pkg.name, logfile))
  optionsDict = {
    "topdir": abspath("."),
    "specdir": pkg.specdir,
    "builddir": pkg.builddir,
    "makeprocesses": "",
    "ignoreCompileErrors": "",
    "nodeps": ""
  }

  rpmsCacheDir = dirname(join(abspath ("RPMS/cache/%s" % pkg.checksum), pkg.rpmfilename))
  finalRpmCacheDir = dirname(join (abspath ("RPMS"), pkg.rpmfilename))
  srpmsCacheDir = join(abspath("SRPMS/cache/%s" % pkg.checksum))
  
  missingDirs = [d for d in [rpmsCacheDir, finalRpmCacheDir, srpmsCacheDir] 
                 if not exists(d)]
  for directory in missingDirs:
    makedirs(directory) 
  
  finalRpmFilename = join(abspath("RPMS"), pkg.rpmfilename)
  uniqueRpmFilename = join(abspath("RPMS/cache/%s" % pkg.checksum), pkg.rpmfilename)
  handleStaleFiles ([finalRpmFilename, uniqueRpmFilename], pkg.options.noCleanup)    
  
  if pkg.options.compilingProcesses:
    optionsDict["makeprocesses"] = "--define \"compiling_processes %s\"" % pkg.options.compilingProcesses
  if pkg.options.ignoreCompileErrors:
    optionsDict["ignoreCompileErrors"] = "--define \"ignore_compile_errors 1\"" 
  optionsDict["tmpdir"] = join(opts.workDir, opts.tempDirPrefix)
  optionsDict["rpmenv"] = rpmEnvironmentScript
  optionsDict.update({"prefix": getCommandPrefix(pkg.options),
                      "buildRoot": join(optionsDict["tmpdir"], "BUILDROOT", pkg.checksum),
                      "extraRpmDefines": pkg.options.rpmQueryDefines})
  if not pkg.options.bootstrap:
    optionsDict["nodeps"] = "--nodeps"

  # FIXME: should be done only once!
  err, out = getstatusoutput("%s ; rpmbuild --version" % rpmEnvironmentScript)
  if err:
    return "ERROR: unable to find working rpmbuild"
 
  rpmbuildCommand = "%(rpmenv)s ; TMPDIR=%(tmpdir)s %(prefix)s rpmbuild %(nodeps)s --buildroot %(buildRoot)s -ba --define '_topdir %(topdir)s'" \
                    " %(makeprocesses)s %(ignoreCompileErrors)s %(extraRpmDefines)s" \
                    " %(specdir)s/spec >%(builddir)s/log 2>&1" % optionsDict
  rpmbuildCommand = rpmbuildCommand.strip()
  scheduler.log(rpmbuildCommand)
  error, output = getstatusoutput(rpmbuildCommand)
  if error:
    if not exists(logfile):
      return "Error happened before any log output."
    logLines = open(logfile).readlines()
    return "Failed to build %s. Log file in %s. Final lines of the log file:\n%s" % (pkg.name, logfile, "".join(logLines[-20:]))
  if output:
    return output
  scheduler.log("Build successful.")
  
  # link the RPM from the unique name to the friendly name
  symlink(uniqueRpmFilename, finalRpmFilename)
  # link subpackages, if any
  for subpackage in pkg.subpackages:
    finalSubFilename = join(abspath ("RPMS"), subpackage.rpmfilename)
    uniqueSubFilename = join(abspath ("RPMS/cache/%s" % subpackage.checksum), subpackage.rpmfilename)
    symlink(uniqueSubFilename, finalSubFilename)
  
def installPackage(pkg, scheduler):
  if not checkCanInstallRpm (pkg):
    raise RpmBuildFailed (pkg)
  scheduler.log("Trying to install the rpm package %s just built." % pkg.pkgName ())
  if bootstrap:
    scheduler.log("Checking local path dependency for rpm package %s just build." % pkg.pkgName ())
    rpm_env = rpmEnvironmentScript
    command = "%s ; rpm  -qp --requires %s | cut -d\  -f1" % (rpm_env, pkg.rpmLocation())
    error, output = getstatusoutput (command)
    if error: raise RpmBuildFailed (pkg)
    localPaths = [l for l in output.split("\n") if l.startswith(pkg.options.workDir)]
    pkg_error = False
    if localPaths:
      scheduler.log("Error: Local path dependency found for %s\n  %s" % (pkg.pkgName (), "\n  ".join(localPaths)))
      pkg_error = True
    if pkg.options.checkPackageDeps:
      pkg_deps = ["system-base-import", pkg.rpmLocation()] + [ p.pkgName () for p in pkg.dependencies ]
      for p in rpm_db_cache:
        if '+bootstrap-bundle+' in p:
          pkg_deps.append(p)
          break
      all_provides = {}
      for dep_pkg in pkg_deps:
        provides_cachedir = join(pkg.options.workDir, pkg.options.tempDirPrefix, "cache")
        opt = "-q --provides"
        if dep_pkg == pkg.rpmLocation():
          opt += " -p"
          provides_cache = join(provides_cachedir, "provides-"+pkg.pkgName())
        else:
          provides_cache = join(provides_cachedir, "provides-"+dep_pkg)
        cmd = "if [ ! -f %(provides_cache)s ] ; then %(rpm_env)s ; rpm %(opt)s %(dep_pkg)s > %(provides_cache)s ; fi ; cat %(provides_cache)s | cut -d\  -f1" % locals()
        e, o = getstatusoutput(cmd)
        for p in o.split("\n"): all_provides[p]=1
      miss_deps = {}
      for d in output.split("\n"):
        if d.startswith("rpmlib(") or (d in pkg_deps): continue
        if not d in all_provides: miss_deps[d]=1
      if miss_deps:
        scheduler.log("Error: Package %s requires '%s' while there is no direct dependency in spec file" % (pkg.pkgName (), ",".join(sorted(miss_deps.keys()))))
        pkg_error = True
    if pkg_error: raise RpmBuildFailed (pkg)
  installRpm(pkg, pkg.options.bootstrap)
  scheduler.log("Done")
  f = open(join(pkg.options.workDir, pkg.pkgrel, ".package-checksum"), 'w')
  f.write (pkg.checksum)
  f.close ()
  scheduler.reschedule()

from time import sleep

class ActionFactory (object):
    def __init__ (self, pkg):
        self.__package = pkg
        self.__actionList = []
        
    def create (self, cls, parent=None, prevAlternative=None):
        """ Creates an action of kind cls with the specified parent and/or
            alternatives.
        """
        obj  = cls (self.__package, parent, prevAlternative)
        self.__lastCreated = obj
        self.__actionList.append (obj)
        return obj

    def createAlternative (self, cls, prevAlternative=None):
        """ Creates an alternative to prevAlternative action. By default
            prevAlternative is the last action created.
        """
        return self.create (cls, parent=None, 
                            prevAlternative=(prevAlternative or self.__lastCreated))
    
    def createChild (self, cls, parent=None):
        """ Creates a child of the parent action. By default the parent is the
            last action created.
        """
        return self.create (cls, parent=(parent or self.__lastCreated),
                            prevAlternative=None)
                            
    def getActionList (self):
        return self.__actionList
    

def createBuildActionLists (pkg):
    """ Builds the action tree depth first.
    """
    log ("Creating actions for %s" % pkg.pkgName (), DEBUG)
    factory = ActionFactory (pkg)
    factory.create (BuildSystemCompiler)
    factory.createAlternative (InstallFromServer)
    if pkg.sources:
        factory.createAlternative (SourcesDownload)
        factory.createChild (BuildPackage)
    else:
        factory.createAlternative (BuildPackage)
    factory.createChild (LinkPackageFromCache)
    factory.createChild (InstallFromLocalArea)
    return factory.getActionList ()

class BuildChecker (object):
    def __init__ (self, pkg):
        """ This class is used to perform various checks on the build procedure
            and its outcome.
        """
        self.__packages = [pkg]
        self.__actions = []
        for package in self.__packages:
            self.__actions.extend (createBuildActionLists (package))
        for action in self.__actions:
            action.dryRun ()
    
    def checkConsistency (self):
        def checkActionConsistency (action):
            actionName = action.actionName
            pkgName = action.pkg.pkgName ()
            checkSentence = "Checking if possible action %(actionName)s %(pkgName)s behaves as expect..." % locals ()
            willRun = action.dryRun ()
            expectedResults = action.expectedResults ()
            if willRun and not expectedResults:
                log (checkSentence + " NO!!! The following happened:")
                log (action.missingExecution ())
                return False
            if not willRun and expectedResults:
                log (checkSentence + " NO!!! The following happened:")
                log (action.nonExpectedExecution ())
                return False
            log (checkSentence + "YES! %s %s %s and %s" % (actionName, pkgName,
                                                        willRun and "should have run" or "should have not run",
                                                        expectedResults and "looks like it actually was." or "does not look like it was."), DEBUG)
            return True
        message = "Something wrong with action '%s' for package '%s'."
        errorMessage = "\n".join ([message % (action.actionName, action.pkg.pkgName ())
                                   for action in self.__actions
                                   if not checkActionConsistency (action) ])
        if errorMessage:
            log (errorMessage)
            return False
        return True

    def checkIfUploadable (self):
        log ("Checking for anything ready to upload.", DEBUG)
        result = False
        for action in self.__actions:
            if action.dryRun () and action.producesStuffToUpload ():
                log ("Action '%s' for package '%s' produces something to be uploaded." % (action.actionName, 
                                                                                          action.pkg.pkgName ()), DEBUG)
                result = result or True
        return result

# If a package is in apt cache, queue the action to install it.
# If a package is not found in cache, queue actions to download
# sources, build, and install the resulting package.
# Notice that in both cases the action completes successfully.
def checkPackageInCache(pkg, scheduler):
  # make sure subpackages are properly up-to-date with the definitions in their
  # parents
  if pkg.parent:
    pkg.updateFromParent()

  pkgName = pkg.pkgName()
  scheduler.log("Starting to process package %s" % pkgName)
  sourcedir = pkg.sourcedir
  if not exists (sourcedir):
    log ("Creating directory %s" % sourcedir, DEBUG)
    makedirs (sourcedir)
    pkg.dumpCmsos ()
  # Check if it possible to install package and enqueue 
  # serial task to do it.
  # FIXME: Clean up the fact queuing of tasks is actually
  #       a consequence of invoking scheduleInstallPackage.
  scheduled = scheduleInstallPackage(pkg, scheduler)
  if scheduled:
    scheduler.log("Package %s found in repository" % pkgName)
    scheduler.reschedule()
    return
  scheduler.log("Package %s not found in repository. Queuing for build." % pkgName)
  fetchDependencies = []
  if pkg.name.endswith("-patch"):
    baseTool = pkg.name[:-6]
    baseToolVersion = [d.version for d in pkg.dependencies if d.name == baseTool]
    if len(baseToolVersion)>0:
      baseToolVersion = "cms+%s+%s" % (baseTool, baseToolVersion[0])
      if not rpm_db_cache.has_key(baseToolVersion): fetchDependencies = ["install-%s" % baseToolVersion]
  if pkg.options.pipPackage and [ s for s in pkg.sources if s[:6] == "pip://" ]:
    pip = [ p.pkgName() for p in pkg.fullDependencies if p.name == pkg.options.pipPackage ][0]
    if not rpm_db_cache.has_key(pip): fetchDependencies += [ "install-"+pip ]
  scheduler.parallel("fetch-%s" % pkgName, fetchDependencies, fetchSources, pkg, scheduler)
  buildActionDependencies = []
  for p in pkg.origDependencies + pkg.origBuildDependencies:
    if not isPackageInstalled(p):
      scheduler.serial("check-%s" % p.pkgName(), [], checkPackageInCache, p, scheduler)
      buildActionDependencies.append("install-%s" % p.pkgName())
  buildActionDependencies.append("fetch-%s" % pkgName)
  installActionDependencies = ["build-%s" % pkgName]
  scheduler.log("Dependencies for %s: %s" % (pkgName, buildActionDependencies))
  scheduler.parallel("build-%s" % pkgName, buildActionDependencies, buildPackage, pkg, scheduler)
  scheduler.serial("install-%s" % pkgName, installActionDependencies, installPackage, pkg, scheduler)
  #Install sub-packages too if any
  subinstallActionDependencies = ["install-%s" % pkgName]
  for subpkg in pkg.subpackages:
    scheduler.serial("install-%s" % subpkg.pkgName(), subinstallActionDependencies, installPackage, subpkg, scheduler)
  scheduler.reschedule()

# Helper to find an unique list 
def uniq(input):
  output = []
  for x in input:
    if x not in output:
      output.append(x)
  return output

# New version using the new scheduler.
def buildSpecs(topLevelPackages):
  from scheduler import Scheduler
  scheduler = Scheduler(topLevelPackages[0].options.workersPoolSize)
  for pkg in topLevelPackages:
    if not isPackageInstalled(pkg):
      scheduler.serial("check-%s" % pkg.pkgName(), [], checkPackageInCache, pkg, scheduler)

  # We create before hand since we know they are going to be needed. This
  # is to avoid having parallel threads creating them at the same time with
  # one of the two failing because the directory is already there.
  # FIXME: clean up the other places where these are created but only
  #        after we move to the new scheduler.
  for path in ["SOURCES/cache", "RPMS", "SRPMS", "BUILD", "SPECS", "BUILDROOT"]:
    d = join(pkg.options.workDir, path)
    if not exists(d):
      makedirs(d)

  scheduler.run()
  for (action, error) in scheduler.errors.iteritems():
    log("* The action \"%s\" was not completed successfully because %s" % (action, error))
  if scheduler.brokenJobs:
    sys.exit(1)

def build(opts, args, factory):
  err, out = getstatusoutput("%s ; rpm --version" % rpmEnvironmentScript)
  if err:
    fatal("unable to find a working rpm.")
  rpmCacheUpdate(opts)
  packages = [factory.createWithSpec(pkgName) for pkgName in args]
  packages.sort()
  for pkg in packages:
    logMessage = "Package %s requested." % pkg.pkgName ()
    if not isDefaultRevision(pkg.pkgRevision):
      logMessage += " Forcing it at revision %s." % pkg.pkgRevision
    log (logMessage)
    if pkg.fullDependencies:
      log ("This will bring in also the following packages: ")
      deps = sorted(pkg.fullDependencies, key = lambda d: d.pkgName().lower())
      finalString = "\n".join (["%s (%s)" % (dep.pkgName (), dep.checksum) 
                                for dep in deps])
      log (finalString)
  
  if opts.specsOnly:
      log ("SPECS files written")
      sys.exit (0)
  
  if opts.pretend:
      log ("Option --pretend specified. Not building.")
      return
  buildSpecs(packages)

def isPackageInstalled(pkg):
    if pkg.options.bootstrap:
        pkgName = pkg.pkgName ()
        if rpm_db_cache.has_key(pkgName):
            if not isDefaultRevision(pkg.pkgRevision):
                if rpm_db_cache[pkgName][0] < pkg.pkgRevision:
                    return False
            log ("Package %s with same/newer revision %s is already installed" % (pkgName, str(rpm_db_cache[pkgName][0])), DEBUG)
            return True
    else:
        instDir = join(pkg.options.workDir, pkg.pkgrel)
        if exists(join(instDir, ".package-checksum")):
            return True
    return False

class PlatformDetectionError (Exception):
    pass

def callCmsos (opts):
    pathname = join (opts.cmsdist, "cmsos.file")
    commandPrefix = getCommandPrefix (opts)
    error, output = getstatusoutput (("%s sh %s" % (commandPrefix, pathname)).strip ())
    if error:
        raise PlatformDetectionError ("Error while executing cmsos.file:\n%s" % output)
    cmsos = output.strip ("\n")
    log ("cmsos value is %s" % cmsos, DEBUG)
    return cmsos

# The helper method responsible for bootstrapping an area.
# @a opts the build options passed on command line.
# @return the location of the init.sh script to be sourced when building 
#         or uploading.
def bootstrap(opts):
  useDev=""
  if opts.useDev: useDev="-dev"
  bootstrapUrl = "%s%s/file/%s/%s/%s" % (opts.server, useDev, opts.repository,  opts.architecture, "bootstrap.sh")
  log("fetching %s" % bootstrapUrl, DEBUG)
  try:
    f=urlopen(bootstrapUrl)
    bootstrapContents = f.read()
  except:
    log("Unable to fetch file %s. Mispelled architecture/repository name?\nNothing changed, aborting bootstrap." % bootstrapUrl)
    sys.exit (1)
  bootstrapFilename = join(opts.tempdir, "bootstrap.sh")
  bootstrapFile = open(bootstrapFilename, "w")
# PG the --insecure option does not work on darwin
  if sys.platform == "darwin" : bootstrapFile.write(bootstrapContents.replace("--insecure",""))
  else : bootstrapFile.write(bootstrapContents)
  bootstrapFile.close()
      
  log("Bootstrapping from server %s" % opts.server, DEBUG)
  bootstrapServer = opts.server.replace("http://","").replace("https://","").split("/",1)[0]
  bootstrapServerPath = ""
  options = ["-server", bootstrapServer, 
             bootstrapServerPath,
             "-arch",  opts.architecture,
             "-path", opts.workDir,
             "-repository", opts.repository,
             "-assume-yes", "-only-once", useDev, "setup"]
  if logLevel is DEBUG:
    options.append("-debug")
  cmpkg = "%s/common/cmspkg -a %s" % (opts.workDir, opts.architecture)
  options.append("&& %s -f upgrade && %s -f update" % (cmpkg, cmpkg))
  bootstrapCommand ="TMPDIR=%s sh -ex %s %s" % (opts.tempdir, bootstrapFilename, " ".join(options)) 
  log("Bootstrapping cmsBuild area.")
  log(bootstrapCommand, DEBUG)
  error, output = getstatusoutput(bootstrapCommand)
  bootstrapLog = join(opts.tempdir, "bootstrap.log")
  f = open(bootstrapLog, "w")
  f.write(output)
  f.close()
  if error:
    log(output, DEBUG)
    fatal("unsuccessful bootstrap, log can be found in %s." % bootstrapLog)

  parts = glob(join(opts.workDir,opts.architecture, "external/rpm/*/etc/profile.d/init.sh"))
  if len(parts) != 1:
    fatal("""malformed bootstrap. More than one cmspkg installation found.""")

  initSh = parts[0]

  if not exists(initSh):
    fatal("""ERROR: cannot read cmspkg environment. File missing cmspkg/rpm env""")

  # If we are not in a cfg file write where to find the correct init.sh
  log("Done. Setup log can be found in %s." % bootstrapLog)
  log("rpm env file can be found in %s" % initSh, DEBUG)
  createDirs(architecture=opts.architecture, dest=opts.workDir)
  return initSh

def checkFileOnServer (contactString, filename):
    command = """ssh %(contactString)s if [ -f %(file)s ]; then echo 1; fi"""
    error, result = getstatusoutput (command % locals ()).strip ("1")
    if error or not result:
        return False
    return (result == "1" and True) or False

def upload_help ():
    log ("""cmsBuild upload <package to upload>""")    

def check (opts, args, factory):
    """ This method is responsible for checking that a given package was build
        and installed correctly.
    """
    pkgs = [ factory.createWithSpec (specName) for specName in args ]
    # expand subpackages to be checked
    pkgs = factory.expandSubpackages(pkgs)
    unconsistentPkgs = [ pkg
                         for pkg in pkgs
                         if not BuildChecker (pkg).checkConsistency () ]
    if unconsistentPkgs:
        log ("Warning the following packages have errors:")
        log ("\n".join ([pkg.name for pkg in unconsistentPkgs]))
        sys.exit (1)
    log ("Everything ok.")    

def format(s, **kwds):
  return s % kwds

def statusAndLog(status, s, **kwds):
  log(s % kwds)
  return status

def executeScript(opts, dumpedScript, local=True):
  if local:
    executionCmd="sh -e %(debug)s %(filename)s"
  else:
    executionCmd="ssh < %(filename)s -p %(cmdPort)s %(cmdUser)s@%(cmdServer)s sh -e %(debug)s"
  # Run (or print-out) the script
  if not opts.pretend:
    fd, filename = mkstemp(".sh", "cmsBuildExecuted", opts.tempDirPrefix, True)
    f = os.fdopen(fd, "w")
  else:
    f = sys.stderr
  f.write(dumpedScript)
  f.close()
  if not opts.pretend:
    script = format(executionCmd,
                    debug=opts.debug and "-x" or "",
                    filename=filename,
                    cmdServer=opts.uploadServer,
                    cmdUser=opts.uploadUser,
                    cmdPort=opts.uploadPort)
    err, out = getstatusoutput(script)
  if opts.debug: log(out)
  return (err, out)

def allPackagesToUpload (args, factory):
  pkgs = [factory.createWithSpec(specName) for specName in args]
  if len(pkgs) !=  len(args):
    return statusAndLog(False, "ERROR: Error while parsing spec.")

  def allDeps(pkg, factory, dep_cache={}):
    if pkg in dep_cache: return dep_cache[pkg]
    deps = [pkg]
    for dep in pkg.fullDependencies:
      for subdep in allDeps(dep, factory, dep_cache):
        if not subdep in deps: deps.append(subdep)
    dep_cache[pkg] = deps
    return deps

  fullPackageList = []
  dep_cache={}
  for pkg in pkgs:
    for dep in allDeps(pkg, factory, dep_cache):
      if dep not in fullPackageList and exists (dep.rpmLocation()):
        fullPackageList.extend(factory.expandSubpackages([dep]))
  return fullPackageList

def  deprecateLocalCommand(opts, fullPackageList):
  if not fullPackageList: return "true"
  deprecablePackages = " ".join([pkg.pkgName() for pkg in fullPackageList])
  deprecableRPMS = " ".join([p.rpmfilename for p in fullPackageList])
  deprecatedSrc  = " ".join(["SOURCES/"+p.pkgdir for p in fullPackageList])
  deprecatedDir  = " ".join([p.pkgrel for p in fullPackageList])
  deprecatedSRPM = " ".join(["SRPMS/cache/*/"+p.pkgName()+"*" for p in fullPackageList])
  deprecateLocal = format("%(rpmenv)s ; rpm -e %(deprecablePackages)s\n"
                          'cd %(workDir)s\n'
                          'rm -rf %(deprecatedDir)s\n'
                          "for x in %(deprecableRPMS)s; do\n"
                          '  [ -e RPMS/$x ] || continue\n'
                          '  realfile=`readlink RPMS/$x`\n'
                          '  rm -f RPMS/$x\n'
                          '  rm -f $realfile\n'
                          "done\n"
                          "for x in %(deprecatedSrc)s; do\n"
                          '  [ -d $x ] || continue\n'
                          "  for f in $x/*; do\n"
                          '    realfile=`readlink $f || true`\n'
                          '    [ "$realfile" ] || continue \n'
                          '    rm -f $realfile\n'
                          "  done\n"
                          '  rm -rf $x\n'
                          "done\n"
                          "rm -rf %(deprecatedSRPM)s\n",
                          rpmenv=rpmEnvironmentScript,
                          architecture=opts.architecture,
                          deprecableRPMS=deprecableRPMS,
                          deprecatedSrc=deprecatedSrc,
                          workDir=opts.workDir,
                          deprecatedDir=deprecatedDir,
                          deprecatedSRPM=deprecatedSRPM,
                          deprecablePackages=deprecablePackages)
  return deprecateLocal

def cleanup_server_upload(opts):
  global SERVER_TMP_UPLOAD_DIRECTORY
  if not SERVER_TMP_UPLOAD_DIRECTORY: return
  cleanupCmd = format("rm -rf %(tmpdir)s*", tmpdir=SERVER_TMP_UPLOAD_DIRECTORY)
  executeScript(opts, cleanupCmd, False)
  SERVER_TMP_UPLOAD_DIRECTORY = None

def upload(opts, args, factory):
  global SERVER_TMP_UPLOAD_DIRECTORY
  """New upload method. It uses the upload.sh server-side script for uploading
     https://github.com/cms-sw/cmspkg/blob/master/server/scripts/upload.sh"""

  if not args:
    upload_help()
    return False

  # A few helpers
  def getResult(s, k):
    return [x.replace(k,"") for x in s.split("\n") if x.startswith(k)][0]
  
  def logAndDieOnError(err, msg):
    if not err:
      return
    log(msg)
    cleanup_server_upload(opts)
    sys.exit(1)

  rpmCacheUpdate(opts)
  useDev=""
  if opts.useDev: useDev="-dev"
  cmspkg_upload_repo = opts.uploadTmpRepository if not opts.syncBack else ""
  migrateRepo = format("/data/scripts%(useDev)s/upload.sh INIT '%(architecture)s' '%(repository)s' '%(cmspkg_upload_repo)s'",
                       architecture=opts.architecture,
                       repository=opts.repository,
                       useDev=useDev,
                       cmspkg_upload_repo=cmspkg_upload_repo)
  (err, uploadDir) = executeScript(opts, migrateRepo, False)
  logAndDieOnError(err, "Error while checking for parent repository and getting a temp area for upload.")
  
  uploadDir  = getResult(uploadDir, "NEW_TEMP_REPOSITORY:")
  SERVER_TMP_UPLOAD_DIRECTORY = uploadDir

  #Once we have established the parent then we should update the apt/cmspkg and rpm cache
  tags_cache.update()
  rpmCacheUpdate(opts)
  fullPackageList = allPackagesToUpload (args, factory)
  if not fullPackageList:
    return statusAndLog(True, "Nothing needs to be uploaded")
  cmsplatf = fullPackageList[0].cmsplatf
  uploadablePackages = []
  for pkg in fullPackageList:
    checker = BuildChecker(pkg)
    if not checker.checkConsistency():
      statusAndLog(False, "ERROR: Build area not consistent. Not uploading.")
      executeScript(opts, deprecateLocalCommand(opts, fullPackageList))
      return False
    if not checker.checkIfUploadable():
      statusAndLog(True, "Nothing needs to be uploaded for %(name)s.",
                                name=pkg.pkgName())
      continue
    uploadablePackages.append(pkg)
  fullPackageList = uploadablePackages
  if not fullPackageList:
    return statusAndLog(True, "Nothing needs to be uploaded")
  log("Ready to upload.")

  BootstrapPackage = ""
  CMSCommonPackage = ""
  BootstrapPackages = [pkg.pkgName() for pkg in fullPackageList if pkg.pkgName().startswith("external+bootstrap-driver+")]
  CMSCommonPackages = [pkg.pkgName() for pkg in fullPackageList if pkg.pkgName().startswith("cms+cms-common+")]
  if BootstrapPackages: BootstrapPackage = "/".join(BootstrapPackages[0].split("+",2))
  if CMSCommonPackage: CMSCommonPackage = "/".join(CMSCommonPackages[0].split("+",2))

  packageNames = [pkg.pkgName() for pkg in fullPackageList]
  pkgChecksums = list(set([p.checksum for p in fullPackageList]))
  uploadSum = sha256("-".join(pkgChecksums)).hexdigest()
  tmpdir=join(opts.workDir, opts.tempDirPrefix, "upload")
  # Create an area locally which has to be merged with the remote repository.
  createEmptyRepository = format(
    "set -e\n"
    "rm -rf %(tmpdir)s\n"
    "mkdir -p %(tmpdir)s/%(uploadSum)s/RPMS\n",
    architecture=opts.architecture,
    tmpdir=tmpdir,
    uploadSum=uploadSum)
  # Hard-link packages.
  md5sum="md5sum $r | awk '{print $1}'"
  if platform == 'darwin' : md5sum="md5 -q $r"
  hardLinkPackages = format(
    "MD5CACHE=%(tmpdir)s/%(uploadSum)s/rpms.md5cache\n"
    "touch $MD5CACHE\n"
    "for h in %(includes)s ; do\n"
    "  hi=$(echo $h | sed 's|^\(..\).*|\\1|')\n"
    "  mkdir -p %(tmpdir)s/%(uploadSum)s/RPMS/$hi/$h\n"
    "  for r in $(find %(workdir)s/RPMS/cache/$h/%(architecture)s -name '*.rpm' -type f) ; do\n"
    "    ln $r %(tmpdir)s/%(uploadSum)s/RPMS/$hi/$h/$(echo $r | sed 's|.*/||')\n"
    "    echo $(basename $r)\" \"$(%(md5sum)s) >> $MD5CACHE\n"
    "  done\n"
    "done\n"
    "WEB_FILES=$(find %(workdir)s/WEB -type f | wc -l)\n"
    "if [ $WEB_FILES -gt 0 ] ; then\n"
    "  mkdir -p %(tmpdir)s/%(uploadSum)s/WEB\n"
    "  %(rsync)s -am --link-dest %(workdir)s/WEB/ %(workdir)s/WEB/ %(tmpdir)s/%(uploadSum)s/WEB/\n"
    "fi\n",
    rsync="rsync --chmod=a+rX",
    workdir=opts.workDir,
    tmpdir=tmpdir,
    includes=" ".join(pkgChecksums),
    architecture=opts.architecture,
    uploadSum=uploadSum,
    md5sum=md5sum )
  # Copy bootstrap-driver.txt, cmsos. Given we can rollback now
  # there is no risk of screwing up the repository by copying some unwanted
  # driver / cmsos.
  # FIXME: copy also some predefined web area, so that we have rollbackable web
  #        area?
  copyByProducts = format("echo Looking for local Bootstrap-driver\n"
                          "cd %(workdir)s/%(architecture)s\n"
                          "if [ 'X%(BootstrapPackage)s' != 'X' ] ; then\n"
                          "  mkdir -p %(tmpdir)s/%(uploadSum)s/drivers \n"
                          "  [ -f %(BootstrapPackage)s/%(architecture)s-driver.txt ]      && cp %(BootstrapPackage)s/%(architecture)s-driver.txt      %(tmpdir)s/%(uploadSum)s/drivers/\n"
                          "  [ -f %(BootstrapPackage)s/%(architecture)s-driver-comp.txt ] && cp %(BootstrapPackage)s/%(architecture)s-driver-comp.txt %(tmpdir)s/%(uploadSum)s/drivers/\n"
                          "fi\n"
                          "echo Looking for local cms common build\n"
                          "if [ 'X%(CMSCommonPackage)s' != 'X' ] ; then\n"
                          "  [ -f common/cmsos ] cp common/cmsos %(tmpdir)s/%(uploadSum)s\n"
                          "fi\n",
                          workdir=opts.workDir,
                          tmpdir=tmpdir,
                          architecture=opts.architecture,
                          uploadSum=uploadSum,
                          BootstrapPackage=BootstrapPackage,
                          CMSCommonPackage=CMSCommonPackage)
  remoteSourceRE=re.compile (".*:.*/.*")
  sources = ""
  for pkg in [pkg for pkg in fullPackageList if exists (pkg.rpmLocation())]:
    # FIXME: this should really parse the url to determine the output filename
    #        rather than relying on the fact we always end up urls with
    #        /some-file.tar.gz
    sourceFiles = [(source.rsplit("/", 1)[1], getUrlChecksum(source))
                   for source in pkg.sources
                   if remoteSourceRE.match(source)]
    for filename, checksum in sourceFiles:
      checksum_in=checksum[0:2]
      if exists(join(opts.workDir, "SOURCES", "cache", checksum_in, checksum, ".no-cmsrep-upload")): continue
      sources += format(
        "SRC_DIR=%(tmpdir)s/%(uploadSum)s/SOURCES\n"
        "mkdir -p $SRC_DIR/cache/%(checksum_in)s/%(checksum)s\n"
        "mkdir -p $SRC_DIR/%(architecture)s/%(group)s/%(name)s/%(version)s\n"
        "ln -f %(workdir)s/SOURCES/cache/%(checksum_in)s/%(checksum)s/%(filename)s $SRC_DIR/cache/%(checksum_in)s/%(checksum)s/%(filename)s\n"
        "ln -sf ../../../../cache/%(checksum_in)s/%(checksum)s/%(filename)s $SRC_DIR/%(architecture)s/%(group)s/%(name)s/%(version)s/%(filename)s\n",
        workdir=opts.workDir,
        tmpdir=tmpdir,
        architecture=opts.architecture,
        group=pkg.group,
        name=pkg.name,
        version=pkg.version,
        filename=filename,
        uploadSum=uploadSum,
        checksum=checksum,
        checksum_in=checksum_in)
  
  (err, out) = executeScript(opts, "\n".join([createEmptyRepository, hardLinkPackages, copyByProducts, sources]))
  logAndDieOnError(err, "Error while creating the local repository.")

  repoInfo = {"uploadDir": uploadDir,
              "repository": opts.repository,
              "rsync": format("rsync -e 'ssh -p %(port)s' --rsync-path=/usr/bin/rsync --chmod=a+rX",port=opts.uploadPort),
              "server": opts.uploadServer,
              "user": opts.uploadUser}

  upload = format(
                  "%(rsync)s -a %(tmpdir)s/ %(user)s@%(server)s:%(uploadDir)s/upload/\n",
                  tmpdir=tmpdir,
                  **repoInfo)
  (err, msg) = executeScript(opts, upload, True)
  if err: logAndDieOnError(err, "Error while uploading to remote repository.")

  upload = format(
                  "/data/scripts%(useDev)s/upload.sh CLONE '%(architecture)s' '%(repository)s' '%(cmspkg_upload_repo)s' '%(tmpUploadDir)s'\n",
                  tmpdir=tmpdir,
                  tmpUploadDir=basename(uploadDir),
                  architecture=opts.architecture,
                  cmspkg_upload_repo=cmspkg_upload_repo,
                  useDev=useDev,
                  **repoInfo)
  (err, msg) = executeScript(opts, upload, False)
  if err:
    if (err >> 8) != 19:
      log("Parallel upload session succeded before us. Starting uploading procedure from scratch. This will check again build area consistency.")
    else:
      logAndDieOnError(err, "Error while uploading to remote repository.")
    return False
  log("Upload successfully finished")
  return True
            
def remove_help ():
    log ("cmsBuild delete <package>")

allOk = lambda x,y: x and y
someOk = lambda x,y: x or y

def doDeprecateLocal (opts, args, factory):
  rpmCacheUpdate(opts)
  fullPackageList = allPackagesToUpload(args, factory)
  executeScript(opts, deprecateLocalCommand(opts, fullPackageList))

def getSpecRepository (url, options):
    destTmpDir = abspath (options.tempDirPrefix)
    destTgz = join(destTmpDir,"CMSDIST.tgz")
    destDir = abspath ("CMSDIST")
    if exists (destTgz):
        unlink (destTgz)
    if "module=" not in url:
        url = url + "&module="+ DEFAULT_SPEC_REPOSITORY_MODULE
    if "strategy=" not in url:
        url = url + "&strategy=checkout"        
    if "timestamp" not in url:
        url = url + "&timestamp=%s" % strftime ("%Y%m%d%H%M%S") 
    if "output=" not in url:
        url = url + "&output=/%s.tgz" % DEFAULT_SPEC_REPOSITORY_MODULE        
    download (url, destTmpDir, options)
    command = "tar xzvf %(destTgz)s CMSDIST " % locals ()
    message = "ERROR: Error while trying to download CMSDIST from a remote source:"
    ok = executeWithErrorCheck (command, message)
    if not ok:
        sys.exit (1)
    return destDir

def rpmCacheUpdate(opts):
    if hasattr (opts, "bootstrap") and opts.bootstrap == True:
        rpm_db_cache.clear()
        rpmQueryCommand = "%s ; rpm -qa --queryformat '%%{NAME} %%{RELEASE} %%{SUMMARY}\n' | sed 's|CMS Experiment package SpecChecksum:||'" % rpmEnvironmentScript
        error, output = getstatusoutput (rpmQueryCommand)
        if error:
            die("Error while executing rpm -qa.\n%s" % output)
        for p in output.split("\n"):
            n,r,c = p.split(" ",2)
            rpm_db_cache[n]=[r,c]
    return

if __name__ == "__main__":
    # Stop processing if SCRAM runtime env is set to avoid picking up
    # python from cms external area
    if environ.has_key("SCRAMRT_SET"):
        fatal ("You have SCRAM runtime environment set. Please run it from a fresh shell.")
    # Avoid locale related issues with gcc output.
    environ["LANG"] = "C"
    opts, args = parseOptions()

    packages = {}
    #tags_cache = TagCacheAptImpl (opts)
    try:
      # We only support three different workflows:
      #
      # * cmsBuild [--no-bootstrap] build <package> [<additional packages>]
      # * cmsBuild [--no-bootstrap] [--sync-back] upload <package> [<additional packages>]
      # * cmsBuild [--no-bootstrap] deprecate-local <package> [<additional packages>]
      #
      # where all workflows include a bootstrap step (unless --no-bootstrap) is
      # specified and upload implies building the same packages.
      commandSpec = []
      
      if opts.bootstrap:
        commandSpec.append("bootstrap")

      if not exists(abspath(opts.cmsdist)) and not "://" in opts.cmsdist:
        cmsdist = abspath(opts.cmsdist)
        fatal("Wrong path specified for CMSDIST: %s.\nNothing done." % cmsdist)

      if args[0] != "deprecate-local":
        commandSpec.append("build")

      if args[0] != "build":
        commandSpec.append(args[0])

      log("The following commands will be executed:\n %s" % 
          "\n".join (["* %s" % spec for spec in commandSpec]), DEBUG)
        
      # Create the work area and a tmp dir for it it does not exists and cd to it.
      opts.tempdir = join(opts.workDir, opts.tempDirPrefix)
      getstatusoutput("rm -rf %s/cache; mkdir -p %s/cache" % (opts.tempdir, opts.tempdir))
      chdir (opts.workDir)
      CMSPKG_CMD = join(opts.workDir,"common",CMSPKG_CMD) + " --architecture %s" % opts.architecture

      #Process level lock: To make sure that there is only one cmsBuild process is running for this work area
      procLock = cmsLock(opts.workDir)
      if not procLock:
          fatal ("There is already a cmsBuild process running for workdir %s." % opts.workDir)

      executeWithErrorCheck ("rm -rf %s" % join(opts.workDir, opts.tempDirPrefix, "BUILDROOT"),"Unable to remove BUILDROOT directory.")
	  
      # Checkout if a tag is specified for CMSDIST. If it is checkout the package
      # in a temporary directory and keep track of the path to it.
      if "://" in opts.cmsdist:
        opts.cmsdist = getSpecRepository(opts.cmsdist, opts)

      #If cmsdist does not have opts.pipPackage then use system pip
      if opts.pipPackage and not exists(join(opts.cmsdist,opts.pipPackage+".spec")):
        opts.pipPackage = None
      
      if not exists(opts.cmsdist):
        fatal("A CMSDIST checkout (or a tag) is required in order to build.")
      # Make sure that the build architecture and the actual platform we
      # are running on are compatible.
      if opts.architecture.startswith("osx"):
        if not sys.platform == "darwin":
          fatal("Cannot build architecture %s on linux. Did you mean %s?" % (opts.architecture, opts.architecture.replace("osx106", "slc5")))
      if opts.architecture.startswith("slc"):
        if not sys.platform.startswith("linux"):
          fatal("Cannot build architecture %s on osx. Did you mean %s?" % (opts.architecture, opts.architecture.replace("slc5", "osx106")))
      
      # Force the architecture and extract ancillary options like the compiler 
      # version, the compiler name, whether to force 32 bit builds on linux and
      # whether the system compiler should being used.
      # Cross check that:
      # * If on macosx or in online, check that the system compiler has the same
      #   version as the one specified in the architecture string.
      # * If we are not using the system compiler, a spec file with the 
      #   compiler name exists and matches the architecture.
      m = re.match("[^_]+_[^_]+_([a-z]+)([0-9]+)", opts.architecture)
      if not m:
        fatal("Malformed architecture string.")
      opts.compilerName, compactCompilerVersion = m.groups()
      opts.compilerVersion = ".".join([x for x in compactCompilerVersion])
      
      # Check validity of the system compiler.
      if opts.compilerName == "gcc" and sys.platform == "darwin":
        if detectCompilerVersion("gcc") == opts.compilerVersion:
          opts.systemCompiler = True
        else:
          opts.systemCompiler = False
      else:
        opts.systemCompiler = False
      
      # Check validity of the spec file.
      if not opts.systemCompiler:
        pathname = join (opts.cmsdist, "%s.spec" % opts.compilerName)
        try:
          lines = open(pathname).readlines()
        except IOError, e:
          fatal("The spec %s does not match the requested architecture %s." % (pathname, opts.architecture))
        (group, name, version) = parseRPMLine(lines, opts)
        version = version.split ("-")[0]
        if name != opts.compilerName or version != opts.compilerVersion:
          msg = "The compiler %s-%s (specified in %s) differs from %s-%s (specified by the architecture %s)."
          fatal(msg % (name, version, pathname, opts.compilerName,
                       opts.compilerVersion, opts.architecture))
      
      arch_data = opts.architecture.split("_",2)
      arch_data[2] = re.sub('^[a-z]+','',arch_data[2])
      opts.rpmQueryDefines = '--define "cmscompilerv  %s" --define "cmsos %s"' % (arch_data[2], "_".join(arch_data[0:2]))
      environ["SCRAM_ARCH"] = opts.architecture
      environ["VO_CMS_SW_DIR"] = opts.workDir
      
      # Tags cache always needs to be there.
      tags_cache = TagCacheAptImpl(opts)
      successfulTransaction = False 
      successfulBootstrapEnv = False
      while not successfulTransaction:
        successfulTransaction = True 
        checksums_cache = {}
        factory = PackageFactory(opts)
        for command in commandSpec:
          if command == "bootstrap":
            # If the apt-init.sh file is missing, do the bootstrap,
            # parse the output to find the init.sh and link it to
            # apt-init.sh, so that next time this stage will we skipped.
            #
            # Source the apt-init.sh file and setup the environment,
            # update the apt cache.
            rpmEnvironmentScript = join(opts.workDir, opts.architecture, "rpm-env.sh")
            if not exists(rpmEnvironmentScript):
              envSh = bootstrap(opts)
              symlink(envSh.replace(opts.workDir+"/"+opts.architecture,"."), rpmEnvironmentScript)
            rpmEnvironmentScript = "source "+rpmEnvironmentScript
            tags_cache.update()
          elif command == "deprecate-local":
            doDeprecateLocal(opts, args[1:], factory)
          elif command == "build":
            build(opts, args[1:], factory)
          elif command == "upload":
            # We continue trying unless some fatal error occurs (which exits
            # immediately).  or the remote repository is not consistent with the
            # current state.
            successfulTransaction = upload(opts, args[1:], factory)
            cleanup_server_upload(opts)
            if not successfulTransaction:
              log("Looks like repository changed while we were building. Trying again.")
    except KeyboardInterrupt:
        log ("User requested to abort. Exiting.")
        sys.exit (1)
    except RpmBuildFailed, e:
        log ("Package %s could not build. Final lines of the build log are: " % e.pkg.name)
        logfile = open("%s/log" % e.pkg.builddir).readlines ()
        for line in logfile[-10:]:
          log(line)
        sys.exit (1)
    except RpmInstallFailed, e:
        log("The installation of %s could not be completed for the following reason:")
        log(e.why)
        sys.exit (1)
    except NotCorrectlyBootstrapped, e:
        log("""FATAL: While it seems that you have run bootstrap.sh, 
               the bootstrapped area actually looks broken for the following reason:""")
        log (e.why)
        sys.exit (1)
    except FileNotFound, e:
        log ("""ERROR! File not found: %(filename)s""" % e.__dict__)
        sys.exit (1)
    except PlatformDetectionError, e:
        log("""ERROR: Unable to detect the architecture:""")
        log("%s" % e)
        sys.exit (1)
