#!/usr/bin/python -u
#
# Driver script for building rpms from a configuration specified in CMSDIST.
#
from os.path import abspath, join, exists, isdir, basename, dirname
from os import popen, getenv, symlink, listdir, readlink, unlink, getpid
from os import chdir, getcwd, environ, walk, sep, kill
from getpass import getuser
from tempfile import mkdtemp, mkstemp, NamedTemporaryFile
from commands import getstatusoutput
from urllib2 import urlopen, URLError
from time import strftime
import sys
import copy
from ConfigParser import ConfigParser
from ConfigParser import InterpolationMissingOptionError
import re, os
import traceback
from optparse import OptionParser, OptionGroup
import fnmatch
from shutil import rmtree
import urllib2
from glob import glob
import itertools
import pickle
from hashlib import sha256
from cmsBuild_consts import *

logLevel = 10
NORMAL = 10
DEBUG = 20
TRACE = 30
DEFAULT_CVS_SERVER = ":pserver:anonymous@cmscvs.cern.ch:2401/local/reps/CMSSW"
DEFAULT_CVS_PASSWORD = "AA_:yZZ3e"
DEFAULT_SPEC_REPOSITORY_MODULE = "CMSDIST"
CMSPKG_CMD = "cmspkg"
REF_CMSPKG_CMD = None
SERVER_TMP_UPLOAD_DIRECTORY = None
rpmEnvironmentScript = "true"
pip_package_env_script = ""
PKGFactory = None
SystemCompilerVersion = {}
BlackListReferencePkgs = []
reference_rpm_db_cache = {}

removeInitialSpace = re.compile("^[ ]*", re.M)
cmsBuildFilename = abspath(__file__)


def fatal(message):
    print "ERROR: " + message
    sys.exit(1)


def die(message):
    fatal(message)


# Minimal string sanitization.
def sanitize(s):
    return re.sub("[^a-zA-Z_0-9*./-]", "", s)


def log(message, level=0):
    """ Asynchronous printouts method. Level should be NORMAL when a message
is intended to be seen by the user, DEBUG, when it's intended to be seen only
by the developer, and TRACE when it's a message that is describing state
of the action scheduler/worker during the build.
    """
    if callable(message):
        message = message()
    if level <= logLevel:
        message = removeInitialSpace.sub("", message)
        print message


def setLogLevel(options):
    global logLevel
    if options.trace:
        logLevel = TRACE
    elif options.debug:
        logLevel = DEBUG
    else:
        logLevel = NORMAL


# Check of online arch
def isOnline(arch):
    if 'onl' in arch: return True
    return False


def isDefaultRevision(rev):
    if rev == '1' or rev.startswith('1.'): return True
    return False


# We have our own version rather than using the one from os
# because the latter does not work seem to be thread safe.
def makedirs(path):
    returncode, out = getstatusoutput("mkdir -p %s" % (path,))
    if returncode != 0:
        raise OSError("makedirs() failed (return: %s):\n%s" % (returncode, out))


def getPackages(packages): return [PKGFactory[p] for p in packages]


def detectCompilerVersion(compilerName):
    global SystemCompilerVersion
    if compilerName in SystemCompilerVersion: return SystemCompilerVersion[compilerName]
    (error, version) = getstatusoutput(COMPILER_DETECTION[compilerName])
    if error: raise UnknownCompiler()
    SystemCompilerVersion[compilerName] = version.strip("\n")
    return SystemCompilerVersion[compilerName]


rpm_db_cache = {}


#################################################################
# Utilities functions for installing packages from ref repository#
#################################################################
def should_install_from_reference(pkg):
    if not pkg.options.reference: return False
    if len([True for ex in BlackListReferencePkgs if ex.match(pkg.name)]): return False
    return is_package_installed(pkg, reference_rpm_db_cache)


def get_cmspkg_repository(cmspkg):
    e, o = getstatusoutput("%s repository" % cmspkg)
    if e:
        print "Error: Unable to run ", ref_cmspkg
        print o
        exit(1)
    data = {}
    for l in o.split("\n"):
        if ":" in l:
            x = [i.strip() for i in l.split(':', 1)]
            data[x[0]] = x[1]
    return data


def is_package_installed(pkg, rpm_cache):
    return ((pkg.pkgName() in rpm_cache) and
            (rpm_cache[pkg.pkgName()][0] == pkg.pkgRevision) and
            (rpm_cache[pkg.pkgName()][1] == pkg.checksum))


def check_reference(opts):
    global REF_CMSPKG_CMD, BlackListReferencePkgs
    if not opts.reference: return
    ref_cmspkg = join(opts.reference, "common", "cmspkg")
    if not exists(ref_cmspkg):
        print "Error: Path %s is not a valid cmspkg installation area" % opts.reference
        exit(1)
    REF_CMSPKG_CMD = "%s -a %s" % (ref_cmspkg, opts.architecture)
    ok = True
    # ref_data = get_cmspkg_repository (REF_CMSPKG_CMD)
    # local_data = get_cmspkg_repository (CMSPKG_CMD)
    # for v in [ "Server", "Repository", "ServerPath"]:
    #  if (not v in ref_data) or (not v in local_data): ok = False
    #  elif ref_data[v]!=local_data[v]: ok = False
    if not ok:
        print "Error: Can not use directory %s as cmspkg reference area." % opts.reference
        print "Error: Repository details mismatched"
        print "Local Server:", local_data
        print "Reference Server:", ref_data
        exit(1)
    log("Using reference repository:%s" % opts.reference, DEBUG)
    black_list_file = join(dirname(cmsBuildFilename), "black_list_reference_packages.txt")
    black_list_pkgs = [opts.blackList]
    if exists(black_list_file): black_list_pkgs += open(black_list_file).readlines()
    for pkgs in [p.strip() for p in black_list_pkgs]:
        if (not pkgs) or (pkgs.startswith("#")): continue
        for pkg in [p.strip() for p in pkgs.split(",")]:
            if pkg:
                BlackListReferencePkgs.append(re.compile("^" + pkg + "$"))
                log("Black listing package %s" % pkg, DEBUG)
    rpmCacheUpdate(opts, reference_rpm_db_cache, REF_CMSPKG_CMD + " env -- ")
    return


def install_reference(pkg):
    ref_permission_error = 'Error: You do not have write permission'
    log("About to build reference package %s using cmspkg..." % pkg.pkgName(), DEBUG)
    command = "%s env -- rpm -qi %s" % (REF_CMSPKG_CMD, pkg.pkgName())
    error, info = getstatusoutput(command)
    if ref_permission_error in info: error = False
    if error:
        log("Command:\n %(command)s failed with the following message: %(info)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, info)
    command = "%s env -- rpm -q --provides %s" % (REF_CMSPKG_CMD, pkg.pkgName())
    error, provides = getstatusoutput(command)
    if 'Error: You do not have write permission' in info: error = False
    if error:
        log("Command:\n %(command)s failed with the following message: %(provides)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, provides)
    pkg_parts = pkg.pkgName().split("+", 2)
    args = {"cmsroot": pkg.options.workDir, "refroot": pkg.options.reference, "cmsplatf": pkg.options.architecture}
    args['pkgdir'] = join(pkg.options.architecture, *pkg_parts)
    tmp_path = join(pkg.options.tempdir, "reference", pkg.pkgName())
    makedirs(tmp_path)
    tmp_spec = join(tmp_path, "package.spec")
    spec = open(tmp_spec, "w")
    infoReg = re.compile("^(Name|Version|Release|Group|License|Packager|Vendor|Summary)\s*:.*")
    for l in info.split("\n"):
        if infoReg.match(l):
            spec.write(l + "\n")
    for l in provides.split("\n"):
        if ref_permission_error in l: continue
        spec.write("Provides: " + l + "\n")
    spec.write("Obsoletes: %s\n" % pkg.pkgName())
    spec.write("Prefix: %s\n" % pkg.options.installDir)
    spec.write(REFERENCE_PACKAGE_POST % args)
    spec.close()
    command = "%s; rpmbuild -bb --define '_topdir %s' %s" % (rpmEnvironmentScript, tmp_path, tmp_spec)
    error, output = getstatusoutput(command)
    if error:
        log("Command:\n %(command)s failed with the following message: %(output)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, output)
    e, rpm_path = getstatusoutput("find %s -name '*.rpm'" % (tmp_path))
    command = "%s ; rpm -Uvh --prefix %s %s" % (rpmEnvironmentScript, pkg.options.workDir, rpm_path)
    error, output = getstatusoutput(command)
    if error:
        log("Command:\n %(command)s failed with the following message: %(output)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, output)


############################################################

def downloadUrllib2(source, destDir, options, cmscache=False):
    try:
        dest = "/".join([destDir.rstrip("/"), basename(source)])
        req = urllib2.Request(source, headers={"Cache-Control": "no-cache"})
        s = urllib2.urlopen(req)
        f = file(dest + ".tmp", "w")
        # Read in blocks to avoid using too much memory.
        block_sz = 8192 * 16
        while True:
            buffer = s.read(block_sz)
            if not buffer:
                break
            f.write(buffer)
        f.close()
        os.rename(dest + ".tmp", dest)
    except URLError, e:
        if cmscache:
            log("Internal cached file not available %s: %s" % (source, e), DEBUG)
        else:
            log("Error while downloading %s: %s" % (source, e))
        return False
    except Exception, e:
        log("Error while downloading %s: %s" % (source, e))
        return False
    return True


def parseUrl(url, requestedKind=None, defaults={}, required=[]):
    match = re.match("([^+:]*)([^:]*)://([^?]*)(.*)", url)
    if not match:
        raise MalformedUrl(url)
    parts = match.groups()
    protocol, deliveryProtocol, server, arguments = match.groups()
    arguments = arguments.strip("?")
    # In case of urls of the kind:
    # git+https://some.web.git.repository.net
    # we consider "https" the actual protocol and
    # "git" merely the request kind.
    if requestedKind and not protocol == requestedKind:
        raise MalformedUrl(url)
    if deliveryProtocol:
        protocol = deliveryProtocol.strip("+")
    arguments.replace("&amp;", "&")
    args = defaults.items()
    parsedArgs = re.split("&", arguments)
    parsedArgs = [x.split("=") for x in parsedArgs]
    parsedArgs = [(len(x) != 2 and [x[0], True]) or x for x in parsedArgs]
    args.extend(parsedArgs)
    argsDict = dict(args)
    missingArgs = [arg for arg in required if arg not in argsDict]
    if missingArgs:
        raise MalformedUrl(url, missingArgs)
    return protocol, server, argsDict


def parseTcUrl(url):
    scheme, server, args = parseUrl(url, requestedKind="cmstc",
                                    defaults={"cvsroot": DEFAULT_CVS_SERVER,
                                              "passwd": DEFAULT_CVS_PASSWORD},
                                    required=["tag", "output"])
    return scheme, server, args


def parseCvsUrl(url):
    scheme, cvsroot, args = parseUrl(url, requestedKind="cvs",
                                     defaults={"strategy": "export",
                                               "tag": "HEAD",
                                               "passwd": DEFAULT_CVS_PASSWORD},
                                     required=["module", "output"])
    if not cvsroot:
        cvsroot = DEFAULT_CVS_SERVER
    cvsroot = cvsroot.replace(":/", ":2401/")
    args["tag"] = re.sub(re.compile("^-r"), "", args["tag"])
    if "export" not in args:
        args["export"] = args["module"]
    args["cvsroot"] = cvsroot
    return (scheme, cvsroot, args)


def parseSvnUrl(url):
    scheme, root, args = parseUrl(url, requestedKind="svn",
                                  defaults={"strategy": "export",
                                            "revision": "HEAD"},
                                  required=["module", "output"])
    if "export" not in args:
        args["export"] = args["module"]
    if "scheme" in args:
        scheme = args["scheme"]
    if not scheme in ["svn", "http", "https", "file"] and (not scheme.startswith('svn+')):
        scheme = "svn+" + scheme
    args["svnroot"] = "%(scheme)s://%(root)s" % {"scheme": scheme, "root": root}
    return (scheme, root, args)


def parseGitUrl(url):
    protocol, gitroot, args = parseUrl(url, requestedKind="git",
                                       defaults={"obj": "master/HEAD"})
    parts = args["obj"].rsplit("/", 1)
    if len(parts) != 2:
        parts += ["HEAD"]
    args["branch"], args["tag"] = parts

    if not "export" in args:
        args["export"] = basename(re.sub("\.git$", "", re.sub("[?].*", "", gitroot)))
        if args["tag"] != "HEAD":
            args["export"] += args["tag"]
        else:
            args["export"] += args["branch"]

    if not "output" in args:
        args["output"] = args["export"] + ".tar.gz"
        args["gitroot"] = gitroot
    if not "filter" in args:
        args["filter"] = "*"
    args["filter"] = sanitize(args["filter"]);
    return protocol, gitroot, args


def createTempDir(workDir, subDir):
    tempdir = join(workDir, subDir)
    if not exists(tempdir):
        makedirs(tempdir)
    tempdir = mkdtemp(dir=tempdir)
    return tempdir


def executeWithErrorCheck(command, errorMessage):
    log(command, DEBUG)
    error, output = getstatusoutput(command)
    if error:
        log(errorMessage + ":")
        log("")
        log(command)
        log("")
        log("resulted in:")
        log(output)
        return False
    log(output, DEBUG)
    return True


def packCheckout(tempdir, dest, *exports):
    """ Use this helper method when download protocol is like cvs/svn/git
        where the code is checked out in a temporary directory and then tarred
        up.
    """
    export = " ".join(['"%s"' % x for x in exports])
    packCommand = """cd %(tempdir)s; tar -zcf "%(dest)s" %(export)s """
    packCommand = packCommand % locals()
    errorMessage = "Error while creating a tar archive for checked out area"
    return executeWithErrorCheck(packCommand, errorMessage)


def downloadSvn(source, dest, options):
    scheme, svnroot, args = parseSvnUrl(source)
    tempdir = createTempDir(options.workDir, options.tempDirPrefix)
    exportDir = join(tempdir, "checkout", args["export"])
    if not exists(exportDir):
        makedirs(exportDir)
    args["dest"] = join(dest, args["output"].lstrip("/"))
    args["tempdir"] = tempdir
    args["exportdir"] = exportDir.rsplit("/", 1)[1]
    args["exportpath"] = exportDir.rsplit("/", 1)[0]
    if not args["revision"].isdigit():
        args["revision"] = '"' + args["revision"] + '"'
    command = """cd %(exportpath)s ; svn %(strategy)s --force --non-interactive --trust-server-cert -r%(revision)s "%(svnroot)s" "%(exportdir)s" """
    command = command % args
    message = "Error while downloading files from subversion repository"
    ok = executeWithErrorCheck(command, message)
    return ok and packCheckout(args["exportpath"], args["dest"], args["export"])


def downloadCvs(source, dest, options):
    protocol, cvsroot, args = parseCvsUrl(source)
    tempdir = createTempDir(options.workDir, options.tempDirPrefix)
    pserverUrlRe = re.compile(":pserver:.*")
    isPserver = pserverUrlRe.match(cvsroot)
    cvspassFilename = None
    if args.has_key("passwd") and isPserver:
        cvspassFilename = join(tempdir, "cvspass")
        f = open(join(tempdir, "cvspass"), "w")
        f.write("/1 %(cvsroot)s %(passwd)s\n" % args)
        f.close()
    exportDir = join(tempdir, "checkout")
    if not exists(exportDir):
        makedirs(exportDir)
    args["dest"] = join(dest, args["output"].lstrip("/"))
    args["tempdir"] = tempdir
    args["exportdir"] = exportDir
    args["passexport"] = (cvspassFilename and "CVS_PASSFILE=%s" % cvspassFilename) or ""
    command = """cd %(exportdir)s ; %(passexport)s cvs -z6 -Q -d"%(cvsroot)s" %(strategy)s -d"%(export)s" -r"%(tag)s" "%(module)s" """
    command = command % args
    message = "Error while executing a %(strategy)s from CVS:" % args
    ok = executeWithErrorCheck(command, message)
    return ok and packCheckout(exportDir, args["dest"], args["export"])


def downloadTc(source, dest, options):
    protocol, tagsSource, args = parseTcUrl(source)
    tempdir = createTempDir(options.workDir, options.tempDirPrefix)
    args["tempdir"] = tempdir
    args["dest"] = join(dest, args["output"].lstrip("/"))
    args["pmLocation"] = abspath(join(dirname(cmsBuildFilename), 'cmspm'))
    if "extratags" in args:
        args["extratags"] = "--additional-tags " + args["extratags"]
    else:
        args["extratags"] = ""

    if 'baserel' not in args:
        command = """cd %(tempdir)s && %(pmLocation)s corel %(tag)s """
    else:
        command = '. ' + options.workDir + """/cmsset_default.sh && cd %(tempdir)s && %(pmLocation)s frombase %(tag)s %(baserel)s %(baserelver)s """
    command += """ %(extratags)s -e -o src/PackageList.cmssw"""
    command = command % args
    log("Downloading %(tag)s from cmsTC." % args, DEBUG)
    message = "Error while downloading sources using tag collector information."
    ok = executeWithErrorCheck(command, message)
    dirs = ["src"]
    if exists("/".join([args["tempdir"], "poison"])): dirs.append("poison")
    return ok and packCheckout(args["tempdir"], args["dest"], *dirs)


# Download a files from a git url.  We do not clone the remote reposiotory, but
# we simply pull the branch we are interested in and then we drop all the git
# information while creating a tarball.  The syntax to define a repository is
# the following:
#
# git:/local/repository?obj=BRANCH/TAG
# git://remote-repository?obj=BRANCH/TAG
# git+https://remote-repository-over-http/foo.git?obj=BRANCH/TAG
#
# If "obj" does not contain a "/", it's value will be considered a branch and TAG will be "HEAD".
# If "obj" is not specified, it will be "master/HEAD" by default.
# By default export is the <basename of the url without ".git">-TAG unless it is HEAD,
# in which case it will be  <basename of the url without .git>-BRANCH.
# One can specify an additional parameter
#
#     filter=<some-path>
#
# which will be used to pack only a subset of the checkout.
def downloadGit(source, dest, options):
    protocol, gitroot, args = parseGitUrl(source)
    tempdir = createTempDir(options.workDir, options.tempDirPrefix)

    exportpath = join(tempdir, args["export"])
    if protocol:
        protocol += "://"
    if not protocol and not gitroot.endswith(".git"):
        gitroot = join(gitroot, ".git")

    dest = join(dest, args["output"].lstrip("/"))
    args.update({"protocol": protocol, "tempdir": tempdir,
                 "gitroot": gitroot, "dest": dest,
                 "exportpath": exportpath})
    makedirs(exportpath)
    command = format("cd %(exportpath)s &&"
                     "git init &&"
                     "git pull --tags %(protocol)s%(gitroot)s refs/heads/%(branch)s &&"
                     "git reset --hard %(tag)s &&"
                     "find . ! -path '%(filter)s' -delete &&"
                     "rm -rf .git .gitattributes .gitignore", **args)
    error, output = getstatusoutput(command % args)
    if error:
        log("Error while downloading sources from %s using git.\n\n"
            "%s\n\n"
            "resulted in:\n%s" % (gitroot, command % args, output))
        return False
    return packCheckout(args["tempdir"], args["dest"], args["export"])


def downloadPip(source, dest, options):
    # Valid PIP URL formats are
    # pip://package/version?[pip_options=options&]output=/tarbalname
    # pip://package/version/tarbalname
    url_parts = source.split("pip://", 1)[1].split("?", 1)
    opts = []
    if len(url_parts) > 1: opts = url_parts[1].split("&")
    pkg = url_parts[0].split("/")
    pack = pkg[0].strip()
    if len(pkg) > 1: pack = pack + '==' + pkg[1].strip()
    tarball = source.rsplit("/", 1)[1]
    # newer pip will need this (but untested)
    #  comm = 'which pip; pip download --no-deps ' + dest + ' ' + pack
    tempdir = createTempDir(options.workDir, options.tempDirPrefix)
    pip_opts = "--no-deps --no-binary=:all:"

    for opt in opts:
        if opt[:12] == "pip_options=":
            pip_optsT = opt[12:].replace("+", " ").replace("%20", " ").replace("%3D", "=")
            # hack here a alternative source location
            pip_opts = ''
            spSrc = pip_optsT.split()
            for i in range(len(spSrc)):
                if 'ALTSRC' in spSrc[i]:
                    pack = spSrc[i + 1]
                    i = i + 1
                else:
                    pip_opts = pip_opts + ' ' + spSrc[i]
            break
    comm = ""
    if pip_package_env_script: comm = ". %s; " % pip_package_env_script
    comm = comm + ' which pip; pip download ' + pip_opts + ' -d ' + tempdir + ' ' + pack + '; /bin/ls ' + tempdir + '| grep -v files.list > ' + tempdir + '/files.list'
    error, output = getstatusoutput(comm)
    if error:
        log("Error while downloading sources from %s using pip.\n\n %s \n %s \n  %s \n " % (
            source, comm, error, output))
        return False

    comm2 = 'cd ' + tempdir + '; tar cfz ' + dest + '/' + tarball + ' files.list `cat files.list`'
    error, output = getstatusoutput(comm2)
    if error:
        log("Error while downloading sources from %s using pip.\n\n %s \n %s \n  %s \n " % (
            source, comm, error, output))
        return False

    return True


downloadHandlers = {'cvs': downloadCvs,
                    'cmstc': downloadTc,
                    'http': downloadUrllib2,
                    'https': downloadUrllib2,
                    'ftp': downloadUrllib2,
                    'ftps': downloadUrllib2,
                    'git': downloadGit,
                    'svn': downloadSvn,
                    'pip': downloadPip}


def getUrlChecksum(s):
    m = md5adder(s)
    return m.hexdigest()


def isProcessRunning(pid):
    running = False
    try:
        os.kill(pid, 0)
        running = True
    except:
        pass
    return running


class cmsLock(object):
    def __init__(self, dirname):
        self.piddir = join(dirname, ".cmsLock")
        self.pidfile = join(self.piddir, "pid")
        self.pid = str(getpid())
        self._hasLock = False
        self._hasLock = self._get()

    def __del__(self):
        self._release()

    def __nonzero__(self):
        return self._hasLock

    def _release(self, force=False):
        if (self._hasLock or force):
            try:
                if exists(self.piddir): getstatusoutput("rm -rf %s" % self.piddir)
            except:
                pass
        self._hasLock = False

    def _get(self, count=0):
        if count >= 5: return False
        pid = self._readPid()
        if pid:
            if pid == self.pid: return True
            if isProcessRunning(int(pid)): return False
        self._create()
        sleep(0.0001)
        return self._get(count + 1)

    def _readPid(self):
        pid = None
        try:
            pid = open(self.pidfile).readlines()[0]
        except:
            pid = None
        return pid

    def _create(self):
        self._release(True)
        try:
            makedirs(self.piddir)
            lock = open(self.pidfile, 'w')
            lock.write(self.pid)
            lock.close()
        except:
            pass


# Helper class which contains only the options that are
# relevant for download.
class DownloadOptions(object):
    def __init__(self, options):
        self.workDir = options.workDir
        self.tempDirPrefix = options.tempDirPrefix
        self.cmsdist = options.cmsdist


def getLocalSources(pkg, source_name, downloadDir, filename):
    # check if given package's source location is overwritten to local file
    options = pkg.options
    local_source_dict = options.localSources
    pkg_name = pkg.name
    if (not pkg_name in local_source_dict) or (not source_name in local_source_dict[pkg_name]):
        return

    local_source_path = local_source_dict[pkg_name][source_name].rstrip("/$")
    log("Package %s source %s is taken from local path  %s" % (pkg_name, source_name, local_source_path))
    cmd = None
    ls_basename = os.path.basename(local_source_path)
    ls_dirname = os.path.dirname(local_source_path)
    if filename.endswith(".rpm") or filename.endswith("none"):
        log("WARNING: the filename extension is not overwritable: %s " % filename)
        return

    elif os.path.isfile(local_source_path):
        cmd = "cp -f %(local_source_path)s %(downloadDir)s/%(filename)s" % locals()
    elif filename.endswith(".tgz") or filename.endswith(".tar.gz"):
        cmd = "cd %(ls_dirname)s; tar -czf %(downloadDir)s/%(filename)s %(ls_basename)s; cd -" % locals()
    elif filename.endswith(".tar.xz"):
        cmd = "cd %(ls_dirname)s; tar -cJf %(downloadDir)s/%(filename)s %(ls_basename)s; cd -" % locals()
    elif filename.endswith(".bz2"):
        cmd = "cd %(ls_dirname)s; tar -cvjSf %(downloadDir)s/%(filename)s %(ls_basename)s; cd -" % locals()
    elif filename.endswith(".zip"):
        cmd = "cd %(ls_dirname)s; zip -r %(downloadDir)s/%(filename)s %(ls_basename)s; cd -" % locals()
    else:
        fatal("DEVELOP ERROR file extension is unknown for: %s" % filename)

    log("The command executed to package local sources: %s" % cmd)
    error, output = getstatusoutput(cmd)
    if error:
        fatal("Error while packaging and moving local sources: \n\t error: %s \n\t error log: %s"
              "\n\t filename: %s \n\t source: %s \n\t local source path: %s " %
              (error, output, filename, source_name, local_source_path))
    return


def download(source, dest, options, pkg=None):
    # FIXME `options` are the same as `pkg.options`
    source_name = pkg.sourcesNumbers[source] if pkg else None

    # Syntactic sugar to allow the following urls for tag collector:
    #
    # cmstc:[base.]release[.tagset[.tagset[...]]]/src.tar.gz
    #
    # in place of:
    #
    # cmstc://?tag=release&baserel=base&extratag=tagset1,tagset2,..&module=CMSSW&export=src&output=/src.tar.gz
    if source.startswith("cmstc:") and not source.startswith("cmstc://"):
        url = source.split(":", 1)[1]
        desc, output = url.rsplit("/", 1)
        parts = desc.split(".")
        releases = [x for x in parts if not x.isdigit()]
        extratags = [x for x in parts if x.isdigit()]
        if extratags:
            extratags = "&extratags=" + ",".join(extratags)
        if len(releases) == 1:
            baserel = ""
            release = "tag=" + releases[0]
        elif len(releases) == 2:
            baserel = "&baserel=" + releases[0]
            release = releases[1]
        else:
            raise MalformedUrl(source)
        source = "cmstc://?%s%s%s&module=CMSSW&export=src&output=/%s" % (release, baserel, extratags, output)

    cacheDir = abspath(join(options.workDir, "SOURCES/cache"))
    urlTypeRe = re.compile("([^:+]*)([^:]*)://.*")
    match = urlTypeRe.match(source)
    if not urlTypeRe.match(source):
        raise MalformedUrl(source)
    downloadHandler = downloadHandlers[match.group(1)]
    checksum = getUrlChecksum(source)
    filename = source.rsplit("/", 1)[1]
    downloadDir = join(cacheDir, checksum[0:2], checksum)
    try:
        makedirs(downloadDir)
    except OSError, e:
        if not exists(downloadDir):
            raise downloadDir

    realFile = join(downloadDir, filename)
    # This will will use source from local file system if --source for package was passed
    if source_name and options.localSources:
        getLocalSources(pkg, source_name, downloadDir, filename)

    if exists(realFile):
        if not exists(join(dest, filename)):
            symlink(realFile, join(dest, filename))
        return True
    srepos = [options.repository]
    for exrepo in ['cms', 'comp', 'cms.week0', 'cms.week1']:
        if not exrepo in srepos: srepos.append(exrepo)
    success = False
    for repo in srepos:
        cachedFile = "%s/SOURCES/%s/%s/%s" % (options.server.rstrip("/"), repo, checksum, filename)
        downloadOptions = DownloadOptions(options)
        log("Trying to fetch cached file: %s" % cachedFile, DEBUG)
        getstatusoutput("rm -f %s" % join(downloadDir, ".no-cmsrep-upload"))
        success = downloadHandlers["http"](cachedFile, downloadDir, downloadOptions, True)
        if success: break
    if not success:
        log("Trying to fetch source file: %s" % source, DEBUG)
        success = downloadHandler(source, downloadDir, downloadOptions)
    if success:
        # if '/github.com/' in source:
        #    r=open (join (downloadDir, ".no-cmsrep-upload"), 'w')
        #    r.close ()
        f = open(join(downloadDir, "url"), 'w')
        f.write("%s\n" % source)
        f.close()
        if exists(realFile) and not exists(join(dest, filename)):
            symlink(realFile, join(dest, filename))
    return success


class MalformedUrl(Exception):
    def __init__(self, url, missingParams=[]):
        if not missingParams:
            self.args = ["ERROR: The following url is malformed: %(url)s." % locals()]
        else:
            self.args = ["ERROR: The following parameters are missing from url %(url)s: %(missingParams)s" % locals()]


class MalformedSpec(Exception):
    pass


class RpmBuildFailed(Exception):
    def __init__(self, package):
        self.args = ["Failed to build package %s." % package.name]
        self.pkg = package


class UnexpectedFile(Exception):
    def __init__(self, filename):
        self.args = ["""Unexpected file:\n %s\n
Please remove it and start again.""" % filename]


class RpmInstallFailed(Exception):
    def __init__(self, package, why=""):
        self.args = ["Failed to install package %s. Reason:\n%s" % (package.name, why)]
        self.pkg = package
        self.why = why


class UnableToDownload(Exception):
    pass


class FileNotFound(Exception):
    def __init__(self, filename):
        log(filename)
        self.filename = filename

    def __repr__(self):
        log("Unable to find file %s" % self.filename)


class NotCorrectlyBootstrapped(Exception):
    def __init__(self, why):
        self.why = why


class UnknownCompiler(Exception):
    pass


def tagToId(tag, origTag):
    return int((tag or 0) and (tag.replace(origTag, "") or 1))


def idToTag(tagId, origTag):
    if not tagId:
        return ""
    elif tagId == 1:
        return origTag
    else:
        return "%s%s" % (origTag, tagId)


# Parses the `### RPM <group> <package> <realversion>` header.
# Such a header defines the package name, group and real version
# for a given package.
# Notice that for a package which matches the compiler
# name we allow the overriding of its version with the one specified
# in the `compilerVersion` settings.
# Notice also that the one can specify /bin/sh commands in backticks
# for the version, so that stuff like the date can be added to the
# version (useful for IB and alikes).
# FIXME: notice that for compatibility with old packages, which were
# specifying a -CMSXYZ tag by hand, we remove such a suffix from
# the version. This is probably not needed anymore and can go.
def parseRPMLine(specLines, opts):
    findRpmRe = re.compile("^### RPM[ ]*([^ ]*)\s*([^ ]*)\s*(.*)")
    for line in specLines:
        match = findRpmRe.match(line)
        if not match:
            continue
        results = [x.strip(" ") for x in match.groups()]
        results[2] = re.sub("-CMS.*", "", results[2])
        group, name, version = results
        error, output = getstatusoutput("echo %s" % version)
        if error:
            raise MalformedSpec
        version = output.split("\n")[0]
        if opts.compilerVersion and name == opts.compilerName:
            version = opts.compilerVersion
        return (group, name, version)
    raise MalformedSpec


def parseNoCompilerLine(specLines):
    findNoCompilerRe = re.compile("^## NOCOMPILER")
    for line in specLines:
        if findNoCompilerRe.match(line):
            return True
    return False


def parseNoAutoDependencyLine(specLines):
    findNoDepRe = re.compile("^## NO_AUTO_DEPENDENCY")
    for line in specLines:
        if findNoDepRe.match(line):
            return True
    return False


def parseBuildRequireToolfileLine(specLines):
    findBRToolfileRe = re.compile("^## BUILDREQUIRE-TOOLFILE")
    for line in specLines:
        if findBRToolfileRe.match(line):
            return True
    return False


class PkgInfo(object):
    """ Minimal information about a package.
    """

    def __init__(self, pkg):
        self.name = pkg.name
        self.realVersion = pkg.realVersion
        self.group = pkg.group
        self.checksum = pkg.checksum
        self.cmsplatf = pkg.cmsplatf

    def id(self):
        return "%(group)s+%(name)s+%(realVersion)s" % self.__dict__


def getPkgName(filename):
    return re.match("(.*)-1-[1-9]+[.].*", basename(filename)).group(1)


def getPkgChecksumFile(officialRpmLocation, buildOptions=None):
    try:
        link = readlink(officialRpmLocation)
    except OSError:
        log("""ERROR! File %(officialRpmLocation)s is not a link!?!? 
                Are you running in an old cmsBuild.sh/install.sh area?
                If so, please remove the old package by doing:

                rm -rf %(officialRpmLocation)s

                and try again.
                """ % locals())
        sys.exit(1)
    if not exists(link):
        packageName = getPkgName(officialRpmLocation)
        cmsBuildExec = sys.argv[0]
        workdir = buildOptions.workDir and "--work-dir %s" % buildOptions.workDir or ""
        doNotBootstrap = buildOptions.bootstrap and "" or "--do-not-bootstrap"
        architecture = "--architecture %s" % buildOptions.architecture
        cmsdist = "--cmsdist %s" % buildOptions.cmsdist
        brokenLink = join(buildOptions.workDir, officialRpmLocation)
        log("""ERROR: File
        
                %(brokenLink)s 
        
                links to 
                
                %(link)s 
                
                but the latter does not exists. Please run:
                
                # %(cmsBuildExec)s %(cmsdist)s %(architecture)s %(workdir)s %(doNotBootstrap)s deprecate-local %(packageName)s
            
                to fix the problem and then try again.
            """ % locals())
        sys.exit(1)
    checksum = re.match(".*/(.*)/.*/.*", link).groups()[0]
    if not checksum:
        log("""ERROR: malformed link found: %(link)s.""" % locals())
        sys.exit(1)
    return checksum


class TagCacheAptImpl(object):
    """ Concrete implementation of the tag cache which relies on the
        apt repository information and locally found packages. Consistency
        is enforced by policy (only one person is allowed to upload packages
        for a given tag) and by checking at upload time that packages are not
        already in the repository.
    """

    def __init__(self, options):
        self.options = options

    def update(self):
        if self.options.bootstrap:
            error, output = getstatusoutput("%s update" % CMSPKG_CMD)
            if error:
                die("Error while executing cmspkg update.\n%s" % output)
            error, output = getstatusoutput("%s search --show-revision" % CMSPKG_CMD)
            if error:
                die("Error while executing cmspkg search.\n%s" % output)
            lines = [line for line in output.split("\n") if line]
            chksumRE = re.compile("\s+-\s+.*?SpecChecksum:")
            items = [chksumRE.sub(' ', line).split() for line in lines]
            pairs = [item[0:2] for item in items]
            try:
                self.cache = dict(pairs)
            except:
                die("Malformed cmspkg search output.")
            pairs = [[item[0], int(item[2])] for item in items]
            try:
                self.revision_cache = dict(pairs)
            except:
                die("Malformed cmspkg search output.")

    def requestTag(self, pkgInfo, tag):
        """ requestTag returns a unique tag (i.e. the mnemonic suffix at the
            end of the package name) based on what is found in the online
            database and in the local build area.

            @a pkgInfo is the structure which holds the information about a
               tag.
            @a tag the mnemonic tag to be used to keep track of different
               package builds. E.g. "cms" or "ge"
            @return a unique tag (ie cmsXXX) which can be used for the package.
        """
        tags = {}
        if self.options.bootstrap:
            matchingPackages = [(n, rpm_db_cache[n][1]) for n in rpm_db_cache if
                                (pkgInfo.id() in n) and (not n in self.cache)]
            matchingPackages += [(n, self.cache[n]) for n in self.cache if pkgInfo.id() in n]
            for name, checksum in matchingPackages:
                tempTag = name.replace(pkgInfo.id(), "").strip("-")
                tags[tempTag] = checksum
        for package in listdir(join("RPMS", pkgInfo.cmsplatf)):
            if pkgInfo.id() not in package:
                continue
            linkName = join("RPMS", pkgInfo.cmsplatf, package)
            checksum = getPkgChecksumFile(linkName, self.options)
            tempTag = getPkgName(package).replace(pkgInfo.id(), "").strip("-")
            tags[tempTag] = checksum
        # Use --force-tag to always append the tag (e.g. "-cms") to the package name,
        # even if it is the first version being built.
        for i in itertools.count(1 if self.options.forcetag else 0):
            finalTag = idToTag(i, tag)
            if finalTag not in tags:
                break
        return finalTag

    def getTag(self, pkg):
        """ getTag looks up for a tag associated to an md5 sum the following way.
        1) Look up in the cache cmspkg search results.
        2) Looks up in RPMS/cache/<checksum> to see if a package is already there.
        """
        output = ""
        if self.options.bootstrap:
            matchingPackages = [n for n in self.cache if self.cache[n] == pkg.checksum]
            matchingPackages += [n for n in rpm_db_cache if rpm_db_cache[n][1] == pkg.checksum]
            if len(matchingPackages) > 1:
                orderedPackages = []
                for n in matchingPackages:
                    if exists(
                            "%s/RPMS/cache/" % self.options.workDir + "%(checksum)s/%(cmsplatf)s/" % pkg.__dict__ + n + "-%(rpmVersion)s-%(pkgRevision)s.%(cmsplatf)s.rpm" % pkg.__dict__):
                        orderedPackages.insert(0, n)
                    else:
                        orderedPackages.append(n)
                matchingPackages = orderedPackages
            log("Matching Packages all %s: %s" % (pkg.checksum, ",".join(matchingPackages)), DEBUG)
            if len(matchingPackages):
                output = matchingPackages[0]
            else:
                return None
        else:
            try:
                assert (pkg.cmsplatf and pkg.cmsplatf != "%cmsplatf")
                assert (pkg.checksum and pkg.checksum != "%checksum" and pkg.checksum != "%{nil}")
                rpmCachePath = join(abspath("RPMS"),
                                    "cache/%(checksum)s/%(cmsplatf)s" % pkg.__dict__)
                if "%{" in rpmCachePath:
                    print "ERROR: you seem to be using an old rpm-preamble.file in your CMSDIST."
                    print "Please make sure you update it to revision 1.20 at least."
                    sys.exit(1)
                files = listdir(rpmCachePath % pkg.__dict__)
                if len(files) > 1 + len(pkg.subpackages):
                    log("""ERROR: %s structure is hoosed. You might want to do:
                            cmsBuild remove %s""" % (rpmCachePath,
                                                     getPkgName(files[0])))
                    sys.exit(1)
                elif not len(files):
                    return None
                output = getPkgName(files[0])
            except OSError:
                return None

        if not output:
            return None
        fullVersion = output.rsplit("+", 1)[1]
        if "-" not in fullVersion:
            return ""
        tag = fullVersion.rsplit("-", 1)[1]
        # Return tag if it is not part of realVersion
        if not pkg.realVersion.endswith("-" + tag):
            return tag
        return ""

    def packageChecksums(self, package):
        """
        """
        assert (False and "Not implemented for the time being.")


global tags_cache
tags_cache = None


class CacheProxy(object):
    def __init__(self, cache, decorator):
        """ This object is responsible for caching object but keeping in mind the fact that
            different architectures will
        """
        self.__cache = cache
        self.__decorator = decorator

    def __getitem__(self, name):
        return self.__cache.__getitem__(self.__decorator(name))

    def __setitem__(self, name, item):
        self.__cache.__setitem__(self.__decorator(name), item)

    def has_key(self, name):
        return self.__cache.has_key(self.__decorator(name))


class ArchitectureDecorator(object):
    def __init__(self, architecture):
        self.__architecture = architecture

    def __call__(self, name):
        return self.__architecture + name


global checksums_cache
checksums_cache = {}

# Silence the deprecation warning until we move completely to 2.6.X
import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)
try:
    from md5 import new as md5adder
except ImportError:
    from hashlib import md5 as md5adder


def calculateHumanReadableVersion(pkg):
    # This takes care of converting a checksum to something human-readable.
    #  * If the package has a revision different than 1, we assume that it is
    #    an old style one and we return the realVersion as version.
    #  * If the checksum is available in the DB, we use the tag, rather than
    #    the checksum.
    #  * If the checksum is not in the DB, but an official tag is requested,
    #    we associate the checksum to the tag, possibly adding an incremental
    #    number to it if a given package/version already uses it.

    if not isDefaultRevision(pkg.pkgRevision):
        # lange - 080727 -- to get a revision the user will just have to specify the full
        # version including the tag. Otherwise we get the tag no matter what..
        #
        #        if pkg.options.tag:
        #            return "%s-%s" % (pkg.realVersion, pkg.options.tag)
        return pkg.realVersion
    log("%s has checksum %s" % (pkg.name, pkg.checksum), DEBUG)
    tag = tags_cache.getTag(pkg)
    if tag != None:
        log("%s is aliased to \'%s\', using \'%s\'" % (pkg.checksum, tag, tag), DEBUG)
    elif pkg.options.tag:
        pkgInfo = PkgInfo(pkg)
        tag = tags_cache.requestTag(pkgInfo, pkg.options.tag)
        log("Attempt to assign %s to \'%s\'" % (pkg.checksum, tag), DEBUG)
    else:
        tag = pkg.checksum
    if not tag:
        return "%s" % pkg.realVersion
    else:
        return "%s-%s" % (pkg.realVersion, tag)


def specFilename(opts, pkgName):
    return join(abspath(opts.cmsdist), "%s.spec" % pkgName)


def redefineMacro(name, value, maxLength=8000, initCount=0):
    exSpec = ""
    value = re.sub("\s+", " ", value.strip())
    values = splitMacroLine(value, maxLength)
    if len(values) > 1:
        value = ""
        for v in values:
            exSpec += "%%define %s%d %s\n" % (name, initCount, v)
            value += "%%{%s%d} " % (name, initCount)
            initCount += 1
        subexSpec, value = redefineMacro(name, value, maxLength, initCount)
        exSpec += subexSpec
    return (exSpec, value)


def splitMacroLine(value, maxLength=8000):
    nvalue = [value]
    if len(value) > maxLength:
        nvalue = []
        while len(value) > maxLength:
            xIndex = value.find(" ", maxLength)
            if xIndex == -1: break
            nvalue.append(value[0:xIndex])
            value = value[xIndex + 1:]
        nvalue.append(value)
    return nvalue


class ReadOnlyDict(dict):
    class PermissionError(Exception):
        def __init__(self):
            Exception.__init__(self, "Read only dict, cannot set its items")

    def __setitem__(self, key, value):
        raise ReadOnlyDict.PermissionError()


class HeaderMatchingRegexps(object):
    def __init__(self):
        self.REQUIRES_REGEXP = re.compile("^Requires: (.*)")
        self.REMOTE_SOURCE_REGEXP = re.compile("^([Ss]ource[0-9]*): (.*:.*/.*)")
        self.REMOTE_PATCH_REGEXP = re.compile("^[Pp]atch[0-9]*: (.*:.*/.*)")
        self.LOCAL_SOURCE_REGEXP = re.compile("^[Ss]ource[0-9]*: (.*)")
        self.LOCAL_PATCH_REGEXP = re.compile("^[Pp]atch[0-9]*: (.*)")
        self.BUILD_REQUIRES_REGEXP = re.compile("^BuildRequires: (.*)")


class PackageFactory(object):
    def __init__(self, options):
        self.syntax = MetaSpecSyntax()
        self.preamble = self.__getPreamble(options)
        self.headerMatchingRegexp = HeaderMatchingRegexps()
        self.sectionOptions = ReadOnlyDict({"": "",
                                            "%%description": "",
                                            "%prep": "",
                                            "%build": "",
                                            "%install": "",
                                            "%pre": "",
                                            "%post": "",
                                            "%preun": "",
                                            "%postun": "",
                                            "%files": "-f %_builddir/files"})
        self.sectionPreambles = ReadOnlyDict({"": DEFAULT_PREAMBLE,
                                              "%%description": DEFAULT_DESCRIPTION_PREAMBLE,
                                              "%prep": DEFAULT_PREP_PREAMBLE,
                                              "%build": DEFAULT_BUILD_PREAMBLE,
                                              "%install": DEFAULT_INSTALL_PREABLE,
                                              "%pre": DEFAULT_PRE_PREAMBLE,
                                              "%post": DEFAULT_POST_PREAMBLE,
                                              "%preun": DEFAULT_PREUN_PREAMBLE,
                                              "%postun": DEFAULT_POSTUN_PREAMBLE,
                                              "%files": DEFAULT_FILES_PREAMBLE})
        self.sectionPostambles = ReadOnlyDict({"": "",
                                               "%%description": "",
                                               "%prep": DEFAULT_PREP_POSTAMBLE,
                                               "%build": DEFAULT_BUILD_POSTAMBLE,
                                               "%install": DEFAULT_INSTALL_POSTAMBLE,
                                               "%pre": "",
                                               "%post": "",
                                               "%preun": "",
                                               "%postun": "",
                                               "%files": ""})
        self.__postprocessingRules = [(re.compile("%\{n\}"), "%{pkgname}"),
                                      (re.compile("%\{v\}"), "%{pkgversion}"),
                                      (re.compile("%\{i\}"), "%{pkginstroot}"),
                                      (re.compile("%n$"), "%{pkgname}"),
                                      (re.compile("%v$"), "%{pkgversion}"),
                                      (re.compile("%i$"), "%{pkginstroot}"),
                                      (re.compile("%n([^_A-Za-z0-9])"), "%{pkgname}\\1"),
                                      (re.compile("%v([^_A-Za-z0-9])"), "%{pkgversion}\\1"),
                                      (re.compile("%i([^_A-Za-z0-9])"), "%{pkginstroot}\\1"),
                                      (re.compile("^Source:"), "Source0:"),
                                      (re.compile("^Patch:"), "Patch0:")]
        self.__basePackageHash = sha256(str([pickle.dumps(self),
                                             COMMANDS_SH,
                                             COMMANDS_CSH,
                                             SPEC_HEADER,
                                             DEFAULT_RPATH_PREAMBLE,
                                             INITENV_PREAMBLE,
                                             COMPILER_DETECTION,
                                             DEFAULT_SECTIONS, ])).hexdigest()
        self.options = options
        self.__cacheKeyDecorator = ArchitectureDecorator(options.architecture)
        self.__package_cache = {}
        self.__requires_cache = {}
        self.__packageCache = CacheProxy(self.__package_cache, self.__cacheKeyDecorator)
        self.__requiresCache = CacheProxy(self.__requires_cache, self.__cacheKeyDecorator)
        self.checksums_cache = {}

    def __getPreamble(self, options):
        try:
            filename = join(options.cmsdist, "rpm-preamble.file")
            return open(filename).read()
        except:
            raise FileNotFound(filename)

    def __getitem__(self, name):
        return self.__packageCache[name]

    def __setitem__(self, name, item):
        self.__packageCache[name] = item

    def has_key(self, name):
        return self.__packageCache.has_key(name)

    def getRequiresCache(self):
        return self.__requiresCache

    def create(self):
        return Package(self.options)

    def createWithSpec(self, pkgName):
        if self.has_key(pkgName): return self[pkgName]
        filename = specFilename(self.options, pkgName)
        try:
            specLines = open(filename).readlines()
        except IOError, e:
            raise FileNotFound(filename)
        pkg = None
        specCache = "%s/specCache/%s.%s" % (
            self.options.tempdir, pkgName, sha256(self.__basePackageHash + str(specLines)).hexdigest())
        forceRecreate = False
        while True:
            if forceRecreate or (not exists(specCache)):
                getstatusoutput("rm -f %s/specCache/%s.*" % (self.options.tempdir, pkgName))
                pkg = self.create()
                pkg.initWithSpec(specLines)
                pkg.depSum = sha256(" ".join([self[d].pkgName() for d in sorted(pkg.fullDependencies)])).hexdigest()
                pickle.dump(pkg, open(specCache, "w"), 1)
                pkg.setOptions(self.options)
                pkg.specCache = True
                log("Generated cache: %s" % pkg.pkgName())
            else:
                forceRecreate = True
                pkg = pickle.load(open(specCache))
                if not exists(pkg.specFilename()): continue
                pkg.setOptions(self.options)
                for sp in pkg.subpackages: sp.checksum = '%{nil}'
                pkg.origSpec = specLines
                depSpecCache = False
                for p in pkg.fullDependencies:
                    if not self.has_key(p): self[p] = self.createWithSpec(p)
                    if self[p].specCache: depSpecCache = True
                if depSpecCache:
                    log("Recreating package %s cache due its dependency changed" % pkg.pkgName())
                    continue
                pkg.updateDependentCount()
                pkg.generateInitEnv()
                chksum = pkg.checksum
                cachedVersion = pkg.version
                pkg.calculateChecksum(force=True)
                regen_msg = ""
                if (pkg.checksum != chksum):
                    regen_msg = "checksum %s vs %s" % (pkg.checksum, chksum)
                elif (cachedVersion != pkg.version):
                    regen_msg = "version  %s vs %s" % (pkg.version, cachedVersion)
                else:
                    depSum = sha256(" ".join([self[d].pkgName() for d in sorted(pkg.fullDependencies)])).hexdigest()
                    if (depSum != pkg.depSum): regen_msg = "dependencies checksum %s vs %s" % (depSum, pkg.depSum)
                if regen_msg:
                    log("Recreating package %s cache: %s" % (pkg.pkgName(), regen_msg))
                    continue
                for sp in pkg.subpackages: sp.updateFromParent(pkg)
                pkg.specCache = False
                log("Read from cache: %s" % pkg.pkgName())
            break
        self[pkgName] = pkg
        if pkg.name != pkgName:
            log("FATAL: Package name '%s' and spec name '%s' does not match" % (pkg.name, pkgName))
            raise MalformedSpec
        return pkg

    def postProcessSpec(self, spec):
        for regexp, subst in self.__postprocessingRules:
            spec = regexp.sub(subst, spec)
        return spec

    def expandSubpackages(self, packages):
        """ Expand the packages (and their dependencies)'s subpackages.
        """
        out = set()
        for pkg in packages:
            out.add(pkg)
            out.update(pkg.subpackages)
        return sorted(out)


class MetaSpecSyntax(object):
    SPEC_HEADER = property(lambda self: self.__SPEC_HEADER)
    IMPORT = property(lambda self: self.__IMPORT)
    BUILDIF = property(lambda self: self.__BUILDIF)
    INITENV = property(lambda self: self.__INITENV)
    REVISION = property(lambda self: self.__REVISION)
    SUBPACKAGE = property(lambda self: self.__SUBPACKAGE)

    def __init__(self):
        self.__SPEC_HEADER = re.compile("^### RPM[ ]*([^ ]*)\s*([^ ]*)\s*(.*)")
        self.__IMPORT = re.compile("^## IMPORT (.*)")
        self.__BUILDIF = re.compile("^## BUILDIF (.*)")
        self.__REVISION = re.compile("^## REVISION (.*)")
        self.__SUBPACKAGE = re.compile(r'^##\s+SUBPACKAGE\s+([\w+-]+)(\s+IF\s+(%[\w+-]+))?\s*$', re.M)

        commands = "|".join(COMMANDS_SH.keys()).strip("|").replace("+",
                                                                   "[+]")
        initenvStr = "^## INITENV\s+(%s)\s+([^\s]*)\s+(.*)" % commands
        self.__INITENV = re.compile(initenvStr)


class BuilderAction(object):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        """ This is a base class for an action performed by the builder.
            pkg is the payload for the action.
            parent is an action to be completed/completable before being able
            to execute this one.
            prevAlternative is an alternative action that has precedence on
            this one.
        """
        self.pkg = pkg
        self.prevAlternative = prevAlternative
        self.parent = parent
        self.__cachedRun = None
        self.__cachedExpectedResults = None
        self.__safeRecursion = 0

    def run(self):
        """ Actually run a command.
        """
        assert (False)

    def dryRun(self):
        """ Returns True if the action should been executed, False if not.
        """
        # If we already have checked this, do not run the check again.
        if self.__cachedRun:
            return self.__cachedRun
        self.__safeRecursion += 1
        if self.__safeRecursion > 100:
            traceback.print_stack()
            sys.exit(1)

        actionName = self.actionName
        pkgName = self.pkg.pkgName()
        # Run the check and cache the results but actually return the correct
        # value only if prerequisites are fulfilled and there is no better
        # alternative.
        self.__cachedRun = self.doDryRun()

        # Make sure that all the prerequisites can be executed.
        log("Checking prerequisites for %(actionName)s %(pkgName)s" % locals(),
            DEBUG)
        tmpParent = self.parent
        assert (tmpParent != self)
        while tmpParent:
            parentName = tmpParent.actionName
            if tmpParent.dryRun() == False:
                self.cannotRun("""Cannot run '%(actionName)s' for package %(pkgName)s because 
                    dependending on action '%(parentName)s' which will not be executed.""" % locals())
                self.__cachedRun = False
                return False
            tmpParent = tmpParent.parent
        log("All the prerequisites for %(actionName)s %(pkgName)s are there" % locals(), DEBUG)

        # Make sure that none of the better alternatives can be executed
        log("Checking altenatives to %(actionName)s %(pkgName)s" % locals(),
            DEBUG)
        tmpAlternative = self.prevAlternative
        assert (tmpAlternative != self)
        while tmpAlternative:
            if tmpAlternative.dryRun() == True:
                alternativeName = tmpAlternative.actionName
                self.cannotRun("""Cannot run '%(actionName)s' for package %(pkgName)s because 
                                   alternative action '%(alternativeName)s' has priority.""" % locals())
                self.__cachedRun = False
                return False
            tmpAlternative = tmpAlternative.prevAlternative
        log("No better alternative to %(actionName)s for %(pkgName)s." % locals(), DEBUG)
        return self.__cachedRun

    def cannotRun(self, message, level=NORMAL):
        """ Use to specify why you couldn't dryRun something.
        """
        self.cannotRunMessage = message
        self.level = level

    def expectedResults(self):
        if not self.__cachedExpectedResults:
            self.__cachedExpectedResults = self.doExpectedResults()
        return self.__cachedExpectedResults

    def doExpectedResults(self):
        """ Returns True if the command could run as expected with the correct
            outputs being produced, False otherwise.
        """
        assert (False and "Please implement doExpectedResults in derived class.")

    def nonExpectedExecution(self):
        """ Return a string to be printed when the execution should have not
            happened, but it did.
        """
        assert (False)

    def missingExecution(self):
        """ Returns a string to be printed when the execution should have
            happened, but it did not.
        """
        assert (False)

    def producesStuffToUpload(self):
        """ Can be overridden to return True if the execution of the action
            will produce stuff that is then uploaded.
        """
        return False

    actionName = property(lambda self: self._actionName)


class SourcesDownload(BuilderAction):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__(self, pkg, parent, prevAlternative)
        self._actionName = "Download sources"

    def doDryRun(self):
        return True

    def doExpectedResults(self):
        remoteSourcesRE = re.compile(".*:.*/.*")
        self.files = []
        for source in self.pkg.sources:
            if remoteSourcesRE.match(source):
                self.files.append(join("SOURCES", self.pkg.pkgdir,
                                       source.rsplit("/", 1)[1]))
            else:
                self.files.append(join("SOURCES", self.pkg.pkgdir,
                                       basename(source).rsplit(".", 1)[0]))
        self.missingFiles = [abspath(filename)
                             for filename in self.files
                             if not exists(filename)]
        return self.missingFiles == []

    def nonExpectedExecution(self):
        unexpectedFiles = "\n".join([filename
                                     for filename in self.files
                                     if exists(filename)])
        return "I was not expecting to find the following files:\n %(unexpectedFiles)s" % locals()

    def missingExecution(self):
        missingFiles = "\n".join(self.missingFiles)
        return "I was expecting the following files: \n %(missingFiles)s" % locals()


class InstallFromLocalArea(BuilderAction):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__(self, pkg, parent, prevAlternative)
        self._actionName = "Install from local area"

    def doDryRun(self):
        """ Return True if there are the rpms ready to be installed.
        """
        # If the area is not bootstrapped, this should not run.
        self.cachedRpmName = join(self.pkg.rpmdir, self.pkg.rpmfilename)
        self.officialRpmName = join(abspath("RPMS"), self.pkg.rpmfilename)
        if not self.pkg.options.bootstrap:
            return False
        # Otherwise make sure that the packages are there.
        filesExist = exists(self.cachedRpmName) and exists(self.officialRpmName)
        return filesExist

    def doExpectedResults(self):
        """We expect to see the rpm installed in the database, and the files in RPMS"""
        # If we ran this action, we expected rpms to be installed in the db and files
        # to be there.
        if not self.dryRun():
            return False
        pkgName = self.pkg.pkgName()
        error, output = getstatusoutput("%s ; rpm -q %s" % (rpmEnvironmentScript, pkgName))
        # Not all the rpm commands set the error correctly.
        if error or "error:" in output:
            return False
        filesExists = exists(self.cachedRpmName) and exists(self.officialRpmName)
        lines = output.strip("\n").split("\n")
        tooManyLines = len(lines) != 1
        if tooManyLines and filesExists:
            return False
        firstLine = lines[0].strip()
        if not firstLine:
            return False
        if firstLine and firstLine.replace(pkgName, "")[0] != "-" and filesExists:
            return False
        return True

    def nonExpectedExecution(self):
        pkgName = self.pkg.pkgName()
        officialRpmName = self.officialRpmName
        return "%(pkgName)s was installed from %(officialRpmName)s although no installation can happen from the local area." % locals()

    def missingExecution(self):
        pkgName = self.pkg.pkgName()
        officialRpmName = self.officialRpmName
        return "I was expecting %(pkgName)s to be installed using %(officialRpmName)s but it was not." % locals()


class InstallFromServer(BuilderAction):
    def __init__(self, pkg, parent, prevAlternative):
        BuilderAction.__init__(self, pkg, parent, prevAlternative)
        self.called = False
        self._actionName = 'Install from server'

    def doDryRun(self):
        """ Return True if the package is on server
        """
        if not self.pkg.options.bootstrap:
            return False
        self.called = True
        pkgName = self.pkg.pkgName()
        pkgInfo = PkgInfo(self.pkg)
        pkgRealName = pkgInfo.id()
        pkgsWithSameHash = [p for (p, h) in tags_cache.cache.iteritems() if
                            (h == pkgInfo.checksum) and p.startswith(pkgRealName) and (pkgName != p)]

        # If a file exists on server we return True
        cmsPkgCmd = CMSPKG_CMD
        rpmenv = rpmEnvironmentScript
        pkgRev = self.pkg.pkgRevision
        searchCommand = """%(cmsPkgCmd)s showpkg %(pkgName)s; %(rpmenv)s ; rpm -q %(pkgName)s-1-%(pkgRev)s""" % locals()
        error, output = getstatusoutput(searchCommand)
        self.output = output.split("\n")
        if error: return False

        def evalExistsOnServer():
            for line in self.output[2:]:
                if line.startswith("1-%s." % pkgRev): return True
            return False

        return pkgsWithSameHash or evalExistsOnServer()

    def doExpectedResults(self):
        # In order for a download to be successful we expect:
        # 1) to find it on server
        # 2) to find it on client
        # 3) not to find the rpm in RPMS
        if not self.called:
            return False

        def onServerAndLocal():
            if not self.output[0].startswith(self.pkg.pkgName() + ' - CMS Experiment package'): return False
            return self.output[-1].startswith("%s-1-%s." % (self.pkg.pkgName(), self.pkg.pkgRevision))

        rpmInstalled = onServerAndLocal()
        rpmFilename = join(abspath(self.pkg.rpmdir), self.pkg.rpmfilename)
        return rpmInstalled and not exists(rpmFilename)

    def nonExpectedExecution(self):
        pkgName = self.pkg.pkgName()
        return """I was not expecting to download %(pkgName)s from server 
                  but it looks like I can.
                  Probably you need to run:
                  
                  cmsBuild deprecate-local %(pkgName)s """ % locals()

    def missingExecution(self):
        pkgName = self.pkg.pkgName()
        return """ I was expecting to be able to download %(pkgName)s from server, 
                  but I can't. Are you sure you don't need to rebuild it?""" % locals()


class BuildPackage(BuilderAction):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__(self, pkg, parent, prevAlternative)
        self._actionName = 'Build Package'

    def doDryRun(self):
        """ The only requirement for a package to be built apart from sources
            being there and no other alternatives (installing from sever) is that
            the specfile for it exists.
            For a subpackage, check the parent's specfile.
        """
        pkg = self.pkg
        if pkg.name == "system-compiler":
            return False
        if pkg.parent:
            specfilename = join(pkg.parent.options.cmsdist, "%s.spec" % pkg.parent.name)
        else:
            specfilename = join(pkg.options.cmsdist, "%s.spec" % pkg.name)
        return exists(specfilename)

    def doExpectedResults(self):
        if self.pkg.name == "system-compiler":
            return False
        cachedRpmName = join(self.pkg.rpmdir, self.pkg.rpmfilename)
        return exists(cachedRpmName)

    def nonExpectedExecution(self):
        pkgName = self.pkg.pkgName()
        return "I would have not expected %(pkgName)s to be built, but it was." % locals()

    def missingExecution(self):
        pkgName = self.pkg.pkgName()
        return "I would have expected a local build of %(pkgName)s but that did not happen." % locals()

    def producesStuffToUpload(self):
        """ A package that gets built will always produce stuff to upload.
        """
        return True


class BuildSystemCompiler(BuilderAction):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__(self, pkg, parent, prevAlternative)
        self._actionName = 'Build system compiler'

    def doDryRun(self):
        """ The only case we build the system compiler is the case in which the
            name matches the dummy package.
        """
        if self.pkg.name != "system-compiler":
            return False
        return self.pkg.options.systemCompiler

    def doExpectedResults(self):
        return self.pkg.name == "system-compiler"

    def nonExpectedExecution(self):
        return "I was not expecting to use the system compiler."

    def missingExecution(self):
        return "I was expecting to use the system compiler."


class LinkPackageFromCache(BuilderAction):
    def __init__(self, pkg, parent=None, prevAlternative=None):
        BuilderAction.__init__(self, pkg, parent=None, prevAlternative=None)
        self._actionName = 'Create links for rpm'
        self.called = False

    def doDryRun(self):
        """ We always expect to be able to run the link, if the building
            was possible. Since the building is actually performed by a
            parent action we always return True and make sure we have a
            BuildAction as parent.
        """
        self.cachedRpmName = join(self.pkg.rpmdir, self.pkg.rpmfilename)
        self.officialRpmName = join(abspath("RPMS"), self.pkg.rpmfilename)
        self.called = True
        if not exists(self.cachedRpmName):
            return False
        return True

    def doExpectedResults(self):
        """ We expect the link to exists, to be readable, and to point to a
            an RPM which has the same checksum as the package associated to
            this action.
        """
        if not self.called:
            return False
        if not exists(self.officialRpmName):
            return False
        checksum = getPkgChecksumFile(self.officialRpmName, self.pkg.options)
        return self.pkg.checksum == checksum

    def nonExpectedExecution(self):
        officialRpmName = self.officialRpmName
        cachedRpmName = self.cachedRpmName
        return """A link was found in %(officialRpmName)s but it points to the
                  wrong rpm %(cachedRpmName)s""" % locals()

    def missingExecution(self):
        officialRpmName = self.officialRpmName
        cachedRpmName = self.cachedRpmName
        return """A link was expected from %(officialRpmName)s to %(cachedRpmName)s, but it not found. """ % locals()


class ChecksumCalculator(object):
    def __init__(self):
        self.__adder = md5adder()
        self.__checksums = {}

    def addString(self, string):
        self.__adder.update(string)

    def addStrings(self, stringList):
        self.__adder.update("".join(stringList))

    def addFile(self, filename):
        assert (filename[0] == "/")
        if checksums_cache.has_key(filename):
            self.__checksums[filename] = checksums_cache[filename]
            return
        if not exists(filename):
            raise FileNotFound(filename)
        f = open(filename)
        m = md5adder(f.read())
        f.close()
        checksum = m.hexdigest()
        checksums_cache[filename] = checksum
        self.__checksums[filename] = checksum

    def addPkg(self, pkg):
        if pkg.name == "system-compiler":
            filename = pkg.name
        else:
            filename = specFilename(pkg.options, pkg.name)
        self.__checksums[filename] = pkg.checksum

    def getChecksum(self):
        items = self.__checksums.items()
        items.sort()
        for key, value in items:
            self.__adder.update(value)
        return self.__adder.hexdigest()


class SubPackage(object):
    def __init__(self, parent, name):
        self.subname = name
        self.subpackages = []
        self.sources = []
        self.parent = None

    def updateFromParent(self, parent):
        self.name = '%s-%s' % (parent.name, self.subname)
        self.group = parent.group
        self.version = parent.version
        self.realVersion = parent.realVersion
        self.pkgRevision = parent.pkgRevision
        self.pkgrel = parent.pkgrel
        self.pkgdir = parent.pkgdir
        self.options = parent.options
        self.cmsplatf = parent.cmsplatf
        self.workDir = parent.workDir
        self.installDir = parent.installDir
        self.tempDirPrefix = parent.tempDirPrefix
        self.builddir = parent.builddir
        self.sourcedir = parent.sourcedir
        self.specdir = parent.specdir
        self.checksum = parent.checksum
        self.dependencies = [parent.name] + parent.dependencies
        self.origDependencies = [parent.name] + parent.origDependencies
        self.buildDependencies = [parent.name] + parent.buildDependencies
        self.origBuildDependencies = [parent.name] + parent.origBuildDependencies
        self.fullDependencies = [parent.name] + parent.fullDependencies
        self.dependentCounter = 0
        self.patches = parent.patches
        self.rpmdir = parent.rpmdir
        self.rpmfilename = '%s/%s+%s+%s-%s-%s.%s.rpm' % (
            self.cmsplatf, self.group, self.name, self.version, '1', self.pkgRevision, self.cmsplatf)
        self.srpmfilename = parent.srpmfilename
        self.pkginstroot = parent.pkginstroot
        self.parent = parent

    def dumpSpecFragment(self, computeSpecChecksum=True):
        importName = 'subpackage-%s.file' % self.subname
        importFilename = join(self.options.cmsdist, importName)
        spec = open(importFilename, 'r').read()
        if computeSpecChecksum:
            spec = re.compile(r'^(Summary:.*?)( SpecChecksum:.*|)$', re.M).sub(r'\g<1> SpecChecksum:%s' % self.checksum,
                                                                               spec)
        return spec

    def pkgName(self):
        return "%(group)s+%(name)s+%(version)s" % self.__dict__

    def rpmLocation(self):
        assert (self.parent)
        return join(self.rpmdir, self.rpmfilename)

    def __repr__(self):
        return "<SubPackage name=%(name)s>" % self.__dict__

    def __eq__(self, other):
        """ Two (sub)packages are the same if they have the same name"""
        return type(other) == SubPackage and self.name == other.name

    def __ne__(self, other):
        return not self.__eq__(other)

    # FIXME write a single implementation for both Package and SubPackage
    def __cmp__(self, other):
        """ Subpackage A is greater than package B if A is a subpackage of B.
            Two subpackages of the same package are sorted by name,
            while two subpackages of different packages have the same
            ordering as their parent packages.
            A subpackage and an unrelated package have the same order as the
            subpackage's parent and the other package.
        """
        if self.parent == other:
            return 1
        elif self.parent == other.parent:
            return cmp(self.name, other.name)
        elif other.parent is None:
            return cmp(self.parent, other)
        else:
            return cmp(self.parent, other.parent)


class Package(object):
    tmpspec = property(lambda self: self.__getTmpSpecName())
    sourcedir = property(lambda self: self.__getSourcedir())
    specdir = property(lambda self: self.__getSpecdir())
    pkgdir = property(lambda self: self.__getPkgdir())

    def clean(self):
        del self.sections
        del self.specPreHeader
        del self.pkgreqs
        del self.directpkgreqs
        del self.spec
        del self.requiresStatement
        del self.origSpec
        del self.installPostambles
        self.options = {}
        for sp in self.subpackages: sp.options = {}

    def setOptions(self, options):
        self.options = options
        for sp in self.subpackages: sp.options = options

    def __init__(self, options):
        self.workDir = options.workDir
        self.installDir = options.installDir
        self.tempDirPrefix = options.tempDirPrefix
        self.compilerRealVersion = ""
        self.name = ""
        self.realVersion = ""
        self.group = ""
        self.version = ""
        self.summary = "CMS Experiment package"
        self.license = "As defined by package owner"
        self.subname = ""
        self.parent = None
        self.subpackages = []
        self.imports = []
        self.buildrequires = []
        self.sources = []
        self.sourcesNumbers = {}
        self.patches = []
        self.pkgreqs = "%{nil}"
        self.directpkgreqs = "%{nil}"
        self.buildCondition = None
        self.builddir = None
        self.pkginstroot = None
        self.pkgrel = None
        self.__specdir = None
        self.cmsplatf = options.architecture
        self.rpmdir = None
        self.rpmfilename = None
        self.srpmfilename = None
        self.pkgRevision = '1'
        self.specPreHeader = ""
        self.rpmVersion = "1"
        self.requiresStatement = "Requires: gcc"
        self.sections = {}
        self.dependentCounter = 0
        self.installPostamblesEnv = {"SH": "", "CSH": ""}
        self.installPostambles = ""
        self.dependencies = []
        self.origDependencies = []
        self.buildDependencies = []
        self.origBuildDependencies = []
        self.fullDependencies = []
        self.origSpec = []
        self.spec = []
        self.checksum = "%{nil}"
        self.options = options
        self.status = None
        self.buildRequireToolfile = False
        self.noAutoDependency = False

    def rpmLocation(self):
        return join(self.rpmdir, self.rpmfilename)

    def createDefaultSections(self):
        if self.options.skipPreInstall == True:
            log("Skip preinstall check: " + str(self.options.skipPreInstall), DEBUG)
            replacement = """
# Built with an option to skip CMS default pre-install checks
"""
            DEFAULT_SECTIONS['%pre'] = replacement
        for section in DEFAULT_SECTIONS.keys():
            self.sections[section] = {}
            self.sections[section][''] = DEFAULT_SECTIONS[section]
            # FIXME: This is to avoid trigger a rebuild. This overrides the %files section
            # For any release series which is going to trigger a rebuild please fix DEFAULT_SECTIONS[%file]
            # to have only %{installroot}/ and remove next 2 lines.
            if section == "%files":
                self.sections[section][''] = '%{installroot}/'
            self.sections[section][''] += PKGFactory.sectionPostambles[section]
            if section == "%install": self.sections[section][''] += self.installPostambles
            if section == "%post" and self.options.buildWithRpath: self.sections[section][''] += DEFAULT_RPATH_PREAMBLE

    def initWithSpec(self, specLines):
        """ This parses the spec files and creates a structure with its contents.
        """
        self.origSpec = specLines
        self.group, self.name, self.realVersion = parseRPMLine(self.origSpec, self.options)
        self.version = self.realVersion
        self.parseRevision()
        compilerName = self.options.compilerName
        self.compilerName = compilerName
        if self.name == compilerName:
            self.requiresStatement = ""
            self.compilerRealVersion = self.realVersion
            self.expandSpec()
        else:
            if not PKGFactory.has_key(compilerName):
                compilerPKG = None
                if self.options.systemCompiler == True:
                    compilerPKG = PKGFactory.create()
                    compilerPKG.name = "system-compiler"
                    compilerPKG.realVersion = detectCompilerVersion(compilerName)
                else:
                    compilerPKG = PKGFactory.createWithSpec(compilerName)
                PKGFactory[compilerName] = compilerPKG
            self.compilerRealVersion = PKGFactory[compilerName].realVersion
            self.expandSpec()
            if self.options.systemCompiler == False and parseNoCompilerLine(self.spec) == False:
                self.dependencies.append(compilerName)
                self.origDependencies.append(compilerName)
        self.noAutoDependency = parseNoAutoDependencyLine(self.spec)
        self.buildRequireToolfile = parseBuildRequireToolfileLine(self.spec)
        self.fullDependencies += self.dependencies
        self.setInitEnv()
        self.generateInitEnv()
        self.createDefaultSections()
        self.parseSections()
        self.dumpSpec()
        self.origRequires, self.sources, self.patches, self.origBuildRequires, self.sourcesNumbers = self.getRequiresAndSources()
        self.parseRequires()
        self.dumpSpec()
        # FIXME: saveSpec should really be done once.
        createDirs(architecture=self.cmsplatf)
        self.calculateChecksum()
        self.rewriteRequires()
        self.dumpSpec()
        prepareSaveSpec(self)
        saveSpec(self)
        result = self.rpmEvalStrings("%pkgrel",
                                     "%pkginstroot",
                                     "%_builddir",
                                     "%_specdir",
                                     "%_rpmdir",
                                     "%_rpmfilename",
                                     "%_srpmfilename")
        assert (result)
        try:
            [self.pkgrel, self.pkginstroot, self.builddir,
             self.__specdir, self.rpmdir,
             self.rpmfilename, self.srpmfilename] = result
        except ValueError, e:
            log("FATAL: Error unpacking results: \n%s" % result)
            raise e
        # update subpackages
        for subpackage in self.subpackages: subpackage.updateFromParent(self)
        self.clean()

    def parseRevision(self):
        for line in self.origSpec:
            match = PKGFactory.syntax.REVISION.match(line)
            if match:
                self.pkgRevision = match.group(1)
                return True
        return False

    def expandSpec(self):
        """This function is responsible for finding and parsing all the IMPORT and SUBPACKAGE directives for a given spec.
        """
        imports = []
        subpackages = {}
        self.subpackages = []
        for line in self.origSpec:
            imatch = PKGFactory.syntax.IMPORT.match(line)
            smatch = PKGFactory.syntax.SUBPACKAGE.match(line)
            if imatch:
                imports.append(imatch.group(1).strip(" \n") + ".file")
            elif smatch:
                subpackages[smatch.group(1)] = smatch.group(3)
            else:
                self.spec.append(line)
        try:
            for importName in imports:
                importFilename = join(self.options.cmsdist, importName)
                self.spec.extend(open(importFilename).readlines())
                self.imports.append(importFilename)
        except IOError, e:
            raise FileNotFound(importFilename)

        # Check for sub-packages after all processing all the imports
        for subpackageName in subpackages:
            condition = subpackages[subpackageName]
            if not condition or self.isSymbolDefined(condition):
                self.subpackages.append(SubPackage(self, subpackageName))

    def isSymbolDefined(self, symbol):
        """This function checks if a symbol is defined in the current spec file. That is, if rpmbuild evaluates %symbol to a non-empty string.
        Note: I *think* that only the symbols defined in the main section are visible here.
        """
        tmp = copy.copy(self)
        tmp.createDefaultSections()
        tmp.parseSections()
        value = tmp.rpmEvalStrings(symbol)
        isDefined = (value != symbol)
        return isDefined

    def parseSections(self):
        """ This helper method is responsible for parsing the spec and create subdivide sections found inside it.
        """
        currentSection = ''
        currentSubSection = ''
        SECTION_MATCH = "(%s)[$\s]+(.*)" % "|".join(self.sections.keys()).strip('|')
        sectionRe = re.compile(SECTION_MATCH)
        for line in self.spec:
            match = sectionRe.match(line)
            if match:
                # Close the previous section and open a new one.
                self.sections[currentSection][currentSubSection] += PKGFactory.sectionPostambles[currentSection]
                if currentSection == "%install": self.sections[currentSection][
                    currentSubSection] += self.installPostambles
                currentSection, currentSubSection = match.groups()
                self.sections[currentSection][currentSubSection] = PKGFactory.sectionPreambles[currentSection]
            else:
                self.sections[currentSection][currentSubSection] += line
        self.sections[currentSection][currentSubSection] += PKGFactory.sectionPostambles[currentSection]
        if currentSection == "%install": self.sections[currentSection][currentSubSection] += self.installPostambles
        if "%post" in self.sections and self.options.buildWithRpath: self.sections["%post"][
            ''] += DEFAULT_RPATH_PREAMBLE

        # If no BUILDIF conditions we are done.
        # Otherwise insert the build condition everywhere, so that sections
        # are not actually executed.
        if not self.buildCondition:
            return

        for section in ["%install", "%build"]:
            for subsection in self.sections[section].keys():
                old = self.sections[section][subsection]
                self.sections[section][subsection] = old.replace("%initenv",
                                                                 "%s || exit 0\n%%initenv\n" % self.buildCondition)
        for section in ["%pre", "%post", "%preun", "%postun"]:
            for subsection in self.sections[section].keys():
                old = self.sections[section][subsection]
                self.sections[section][subsection] = "%s || exit 0\n" % self.buildCondition + old

    def calculateChecksum(self, force=False):
        """
        """
        checksumCalculator = ChecksumCalculator()

        if (not force) and (self.checksum != "%{nil}"): return
        # In the case --use-system-compiler option is specified, the compiler itself
        # is called "system-compiler" and the checksum is given by its version rather
        # than the spec.
        # FIXME: add more sensible stuff to the checksum, besides the version (maybe the
        # gcc specfile???)
        if self.name == "system-compiler":
            checksumCalculator.addString(self.compilerRealVersion)
            self.checksum = checksumCalculator.getChecksum()
            self.version = calculateHumanReadableVersion(self)
            return

        checksumCalculator.addStrings(self.origSpec)  # TODO - here it adds string to calculate
        checksumCalculator.addStrings(DEFAULT_SECTIONS.values())
        checksumCalculator.addStrings(PKGFactory.sectionOptions.values())
        checksumCalculator.addStrings(PKGFactory.sectionPreambles.values())
        checksumCalculator.addStrings(PKGFactory.sectionPostambles.values() + [self.installPostambles])

        if self.options.buildWithRpath: checksumCalculator.addStrings(DEFAULT_RPATH_PREAMBLE)

        for filename in self.imports:
            checksumCalculator.addFile(abspath(filename))

        for subpackage in self.subpackages:
            checksumCalculator.addString(
                subpackage.dumpSpecFragment(not self.options.repository.split('.')[0] == "comp"))

        for pkg in getPackages(self.dependencies + self.buildDependencies):
            # for a, v in pkg.__dict__.iteritems():
            #  print a,v
            checksumCalculator.addPkg(pkg)
        remotefileRE = re.compile(".*:.*/.*")
        for patch in self.patches:
            if remotefileRE.match(patch):
                continue
            filename = join(abspath(self.options.cmsdist), patch)
            checksumCalculator.addFile(filename)
        for source in self.sources:
            if remotefileRE.match(source):
                continue
            filename = join(abspath(self.options.cmsdist), source)
            if exists(filename):
                checksumCalculator.addFile(filename)

        # FIXME could be part of checksumCalculator
        if self.options.localSources and self.name in self.options.localSources:
            # recalculate hash based on file system if --source flag for pkg
            source_v_list = []
            for source_k, source_v in self.options.localSources[self.name].iteritems():
                source_v_list.append(source_v)
            cmd = "tar cf - %s 2>&1 | md5sum" % (" ".join(source_v_list))
            exit, result = getstatusoutput(cmd)
            self.checksum = result.split()[0]
        else:
            self.checksum = checksumCalculator.getChecksum()

        self.version = calculateHumanReadableVersion(self)
        if self.name == self.options.pipPackage:
            global pip_package_env_script
            pip_package_env_script = join(self.options.workDir, self.cmsplatf, self.group, self.name, self.version,
                                          "etc/profile.d/init.sh")

    def generateRequires(self, dependencies, origDependencies):
        requiresPkgs = ["%s+%s+%s" % (pkg.group, pkg.name, pkg.version)
                        for pkg in getPackages(dependencies)
                        if pkg.name != "system-compiler"]
        pkgreqsPkgs = ["%s/%s/%s " % (pkg.group, pkg.name, pkg.version)
                       for pkg in getPackages(dependencies)
                       if pkg.name != "system-compiler"]
        directpkgreqsPkgs = ["%s/%s/%s " % (pkg.group, pkg.name, pkg.version)
                             for pkg in getPackages(origDependencies)
                             if pkg.name != "system-compiler"]
        requiredtoolsPkgs = [pkg.name
                             for pkg in getPackages(dependencies)
                             if pkg.name != "system-compiler"]
        requires = " ".join(requiresPkgs)
        pkgreqs = " ".join(pkgreqsPkgs)
        directpkgreqs = " ".join(directpkgreqsPkgs)
        requiredtools = " ".join(requiredtoolsPkgs)
        if not pkgreqs:       pkgreqs = "%{nil}"
        if not directpkgreqs: directpkgreqs = "%{nil}"
        if not requiredtools: requiredtools = "%{nil}"
        return (requires, pkgreqs, directpkgreqs, requiredtools)

    def rewriteRequires(self):
        """ This rewrites both the Requires line to specify dependencies and
            sets the pkgreq to point to their path.
        """
        requires, pkgreqs, directpkgreqs, requiredtools = self.generateRequires(self.dependencies,
                                                                                self.origDependencies)
        bldrequires, bldpkgreqs, blddirectpkgreqs, bldrequiredtools = self.generateRequires(self.origBuildDependencies,
                                                                                            self.origBuildDependencies)
        allDepsPkgs = " ".join(["%s/%s/%s " % (pkg.group, pkg.name, pkg.version)
                                for pkg in getPackages(self.fullDependencies)
                                if pkg.name != "system-compiler"])
        if not allDepsPkgs: allDepsPkgs = "%{nil}"
        # After rewrite of Requires we split pkgeqs and directpkgreqs to avoid RPM macro length limit
        specPre1, pkgreqs = redefineMacro("pkgreqs", pkgreqs)
        specPre2, requiredtools = redefineMacro("requiredtools", requiredtools)
        specPre3, directpkgreqs = redefineMacro("directpkgreqs", directpkgreqs)
        specPre4, bldpkgreqs = redefineMacro("buildpkgreqs", bldpkgreqs)
        specPre5, bldrequiredtools = redefineMacro("buildrequiredtools", bldrequiredtools)
        specPre6, blddirectpkgreqs = redefineMacro("builddirectpkgreqs", blddirectpkgreqs)
        specPre7, allDepsPkgs = redefineMacro("allpkgreqs", allDepsPkgs)

        requires = "\nRequires: ".join(splitMacroLine(requires))
        bldrequires = "\nBuildRequires: ".join(splitMacroLine(bldrequires))
        reqStatement = "%%define requiredtools %(requiredtools)s\n%%define buildrequiredtools %(bldrequiredtools)s\n"
        reqStatement += "%%define buildpkgreqs %(bldpkgreqs)s\n%%define builddirectpkgreqs %(blddirectpkgreqs)s\n"
        reqStatement += "%%define allpkgreqs   %(allDepsPkgs)s\n"
        if requires:
            reqStatement += "Requires: %(requires)s\n"
        if bldrequires:
            reqStatement += "BuildRequires: %(bldrequires)s\n"
        self.pkgreqs = pkgreqs
        self.directpkgreqs = directpkgreqs
        self.requiresStatement = reqStatement % locals()
        self.specPreHeader = specPre1 + specPre2 + specPre3 + specPre4 + specPre5 + specPre6 + specPre7

    def updateChildDependencies(self, pkg, dependencies, pkgdeps):
        if not pkg in dependencies: dependencies.insert(0, pkg)
        for subdep in pkgdeps:
            if not subdep in dependencies: dependencies.insert(0, subdep)
        return

    def updateDependencies(self, require, origDependencies, dependencies, buildRequires=False):
        if PKGFactory.has_key(require):
            pkg = PKGFactory[require]
        else:
            pkg = PKGFactory.createWithSpec(require)
            PKGFactory[require] = pkg
        origDependencies.insert(0, require)
        self.updateChildDependencies(require, dependencies, pkg.dependencies)
        if buildRequires:
            self.updateChildDependencies(require, dependencies, pkg.buildDependencies)

    def parseRequires(self):
        """This function is responsible for finding all the required dependencies for a given spec.
           We recursively create dependend Packages or we pick them from the package_cache if needed.
           The dependencies of the dependent Packages are added to the dependency list of the parent,
           so that each Package has the full list of dependent packages. If a dependency is already there
           in the list, it gets "bubbled", so that more fundamental dependencies will come first in the
           list.
        """
        for require in self.origRequires:
            self.updateDependencies(require, self.origDependencies, self.dependencies)
        if self.buildRequireToolfile:
            deps = self.dependencies[:]
            for dep in deps:
                if not dep.endswith("-toolfile"):  continue
                if not PKGFactory.has_key(dep.replace("-toolfile", "")): continue
                if not dep in self.origBuildRequires: self.origBuildRequires.append(dep)
                if dep in self.origDependencies: self.origDependencies.remove(dep)
                self.dependencies.remove(dep)
        for require in self.origBuildRequires:
            self.updateDependencies(require, self.origBuildDependencies, self.buildDependencies, True)
        for dep in self.dependencies:
            if dep in self.buildDependencies:     self.buildDependencies.remove(dep)
        self.fullDependencies = self.dependencies + self.buildDependencies
        self.updateDependentCount()
        self.dependencies = self.sortPkgs(self.dependencies)
        self.origDependencies = self.sortPkgs(self.origDependencies)
        self.buildDependencies = self.sortPkgs(self.buildDependencies)
        self.origBuildDependencies = self.sortPkgs(self.origBuildDependencies)
        self.fullDependencies = self.sortPkgs(self.fullDependencies)

    def sortPkgs(self, deps):
        pkgs = getPackages(deps)
        pkgs.sort()
        return [pkg.name for pkg in pkgs]

    def updateDependentCount(self):
        for dep in getPackages(self.fullDependencies): dep.dependentCounter += 1

    def dumpSpec(self, saveScripts=False):
        self.spec = "\n".join([self.specPreHeader,
                               SPEC_HEADER % self.__dict__,
                               PKGFactory.preamble])
        if self.options.reference: self.spec += format(SPEC_REFERENCE_REPO, reference_repo=self.options.reference)
        for section in self.sections.keys():
            for subsection in self.sections[section].keys():
                sectionContents = self.sections[section][subsection].strip("\n ")
                if sectionContents:
                    if saveScripts:
                        if section in ["%prep"]:
                            patchedContents = PATCH_SOURCE_MACROS
                            xpatchRE = re.compile("^\s*%patch[0-9]*\s+.+$")
                            for l in sectionContents.split("\n"):
                                if xpatchRE.match(l): l = "%{package_init_source}\n" + l + "\n%{package_commit_patch}"
                                patchedContents += l + "\n"
                            sectionContents = patchedContents + "\n%{package_final_source}"
                        if (section in ["%build", "%install", "%prep"]) and (subsection == ""):
                            secScript = "cmsdist-%s.sh" % section[1:]
                            sectionContents = "cat $0 | grep -v '%%_builddir/%s' > %%_builddir/%s\n%s" % (
                                secScript, secScript, sectionContents)
                        if self.options.reference and (section in ["%install"]):
                            sectionContents += "\n%{relocateReference}\n"
                        self.spec += "\n\n%s %s %s\n" % (section, subsection, PKGFactory.sectionOptions[section])
                        self.spec += sectionContents
                        if not self.noAutoDependency:
                            if section in [
                                "%install"]: self.spec += "\n%{?AutoSetupDependencies:%AutoSetupDependencies}"
                            if section in [
                                "%post"]: self.spec += "\n%{?AutoSetupDependenciesRelocate:%AutoSetupDependenciesRelocate}"
        self.spec = PKGFactory.postProcessSpec(self.spec)

        for subpackage in self.subpackages:
            subpackage.updateFromParent(self)
            self.spec += '\n\n' + subpackage.dumpSpecFragment()

    def __getTmpSpecName(self):
        # FIXME: make this static? Should not change over the whole period.
        return join(abspath(self.tempDirPrefix), "tmpspec-%s" % self.name)

    def rpmEvalStrings(self, *strings):
        self.spec = "\n".join([self.specPreHeader,
                               SPEC_HEADER % self.__dict__,
                               PKGFactory.preamble,
                               self.sections[''][''],
                               "%description"] + list(strings))
        f = file(self.tmpspec, "w")
        f.write(PKGFactory.postProcessSpec(self.spec).replace('%%', '%'))
        f.close()
        commandPrefix = getCommandPrefix(self.options)
        evalCommand = "%s ; %s rpm -q --specfile %s --info %s" % (rpmEnvironmentScript, commandPrefix,
                                                                  self.tmpspec, self.options.rpmQueryDefines)
        log(evalCommand, DEBUG)
        error, output = getstatusoutput(evalCommand)
        if error:
            log("FATAL: malformed spec found while quering it. Command: ")
            log(evalCommand)
            log("Resulted in:\n\n%s" % output)
            raise MalformedSpec(self.tmpspec)
        log(output, DEBUG)
        # This allows us to build packages which have 'Description' as a part of their name.
        description = re.split("Description\s*:", output, 1)[1]
        results = [line for line in description.split("\n")][1:]
        return (len(results) == 1 and results[0]) or results

    def __getPkgdir(self):
        return join(self.group, self.name, self.version)

    def __getSourcedir(self):
        return join(abspath("SOURCES"), self.pkgdir)

    def __getSpecdir(self):
        return join(abspath("SPECS"), self.pkgdir)

    def specFilename(self):
        return join(self.specdir, "spec")

    def finalSpecFilename(self):
        return join(abspath("SPECS"), self.pkgdir, "spec")

    def pkgName(self):
        return "%(group)s+%(name)s+%(version)s" % self.__dict__

    def rpmCachePath(self):
        return join(abspath("RPMS/cache"), self.checksum, self.rpmfilename)

    def setInitEnv(self):
        initSh = ""
        initCsh = ""
        for line in self.spec:
            match = PKGFactory.syntax.INITENV.match(line)
            if match:
                command, var, value = [x.strip(" \t") for x in match.groups()]
                initSh += COMMANDS_SH[command] % {"var": var, "value": value}
                initCsh += COMMANDS_CSH[command] % {"var": var, "value": value}
            buildifMatch = PKGFactory.syntax.BUILDIF.match(line)
            if not self.buildCondition and buildifMatch:
                self.buildCondition = buildifMatch.group(1)
        self.installPostamblesEnv = {"SH": initSh, "CSH": initCsh}

    def generateInitEnv(self):
        """ Parses the spec file and generates the code for init.sh/init.csh
        """
        initSh = """cat <<\EOF_INIT_SH > %i/etc/profile.d/init.sh\n"""
        initCsh = """cat <<\EOF_INIT_CSH > %i/etc/profile.d/init.csh\n"""

        upperNameDict = {"uppername": self.name.upper().replace("-", "_")}

        if self.name == "gcc":
            initSh += COMMANDS_SH["+PATH"] % {"var": "PATH", "value": "%{i}/bin-real"}
            initCsh += COMMANDS_CSH["+PATH"] % {"var": "PATH", "value": "%{i}/bin-real"}
        for command, var, value in INITENV_PREAMBLE:
            initSh += COMMANDS_SH[command] % {"var": var % upperNameDict, "value": value}
            initCsh += COMMANDS_CSH[command] % {"var": var % upperNameDict, "value": value}

        if self.installPostamblesEnv["SH"]: initSh += self.installPostamblesEnv["SH"]
        if self.installPostamblesEnv["CSH"]: initCsh += self.installPostamblesEnv["CSH"]
        initSh += "\nEOF_INIT_SH\n"
        initCsh += "\nEOF_INIT_CSH\n"
        createProfileDScript = "mkdir -p %i/etc/profile.d\n"
        self.installPostambles = "\n".join([createProfileDScript, initSh, initCsh])

    def getFinalSpec(self):
        self.dumpSpec(saveScripts=True)
        return self.spec

    def __repr__(self):
        return "<Package name=%(name)s>" % self.__dict__

    def __eq__(self, other):
        """ Two packages are the same if they have the same name"""
        return type(other) == Package and self.name == other.name

    def __ne__(self, other):
        return not self.__eq__(other)

    def __cmp__(self, other):
        """ Package A is greater than package B if
            Package A depends on package B.
            Moreover, if A does not depend B and viceversa, the one with less dependent
            packages greater first. If they have the same number of dependent packages, the
            one with less dependencies is said to be greater.
        """
        moredeps = cmp(len(self.fullDependencies), len(other.fullDependencies))
        lessdependent = cmp(other.dependentCounter, self.dependentCounter)
        if self in other.fullDependencies:
            return -1
        elif other in self.fullDependencies:
            return 1
        elif lessdependent:
            return lessdependent
        elif moredeps:
            return moredeps
        else:
            return cmp(self.name, other.name)

    def getRequiresAndSources(self, subpackage=''):
        if PKGFactory.getRequiresCache().has_key(self.name):
            return PKGFactory.getRequiresCache()[self.name]
        spec = file(self.tmpspec, "w")
        text = "\n".join([self.specPreHeader,
                          SPEC_HEADER % self.__dict__,
                          PKGFactory.postProcessSpec(PKGFactory.preamble),
                          "%%description",
                          PKGFactory.postProcessSpec(self.sections[''][subpackage])])
        spec.write(text)
        spec.close()
        deps = [];
        sources = [];
        patches = []
        localSources = []
        localPatches = []
        buildDeps = []
        queryCommand = "%s ; %s rpm -q --info --specfile %s %s 2>/dev/null" % (
            rpmEnvironmentScript, getCommandPrefix(self.options),
            self.tmpspec, self.options.rpmQueryDefines)
        regexps = PKGFactory.headerMatchingRegexp
        matchers = [(regexps.REQUIRES_REGEXP, deps),
                    (regexps.REMOTE_SOURCE_REGEXP, sources),
                    (regexps.REMOTE_PATCH_REGEXP, patches),
                    (regexps.LOCAL_SOURCE_REGEXP, localSources),
                    (regexps.LOCAL_PATCH_REGEXP, localPatches),
                    (regexps.BUILD_REQUIRES_REGEXP, buildDeps)]

        def fixSource(source):
            if source.startswith("git:") and not source.startswith("git://"): source = "git://" + source[4:]
            return source

        sourcesNumbers = {}
        for line in popen(queryCommand).readlines():
            line = re.sub("[\s]+", " ", line).strip("\n\t ")
            for rule, target in matchers:
                match = rule.match(line)
                if not match:
                    continue
                if regexps.REMOTE_SOURCE_REGEXP != rule:
                    target.extend([element for element in match.group(1).split()])
                else:
                    for src_num, url in [match.groups()]:
                        for element in url.split():
                            element = fixSource(element.strip())
                            target.append(element)
                            sourcesNumbers[element] = src_num
                break
        cmsdistPath = abspath(self.options.cmsdist)

        # If no site is set, simply returns the original dependency name.
        # If site is set, return "site-dep" as a dependency if site-dep.spec
        # exists.
        def siteSpecific(d):
            if not self.options.site:
                return d
            siteDep = self.options.site + "-" + d
            siteSpec = join(cmsdistPath, siteDep + ".spec")
            if exists(join(cmsdistPath, siteDep + ".spec")):
                log("Site specific spec %s preferred for %s." % (siteSpec, d), DEBUG)
                return siteDep
            return d

        if self.options.pipPackage:
            if [s for s in sources if s.startswith("pip://")]:
                if not self.options.pipPackage in deps + buildDeps:
                    buildDeps.append(self.options.pipPackage)
        deps = [siteSpecific(d) for d in deps]
        sources.extend([join(cmsdistPath, source + ".file")
                        for source in localSources])
        patches.extend([join(cmsdistPath, patch + ".patch")
                        for patch in localPatches])
        PKGFactory.getRequiresCache()[self.name] = (deps, sources, patches, buildDeps, sourcesNumbers)
        return (deps, sources, patches, buildDeps, sourcesNumbers)


def parseOptions():
    parser = OptionParser(usage="""
  cmsBuild [<additional-options>] [--no-bootstrap] -a <architecture> -c <cmsdist-dir> build <package> [<package2> .. <packageN>]
  cmsBuild [<additional-options>] [--sync-back] [--no-bootstrap] -a <architecture> -c <cmsdist-dir> upload <package> [<package2> .. <packageN>]""")
    deprecatedOptions = [("--compiling-processes", "--jobs / -j"),
                         ("--workers-pool-size", "--builders")]
    for deprecated, new in deprecatedOptions:
        if deprecated in sys.argv:
            parser.error("Deprecated option name %s. Please use %s." % (deprecated, new))

    # FIXME add the relevant options.
    parser.add_option("-c", "--cmsdist",
                      dest="cmsdist",
                      help="the location of the CMSDIST directory",
                      metavar="PATH",
                      default=None)
    parser.add_option("--cmsdist-tag",
                      dest="cmsdistTag",
                      default="",
                      metavar="TAG",
                      help="Tag to fetch for CMSDIST.")
    parser.add_option("--architecture", "-a",
                      dest="architecture",
                      default=None,
                      help="Architecture to be used.")
    parser.add_option("-i", "--work-dir",
                      dest="workDir",
                      default=getcwd(),
                      metavar="PATH",
                      help="the location where the build happens")
    parser.add_option("--jobs", "-j",
                      dest="compilingProcesses",
                      metavar="N",
                      help="The number of processes to be used to compile a given package.",
                      default=1)
    parser.add_option("--repository",
                      dest="repository",
                      metavar="NAME",
                      help="Name of the repository directory on server. E.g. 'cms'.",
                      default="cms")
    parser.add_option("--tag",
                      dest="tag",
                      metavar="NAME",
                      help="Name of the tag. Default is constructed from the --repository <repo>.",
                      default="")
    parser.add_option("--force-tag",
                      dest="forcetag",
                      action="store_true",
                      help="Always append the tag to the package name. Default is to build the first version of package without the tag.",
                      default=False)
    parser.add_option("--builders",
                      dest="workersPoolSize",
                      metavar="N",
                      default=1,
                      help="Maximum number of packages to be build in parallel.",
                      type="int")
    parser.add_option("--sync-back",
                      dest="syncBack",
                      action="store_true",
                      help="When uploading, copy the temporary directory to the production one.",
                      default=False)
    advancedBuildOptions = OptionGroup(parser, "Advanced build options")
    advancedBuildOptions.add_option("--sources",
                                    dest="sources",
                                    action="store_true",
                                    help="Outputs formatted sources. Do not build.",
                                    default=False)
    advancedBuildOptions.add_option("--source",
                                    dest="localSources",
                                    action="append",
                                    help="Overwrite given package's source location to local directory "
                                         "(package:source=directory, can be repeated multiple times).",
                                    default=None)
    advancedBuildOptions.add_option("--use-system-compiler",
                                    dest="systemCompiler",
                                    action="store_true",
                                    help="""Use the system compiler rather than the one specified in CMSDIST""",
                                    default=None)
    advancedBuildOptions.add_option("--ignore-compile-errors",
                                    "-k",
                                    dest="ignoreCompileErrors",
                                    help="Ignores CMSSW compilation errors.",
                                    action="store_true",
                                    default=False)
    advancedBuildOptions.add_option("--no-bootstrap",
                                    dest="bootstrap",
                                    action="store_false",
                                    help="Do not bootstrap area and ignore packages on the remote repository.",
                                    default=True)
    advancedBuildOptions.add_option("--skip-pre-install-checks",
                                    action="store_true",
                                    dest="skipPreInstall",
                                    default=None,
                                    help="Skip execution of default CMS pre-install scriplet")
    advancedBuildOptions.add_option("--build-command-prefix",
                                    dest="buildCommandPrefix",
                                    default="",
                                    metavar="COMMAND",
                                    help="String to prepend to any rpmbuild command")
    advancedBuildOptions.add_option("--pretend",
                                    dest="pretend",
                                    action="store_true",
                                    help="Do not actually build",
                                    default=False)
    advancedBuildOptions.add_option("--server",
                                    dest="server",
                                    metavar="URL",
                                    help="URL of cmspkg cgi-script e.g. 'http://cmsrep.cern.ch/cgi-bin/cmspkg'",
                                    default="http://cmsrep.cern.ch/cgi-bin/cmspkg")
    advancedBuildOptions.add_option("--use-dev",
                                    action="store_true",
                                    dest="useDev",
                                    default=None,
                                    help="Use development cmspkg instead of production.")
    advancedBuildOptions.add_option("--pip-package",
                                    dest="pipPackage",
                                    metavar="NAME",
                                    help="Name of the cmsdist pip package",
                                    default="py2-pip")
    advancedBuildOptions.add_option("--check-pkg-deps",
                                    dest="checkPackageDeps",
                                    action="store_true",
                                    help="Run extra checks after the build to make sure package dependencies are fully satisfied",
                                    default=False)
    advancedBuildOptions.add_option("--build-with-rpath",
                                    dest="buildWithRpath",
                                    action="store_true",
                                    help="""Added rpath to the executables. This is done at post install time.""",
                                    default=None)
    advancedBuildOptions.add_option("--reference",
                                    dest="reference",
                                    default=None,
                                    metavar="PATH",
                                    help="Path to an existing installation which can be used to install already available packages.")
    advancedBuildOptions.add_option("--black-list",
                                    dest="blackList",
                                    default="",
                                    help="CSV of package(s) which should not be taken from reference repostiroy.")
    advancedBuildOptions.add_option("--new-scheduler", dest="newScheduler", action="store_true",
                                    default=False, help="Use the new scheduler to install / build packages")
    # FIXME: change option to --no-deprecate and do the deprecation
    #        automatically by default.
    # parser.add_option ("--deprecate-local",
    #                   dest="doDeprecate",
    #                   action="store_true",
    #                   default=False)
    uploadGroup = OptionGroup(parser, "Upload Options",
                              "Options to fine-tune the upload to repository process.")
    uploadGroup.add_option("--upload-server",
                           dest="uploadServer",
                           metavar="HOSTNAME",
                           help="The hostname of the server where the repository is physically located.",
                           default="cmsrep.cern.ch")
    uploadGroup.add_option("--upload-user",
                           dest="uploadUser",
                           metavar="USERNAME",
                           help="The username by which connect to the server where the repository is located.",
                           default="cmsbuild")
    uploadGroup.add_option("--upload-port",
                           dest="uploadPort",
                           metavar="<0-65535>",
                           help="The port on which the repository sshd is listening to (default 22).",
                           default="22")
    uploadGroup.add_option("--upload-root-directory",
                           dest="uploadRootDirectory",
                           metavar="PATH",
                           default="/data/cmssw",
                           help="The base directory where the repository is located. E.g. /data/cmssw.")
    uploadGroup.add_option("--upload-tmp-repository",
                           dest="uploadTmpRepository",
                           help="Name of temporary repository to use during upload. Default=cms.<username> (Deleted/recreated for each upload request)",
                           default=getuser())

    uploadGroup.add_option("--server-apt-env",
                           dest="serverAptEnv",
                           default="/data/cmssw/apt/etc/profile.d/init.sh",
                           metavar="FILENAME",
                           help="Server side location of the apt environment script to be sourced.")

    debugGroup = OptionGroup(parser, "Debug options")
    debugGroup.add_option("--debug",
                          dest="debug",
                          action="store_true",
                          help="Print out debug information.",
                          default=False)
    debugGroup.add_option("--no-cleanup",
                          dest="noCleanup",
                          default=False,
                          action="store_true",
                          help="Do not automatically clean-up stale files.")
    debugGroup.add_option("--specs-only",
                          dest="specsOnly",
                          help="Do not build. Only write out RPM spec files.",
                          action="store_true",
                          default=False)
    debugGroup.add_option("--trace",
                          dest="trace",
                          action="store_true",
                          help="Show activity of builders and scheduler.",
                          default=False)
    debugGroup.add_option("--progress",
                          dest="progress",
                          action="store_true",
                          help="Show progress",
                          default=False)
    parser.add_option_group(advancedBuildOptions)
    parser.add_option_group(uploadGroup)
    parser.add_option_group(debugGroup)
    opts, args = parser.parse_args(None, None)

    # if cmsdist is not set then look for cmsdist/CMSDISTin local directory
    if not opts.cmsdist:
        if exists("cmsdist"):
            opts.cmsdist = abspath("./cmsdist")
        else:
            opts.cmsdist = abspath("./CMSDIST")

    # Setup some default values.
    # FIXME: use an OptionParser callback.
    # FIXME: exclusive --cmsdist and --cmsdist-tag options.
    # FIXME: change site to "variant" and extract it from the architecture.
    opts.workDir = abspath(opts.workDir)
    opts.site = ""
    if "://" not in opts.cmsdist:
        opts.cmsdist = abspath(opts.cmsdist)

    if opts.cmsdistTag:
        opts.cmsdist = "cvs://?tag=%s" % opts.cmsdistTag

    if not opts.architecture:
        parser.error("Please specify the architecture you want to build for.")

    # Check for weird characters in workdir
    if "/." in opts.workDir:
        parser.error("Hidden directories not allowed as --work-dir path.")

    if re.match(".*[\\\+[*$].*", opts.workDir):
        parser.error("Please avoid '\\+[*$' in --work-dir path.")

    # If --tag is not provided via command line then tag will always match the
    # repository (minus the various .pre bits, like for comp.pre)
    if not opts.tag:
        opts.tag = opts.repository.split(".")[0]

    setLogLevel(opts)
    if len(args) < 2:
        parser.error("Please build or upload action. Use --help to see additional options.")

    opts.installDir = opts.workDir
    if (opts.repository == "cms") or opts.repository.startswith("cms."):
        opts.installDir = "/opt/cmssw"

    opts.tempDirPrefix = "tmp"
    if opts.workDir.split(sep)[1] == opts.tempDirPrefix:
        opts.tempDirPrefix += "X"

    if len(args) < 2:
        fatal("Wrong number of arguments.")

    if not args[0] in ["build", "upload", "deprecate-local"]:
        fatal("Unknown command %s. Alternatives are build, upload." % args[0])

    if opts.syncBack and args[0] != "upload":
        fatal("--sync-back option is available only when uploading.")

    if not re.match("^[a-zA-Z0-9_.]+$", opts.repository):
        fatal("Repository name '%s' contains invalid characters. Allowed characters are: a-zA-Z0-9_." % opts.repository)

    if not re.match("^[a-zA-Z0-9_]+$", opts.uploadTmpRepository):
        fatal(
            "Tmp upload repository name '%s' contains invalid characters. Allowed characters are: a-zA-Z0-9_" % opts.uploadTmpRepository)

    if opts.localSources and 'upload' in args:
        fatal("'upload' option can not be used together with '--source' flag.")

    return opts, args


def createDirs(architecture, dest="./"):
    dirs = ["SPECS", join("RPMS", architecture),
            "SRPMS", join("BUILD", architecture), "SOURCES", "BUILDROOT", "WEB"]
    for d in dirs:
        try:
            makedirs(join(abspath(dest), d))
        except:
            pass


def prepareSaveSpec(p):
    for directory in [p.specdir, p.sourcedir]:
        log("Creating directory %s" % directory, DEBUG)
        if not exists(directory): makedirs(directory)


def saveSpec(p):
    f = file(p.finalSpecFilename(), 'w')
    # Removes the "Requires:"
    spec = re.sub("Requires:[^+\n]*\n", "\n", re.sub("BuildRequires:[^+\n]*\n", "\n", p.getFinalSpec()))
    f.write(spec)
    # Fix for RPM 4.4.: We need to add something at the end of the spec file otherwise
    # any multiline macro in the %post section does not expant properly if it is not followed
    # by any other command/comment.
    f.write("\n#\n");
    f.close()


def fetchLocal(pkg, sourceFilename):
    assert (sourceFilename[0] == "/")
    try:
        if not exists(pkg.sourcedir):
            makedirs(pkg.sourcedir)
        destFilename = join(pkg.sourcedir,
                            basename(sourceFilename.rsplit(".", 1)[0]))
        log("Copying %s to %s" % (sourceFilename, destFilename), DEBUG)
        source = open(sourceFilename)
        dest = file(destFilename, 'w')
        dest.write(source.read())
        dest.close()
        source.close()
        return (sourceFilename, True)
    except Exception, e:
        return (sourceFilename, False)


def fetchSources(pkg, scheduler):
    scheduler.log("Fetching sources for %s" % pkg.name)
    sourcedir = pkg.sourcedir
    downloadables = pkg.sources + pkg.patches
    if not downloadables:
        scheduler.log("No sources to be downloaded found for packages %s." % pkg.name)
        return
    urlRe = re.compile(".*:.*/.*")

    # No need to create the download directory
    # not to dump the cmsos, because it was already
    # done.
    for url in downloadables:
        if urlRe.match(url):
            try:
                success = download(url, sourcedir, pkg.options, pkg)
            except MalformedUrl, e:
                return str(e)
        else:
            output, success = fetchLocal(pkg, url)
        if not success:
            return "Unable to download %s" % url
        scheduler.log("Done fetching %s" % url)


def checkIfInstalled(pkg):
    """ Check if a given rpm is already in the db.
    """
    if not pkg.pkgName() in rpm_db_cache:
        return False

    if not isDefaultRevision(pkg.pkgRevision):
        revision = rpm_db_cache[pkg.pkgName()][0]
        if revision >= pkg.pkgRevision:
            log("RPM %s found in RPM db with Revision %s (bigger than pkgRevision = %s)" % (
                pkg.pkgName(), revision, pkg.pkgRevision), DEBUG)
            return True
        return False
    log("RPM %s found in RPM db." % pkg.pkgName(), DEBUG)
    return True


def checkIfOnServer(pkg):
    """ Check if the rpm associated to pkg can be downloaded from the apt
        server.
    """
    pkgName = pkg.pkgName()
    log("Checking if package %s can be downloaded from apt servers" % pkgName, DEBUG)
    if pkgName in tags_cache.cache:
        if isDefaultRevision(pkg.pkgRevision): return True
        pkgRevision = tags_cache.revision_cache[pkgName]
        if pkg.pkgRevision <= pkgRevision:
            log(
                "RPM %s found in apt repository with a revision greater than the current one. Accepting package." % pkgName,
                DEBUG)
            return True
        log("""RPM %s is found in the apt repository, but it has a earlier revision (%s) 
than the current one(%s). Building current package.""" % (pkgName, pkgRevision, pkg.pkgRevision), DEBUG)
        return False
    else:
        log("RPM %s not found in apt repository." % pkgName, DEBUG)
        return False


def checkCanInstallRpm(pkg):
    officialRpmLocation = pkg.rpmLocation()
    uniqueRpmLocation = join(abspath("RPMS/cache"), pkg.checksum, pkg.rpmfilename)
    if exists(officialRpmLocation):
        return True
    elif exists(uniqueRpmLocation):
        log("""No rpm found at:
                %(officialRpmLocation)s 
                but original is actually there at:
                %(uniqueRpmLocation)s""" % locals())
        symlink(uniqueRpmLocation, officialRpmLocation)
        return True
    return False


def getScriptlets(pkg, relocation, original):
    """Gets the scriptlet associated to an rpm.
    """
    command = "%s ; rpm -qp --scripts %s" % (rpmEnvironmentScript, pkg.rpmLocation())
    error, output = getstatusoutput(command)
    if error:
        log("Command: %(command)s failed with the following message: %(output)s." % locals(), DEBUG)
        raise RpmInstallFailed(pkg, output)
    capture = None
    scripts = {}
    secEXP = ""
    for sec in "pre", "post", "postun", "preun":
        scripts[sec] = 'RPM_INSTALL_PREFIX="%s"; export RPM_INSTALL_PREFIX\n' % relocation
        secEXP += sec + "|"
    secPattern = re.compile("^(" + secEXP.strip("|") + ")install\s+scriptlet\s+")
    for line in output.split("\n"):
        m = secPattern.match(line)
        if m:
            capture = m.group(1)
        elif capture:
            scripts[capture] += line + "\n"
    return scripts


def installRpm(pkg, bootstrap):
    """ Installs an rpm
    """
    error = 1;
    output = "";
    command = "#No command"
    if bootstrap:
        command = "%s ; rpm -Uvh --prefix %s %s" % (rpmEnvironmentScript, pkg.options.workDir, pkg.rpmLocation())
        error, output = getstatusoutput(command)
    else:
        workDir = pkg.workDir
        tmpDir = join(workDir, pkg.tempDirPrefix, pkg.checksum)
        tmpInstall = join(tmpDir, pkg.installDir.strip(sep))
        rpmLoc = pkg.rpmLocation()
        command = "mkdir -p %(tmpInstall)s; rm -rf %(tmpInstall)s; ln -s %(workDir)s %(tmpInstall)s;"
        if sys.platform == 'darwin':
            command += "cd %(tmpDir)s; rpm2cpio %(rpmLoc)s | cpio --insecure -idmv; cd %(workDir)s; rm -rf %(tmpDir)s"
        else:
            command += "cd %(tmpDir)s; rpm2cpio %(rpmLoc)s | cpio  -idmv; cd %(workDir)s; rm -rf %(tmpDir)s"
        command = command % locals()
        error, output = getstatusoutput(command)
        if not error:
            scripts = getScriptlets(pkg, pkg.options.workDir, "")
            log("Scriptlets: %s" % scripts, DEBUG)
            postScript = NamedTemporaryFile()
            postScript.write(scripts["post"])
            postScript.flush()
            error, output = getstatusoutput("cat %s; sh -e -x %s" % (postScript.name, postScript.name))
    if error:
        e, o = getstatusoutput("rm -rf %s %s/%s" % (pkg.rpmdir, abspath("RPMS"), pkg.rpmfilename))
        log("Command:\n %(command)s failed with the following message: %(output)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, output)
    log("Done installing via rpm.", DEBUG)


def installApt(pkg, scheduler, cache=[]):
    if pkg.options.reference:
        if pkg.name in cache: return
        cache.append(pkg.name)
        for dep in getPackages(pkg.dependencies): installApt(dep, scheduler, cache)
        if should_install_from_reference(pkg):
            if not is_package_installed(pkg, rpm_db_cache): install_reference(pkg)
            scheduler.forceDone("check-%s" % pkg)
            scheduler.forceDone("install-%s" % pkg)
            return
    command = "%s -f -j 1 install %s" % (CMSPKG_CMD, pkg.pkgName())
    error, output = getstatusoutput(command)
    log("About to install %s using cmspkg..." % pkg.pkgName(), DEBUG)
    if error:
        log("Command:\n %(command)s failed with the following message: %(output)s" % locals(), DEBUG)
        raise RpmInstallFailed(pkg, output)
    log("Done installing via cmspkg.", DEBUG)
    for dep in pkg.dependencies:
        scheduler.forceDone("check-%s" % dep)
        scheduler.forceDone("install-%s" % dep)


def scheduleInstallPackage(pkg, scheduler):
    if pkg.name == "system-compiler":
        return False

    bootstrapped = pkg.options.bootstrap

    instDir = join(pkg.options.workDir, pkg.pkgrel)
    if not bootstrapped and exists(join(instDir, ".package-checksum")):
        scheduler.log("Package already built into %s. Not building." % instDir)
        # subpackages were already built as part of the main package, but the RPMs still need to be symlinked
        return checkCanInstallRpm(pkg)

    if not bootstrapped: return False

    scheduler.log("Checking if %s is cached." % pkg.name)
    actionName = "install-%s" % pkg.pkgName()
    if checkCanInstallRpm(pkg):
        scheduler.log("%s is available from local RPMS area. Not building. Installing..." % pkg.pkgName())
        scheduler.serial(actionName, [], installRpm, pkg, bootstrapped)
        return True
    if checkIfOnServer(pkg):
        scheduler.log("%s is available from remote repository \"%s\". Not building. Downloading and installing..." % (
            pkg.name, pkg.options.repository))
        scheduler.serial(actionName, [], installApt, pkg, scheduler)
        return True
    return False


def getCommandPrefix(options):
    linux32RE = "slc[^_]+_ia32_gcc[^_]+"
    returnString = ""
    if re.match(linux32RE, options.architecture):
        returnString = "linux32 %s" % options.buildCommandPrefix
    elif options.buildCommandPrefix:
        returnString = options.buildCommandPrefix
    return returnString.strip()


def handleStaleFiles(files, noCleanup):
    for staleFile in [f for f in files if exists(f)]:
        if noCleanup:
            raise UnexpectedFile(staleFile)
        log("Removing stale file " + staleFile, DEBUG)
        unlink(staleFile)


def buildPackage(pkg, scheduler):
    """ This helper function is responsible for building/installing a given spec and it's associated rpm.
      What it does is the following (TODO):
      * Checks if the rpm is already installed in the RPM DB. If yes, exits.
      * Checks if the rpm is already available in the local area. If yes, installs it.
      * Checks if the rpm is already available on the apt server. If yes, downloads, installs and returns.
      If any of the above is true it:
      * Builds the rpm, if it fails, it aborts.
      * Installs the rpm in the local db, if it fails, it aborts."""
    if pkg.name == "system-compiler":
        return

    # if this is a subpackge do not try to build it, it should have been built as part of its parent
    if pkg.parent:
        scheduler.log("Not building Subpackage %s, it should have been built as part of Package %s." % (
            pkg.name, pkg.parent.name))
        return

    scheduler.log("Creating directory %s if not existing." % pkg.builddir)
    if not exists(pkg.builddir):
        makedirs(pkg.builddir)
    logfile = "%s/log" % pkg.builddir

    scheduler.log("Building %s. Log can be found in %s." % (pkg.name, logfile))
    optionsDict = {
        "topdir": abspath("."),
        "specdir": pkg.specdir,
        "builddir": pkg.builddir,
        "makeprocesses": "",
        "ignoreCompileErrors": "",
        "nodeps": ""
    }

    rpmsCacheDir = dirname(join(abspath("RPMS/cache/%s" % pkg.checksum), pkg.rpmfilename))
    finalRpmCacheDir = dirname(join(abspath("RPMS"), pkg.rpmfilename))
    srpmsCacheDir = join(abspath("SRPMS/cache/%s" % pkg.checksum))

    missingDirs = [d for d in [rpmsCacheDir, finalRpmCacheDir, srpmsCacheDir]
                   if not exists(d)]
    for directory in missingDirs:
        makedirs(directory)

    finalRpmFilename = join(abspath("RPMS"), pkg.rpmfilename)
    uniqueRpmFilename = join(abspath("RPMS/cache/%s" % pkg.checksum), pkg.rpmfilename)
    handleStaleFiles([finalRpmFilename, uniqueRpmFilename], pkg.options.noCleanup)

    if pkg.options.compilingProcesses:
        optionsDict["makeprocesses"] = "--define \"compiling_processes %s\"" % pkg.options.compilingProcesses
    if pkg.options.ignoreCompileErrors:
        optionsDict["ignoreCompileErrors"] = "--define \"ignore_compile_errors 1\""
    optionsDict["tmpdir"] = join(opts.workDir, opts.tempDirPrefix)
    optionsDict["rpmenv"] = rpmEnvironmentScript
    optionsDict.update({"prefix": getCommandPrefix(pkg.options),
                        "buildRoot": join(optionsDict["tmpdir"], "BUILDROOT", pkg.checksum),
                        "extraRpmDefines": pkg.options.rpmQueryDefines})
    if not pkg.options.bootstrap:
        optionsDict["nodeps"] = "--nodeps"

    # FIXME: should be done only once!
    err, out = getstatusoutput("%s ; rpmbuild --version" % rpmEnvironmentScript)
    if err:
        return "ERROR: unable to find working rpmbuild"

    rpmbuildCommand = "rm -rf %(builddir)s/pkgtools-pkg-src-move2git ; %(rpmenv)s ; " \
                      " TMPDIR=%(tmpdir)s %(prefix)s rpmbuild %(nodeps)s --buildroot %(buildRoot)s -ba --define '_topdir %(topdir)s'" \
                      " %(makeprocesses)s %(ignoreCompileErrors)s %(extraRpmDefines)s" \
                      " %(specdir)s/spec >%(builddir)s/log 2>&1" % optionsDict
    rpmbuildCommand = rpmbuildCommand.strip()
    scheduler.log(rpmbuildCommand)
    error, output = getstatusoutput(rpmbuildCommand)
    if error:
        if not exists(logfile):
            return "Error happened before any log output."
        logLines = open(logfile).readlines()
        return "Failed to build %s. Log file in %s. Final lines of the log file:\n%s" % (
            pkg.name, logfile, "".join(logLines[-20:]))
    if output:
        return output
    scheduler.log("Build successful.")

    # link the RPM from the unique name to the friendly name
    symlink(uniqueRpmFilename, finalRpmFilename)
    # link subpackages, if any
    for subpackage in pkg.subpackages:
        finalSubFilename = join(abspath("RPMS"), subpackage.rpmfilename)
        uniqueSubFilename = join(abspath("RPMS/cache/%s" % subpackage.checksum), subpackage.rpmfilename)
        symlink(uniqueSubFilename, finalSubFilename)


def installPackage(pkg, scheduler):
    if not checkCanInstallRpm(pkg):
        raise RpmBuildFailed(pkg)
    scheduler.log("Trying to install the rpm package %s just built." % pkg.pkgName())
    pkg_error = False
    if pkg.options.bootstrap:
        scheduler.log("Checking local path dependency for rpm package %s just build." % pkg.pkgName())
        rpm_env = rpmEnvironmentScript
        command = "%s ; rpm  -qp --requires %s | cut -d\  -f1" % (rpm_env, pkg.rpmLocation())
        error, output = getstatusoutput(command)
        if error: raise RpmBuildFailed(pkg)
        localPaths = [l for l in output.split("\n") if l.startswith(pkg.options.workDir)]
        if localPaths:
            scheduler.log("Error: Local path dependency found for %s\n  %s" % (pkg.pkgName(), "\n  ".join(localPaths)))
            pkg_error = True
        if pkg.options.checkPackageDeps:
            pkg_deps = ["system-base-import", pkg.rpmLocation()] + [p.pkgName() for p in pkg.dependencies]
            for p in rpm_db_cache:
                if '+bootstrap-bundle+' in p:
                    pkg_deps.append(p)
                    break
            all_provides = {}
            for dep_pkg in pkg_deps:
                provides_cachedir = join(pkg.options.workDir, pkg.options.tempDirPrefix, "cache")
                opt = "-q --provides"
                if dep_pkg == pkg.rpmLocation():
                    opt += " -p"
                    provides_cache = join(provides_cachedir, "provides-" + pkg.pkgName())
                else:
                    provides_cache = join(provides_cachedir, "provides-" + dep_pkg)
                cmd = "if [ ! -f %(provides_cache)s ] ; then %(rpm_env)s ; rpm %(opt)s %(dep_pkg)s > %(provides_cache)s ; fi ; cat %(provides_cache)s | cut -d\  -f1" % locals()
                e, o = getstatusoutput(cmd)
                for p in o.split("\n"): all_provides[p] = 1
            miss_deps = {}
            for d in output.split("\n"):
                if d.startswith("rpmlib(") or (d in pkg_deps): continue
                if not d in all_provides: miss_deps[d] = 1
            if miss_deps:
                scheduler.log("Error: Package %s requires '%s' while there is no direct dependency in spec file" % (
                    pkg.pkgName(), ",".join(sorted(miss_deps.keys()))))
                pkg_error = True
        if pkg_error and not pkg.options.ignoreCompileErrors: raise RpmBuildFailed(pkg)
    installRpm(pkg, pkg.options.bootstrap)
    scheduler.log("Done %s" % pkg.pkgName())
    f = open(join(pkg.options.workDir, pkg.pkgrel, ".package-checksum"), 'w')
    f.write(pkg.checksum)
    f.close()
    if pkg_error: raise RpmBuildFailed(pkg)
    scheduler.reschedule()


from time import sleep


class ActionFactory(object):
    def __init__(self, pkg):
        self.__package = pkg
        self.__actionList = []

    def create(self, cls, parent=None, prevAlternative=None):
        """ Creates an action of kind cls with the specified parent and/or
            alternatives.
        """
        obj = cls(self.__package, parent, prevAlternative)
        self.__lastCreated = obj
        self.__actionList.append(obj)
        return obj

    def createAlternative(self, cls, prevAlternative=None):
        """ Creates an alternative to prevAlternative action. By default
            prevAlternative is the last action created.
        """
        return self.create(cls, parent=None,
                           prevAlternative=(prevAlternative or self.__lastCreated))

    def createChild(self, cls, parent=None):
        """ Creates a child of the parent action. By default the parent is the
            last action created.
        """
        return self.create(cls, parent=(parent or self.__lastCreated),
                           prevAlternative=None)

    def getActionList(self):
        return self.__actionList


def createBuildActionLists(pkg):
    """ Builds the action tree depth first.
    """
    log("Creating actions for %s" % pkg.pkgName(), DEBUG)
    factory = ActionFactory(pkg)
    factory.create(BuildSystemCompiler)
    factory.createAlternative(InstallFromServer)
    if pkg.sources:
        factory.createAlternative(SourcesDownload)
        factory.createChild(BuildPackage)
    else:
        factory.createAlternative(BuildPackage)
    factory.createChild(LinkPackageFromCache)
    factory.createChild(InstallFromLocalArea)
    return factory.getActionList()


class BuildChecker(object):
    def __init__(self, pkg):
        """ This class is used to perform various checks on the build procedure
            and its outcome.
        """
        self.__packages = [pkg]
        self.__actions = []
        for package in self.__packages:
            self.__actions.extend(createBuildActionLists(package))
        for action in self.__actions:
            action.dryRun()

    def checkConsistency(self):
        def checkActionConsistency(action):
            actionName = action.actionName
            pkgName = action.pkg.pkgName()
            checkSentence = "Checking if possible action %(actionName)s %(pkgName)s behaves as expect..." % locals()
            willRun = action.dryRun()
            expectedResults = action.expectedResults()
            if willRun and not expectedResults:
                log(checkSentence + " NO!!! The following happened:")
                log(action.missingExecution())
                return False
            if not willRun and expectedResults:
                log(checkSentence + " NO!!! The following happened:")
                log(action.nonExpectedExecution())
                return False
            log(checkSentence + "YES! %s %s %s and %s" % (actionName, pkgName,
                                                          willRun and "should have run" or "should have not run",
                                                          expectedResults and "looks like it actually was." or "does not look like it was."),
                DEBUG)
            return True

        message = "Something wrong with action '%s' for package '%s'."
        errorMessage = "\n".join([message % (action.actionName, action.pkg.pkgName())
                                  for action in self.__actions
                                  if not checkActionConsistency(action)])
        if errorMessage:
            log(errorMessage)
            return False
        return True

    def checkIfUploadable(self):
        log("Checking for anything ready to upload.", DEBUG)
        result = False
        for action in self.__actions:
            if action.dryRun() and action.producesStuffToUpload():
                log("Action '%s' for package '%s' produces something to be uploaded." % (action.actionName,
                                                                                         action.pkg.pkgName()), DEBUG)
                result = result or True
        return result


# If a package is in apt cache, queue the action to install it.
# If a package is not found in cache, queue actions to download
# sources, build, and install the resulting package.
# Notice that in both cases the action completes successfully.
def checkPackageInCache(pkg, scheduler):
    pkgName = pkg.pkgName()
    scheduler.log("Starting to process package %s" % pkgName)
    sourcedir = pkg.sourcedir
    if not exists(sourcedir):
        log("Creating directory %s" % sourcedir, DEBUG)
        makedirs(sourcedir)
    # Check if it possible to install package and enqueue
    # serial task to do it.
    # FIXME: Clean up the fact queuing of tasks is actually
    #       a consequence of invoking scheduleInstallPackage.
    scheduled = scheduleInstallPackage(pkg, scheduler)
    if scheduled:
        scheduler.log("Package %s found in repository" % pkgName)
        scheduler.reschedule()
        return
    scheduler.log("Package %s not found in repository. Queuing for build." % pkgName)
    fetchDependencies = []
    if pkg.name.endswith("-patch"):
        baseTool = pkg.name[:-6]
        baseToolVersion = [d.version for d in getPackages(pkg.dependencies) if d.name == baseTool]
        if len(baseToolVersion) > 0:
            baseToolVersion = "cms+%s+%s" % (baseTool, baseToolVersion[0])
            if not rpm_db_cache.has_key(baseToolVersion): fetchDependencies = ["install-%s" % baseToolVersion]
    if pkg.options.pipPackage and [s for s in pkg.sources if s[:6] == "pip://"]:
        pip = [p.pkgName() for p in getPackages(pkg.fullDependencies) if p.name == pkg.options.pipPackage][0]
        if not rpm_db_cache.has_key(pip): fetchDependencies += ["install-" + pip]
    pkgSources = pkg.sources + pkg.patches
    if pkgSources:
        scheduler.parallel("fetch-%s" % pkgName, fetchDependencies, fetchSources, pkg, scheduler)
    buildActionDependencies = []
    for p in getPackages(list(set(pkg.origDependencies + pkg.origBuildDependencies))):
        if not isPackageInstalled(p):
            scheduler.serial("check-%s" % p.pkgName(), [], checkPackageInCache, p, scheduler)
            buildActionDependencies.append("install-%s" % p.pkgName())
    if pkgSources: buildActionDependencies.append("fetch-%s" % pkgName)
    installActionDependencies = ["build-%s" % pkgName]
    scheduler.log("Dependencies for %s: %s" % (pkgName, buildActionDependencies))
    scheduler.parallel("build-%s" % pkgName, buildActionDependencies, buildPackage, pkg, scheduler)
    scheduler.serial("install-%s" % pkgName, installActionDependencies, installPackage, pkg, scheduler)
    # Install sub-packages too if any
    subinstallActionDependencies = ["install-%s" % pkgName]
    for subpkg in pkg.subpackages:
        scheduler.serial("install-%s" % subpkg.pkgName(), subinstallActionDependencies, installPackage, subpkg,
                         scheduler)
    scheduler.reschedule()


# New version using the new scheduler.
def buildSpecs(topLevelPackages):
    from scheduler import Scheduler
    scheduler = Scheduler(topLevelPackages[0].options.workersPoolSize)
    for pkg in topLevelPackages:
        if not isPackageInstalled(pkg):
            scheduler.serial("check-%s" % pkg.pkgName(), [], checkPackageInCache, pkg, scheduler)

    # We create before hand since we know they are going to be needed. This
    # is to avoid having parallel threads creating them at the same time with
    # one of the two failing because the directory is already there.
    # FIXME: clean up the other places where these are created but only
    #        after we move to the new scheduler.
    for path in ["SOURCES/cache", "RPMS", "SRPMS", "BUILD", "SPECS", "BUILDROOT"]:
        d = join(pkg.options.workDir, path)
        if not exists(d):
            makedirs(d)

    scheduler.run()
    for (action, error) in scheduler.errors.iteritems():
        log("* The action \"%s\" was not completed successfully because %s" % (action, error))
    if scheduler.brokenJobs:
        sys.exit(1)


def build(opts, args, factory):
    err, out = getstatusoutput("%s ; rpm --version" % rpmEnvironmentScript)
    if err:
        fatal("unable to find a working rpm.")
    rpmCacheUpdate(opts)
    packages = [factory.createWithSpec(pkgName) for pkgName in args]
    for pkg in packages:
        logMessage = "Package %s requested." % pkg.pkgName()
        if not isDefaultRevision(pkg.pkgRevision):
            logMessage += " Forcing it at revision %s." % pkg.pkgRevision
        log(logMessage)
        if pkg.fullDependencies:
            log("This will bring in also the following packages: ")
            deps = sorted(pkg.fullDependencies)
            finalString = "\n".join(["%s (%s)" % (dep.pkgName(), dep.checksum)
                                     for dep in getPackages(deps)])
            log(finalString)

    if opts.specsOnly:
        log("SPECS files written")
        sys.exit(0)
    if opts.sources:
        for pkg in packages:
            log("Sources for %s are :" % pkg.name)
            for key, value in pkg.sourcesNumbers.iteritems():
                log("%s : %s" % (value, key))
        return
    if opts.pretend:
        log("Option --pretend specified. Not building.")
        return
    buildSpecs(packages)


def isPackageInstalled(pkg):
    if pkg.options.bootstrap:
        pkgName = pkg.pkgName()
        if rpm_db_cache.has_key(pkgName):
            if not isDefaultRevision(pkg.pkgRevision):
                if rpm_db_cache[pkgName][0] < pkg.pkgRevision:
                    return False
            log("Package %s with same/newer revision %s is already installed" % (
                pkgName, str(rpm_db_cache[pkgName][0])), DEBUG)
            return True
    else:
        instDir = join(pkg.options.workDir, pkg.pkgrel)
        if exists(join(instDir, ".package-checksum")):
            return True
    return False


class PlatformDetectionError(Exception):
    pass


# The helper method responsible for bootstrapping an area.
# @a opts the build options passed on command line.
# @return the location of the init.sh script to be sourced when building
#         or uploading.
def bootstrap(opts):
    useDev = ""
    if opts.useDev: useDev = "-dev"
    bootstrapUrl = "%s%s/file/%s/%s/%s" % (opts.server, useDev, opts.repository, opts.architecture, "bootstrap.sh")
    log("fetching %s" % bootstrapUrl, DEBUG)
    try:
        f = urlopen(bootstrapUrl)
        bootstrapContents = f.read()
    except:
        log(
            "Unable to fetch file %s. Mispelled architecture/repository name?\nNothing changed, aborting bootstrap." % bootstrapUrl)
        sys.exit(1)
    bootstrapFilename = join(opts.tempdir, "bootstrap.sh")
    bootstrapFile = open(bootstrapFilename, "w")
    bootstrapFile.write(bootstrapContents)
    bootstrapFile.close()

    log("Bootstrapping from server %s" % opts.server, DEBUG)
    bootstrapServer = opts.server.replace("http://", "").replace("https://", "").split("/", 1)[0]
    bootstrapServerPath = ""
    options = ["-server", bootstrapServer,
               bootstrapServerPath,
               "-arch", opts.architecture,
               "-path", opts.workDir,
               "-repository", opts.repository,
               "-assume-yes", "-only-once", useDev, "setup"]
    if logLevel is DEBUG:
        options.append("-debug")
    cmpkg = "%s/common/cmspkg -a %s" % (opts.workDir, opts.architecture)
    options.append("&& %s -f upgrade && %s -f update" % (cmpkg, cmpkg))
    bootstrapCommand = "TMPDIR=%s sh -ex %s %s" % (opts.tempdir, bootstrapFilename, " ".join(options))
    log("Bootstrapping cmsBuild area.")
    log(bootstrapCommand, DEBUG)
    error, output = getstatusoutput(bootstrapCommand)
    bootstrapLog = join(opts.tempdir, "bootstrap.log")
    f = open(bootstrapLog, "w")
    f.write(output)
    f.close()
    if error:
        log(output, DEBUG)
        fatal("unsuccessful bootstrap, log can be found in %s." % bootstrapLog)

    parts = glob(join(opts.workDir, opts.architecture, "external/rpm/*/etc/profile.d/init.sh"))
    if len(parts) != 1:
        fatal("""malformed bootstrap. More than one cmspkg installation found.""")

    initSh = parts[0]

    if not exists(initSh):
        fatal("""ERROR: cannot read cmspkg environment. File missing cmspkg/rpm env""")

    # If we are not in a cfg file write where to find the correct init.sh
    log("Done. Setup log can be found in %s." % bootstrapLog)
    log("rpm env file can be found in %s" % initSh, DEBUG)
    createDirs(architecture=opts.architecture, dest=opts.workDir)
    return initSh


def upload_help():
    log("""cmsBuild upload <package to upload>""")


def check(opts, args, factory):
    """ This method is responsible for checking that a given package was build
        and installed correctly.
    """
    pkgs = [factory.createWithSpec(specName) for specName in args]
    # expand subpackages to be checked
    pkgs = factory.expandSubpackages(pkgs)
    unconsistentPkgs = [pkg
                        for pkg in pkgs
                        if not BuildChecker(pkg).checkConsistency()]
    if unconsistentPkgs:
        log("Warning the following packages have errors:")
        log("\n".join([pkg.name for pkg in unconsistentPkgs]))
        sys.exit(1)
    log("Everything ok.")


def format(s, **kwds):
    return s % kwds


def statusAndLog(status, s, **kwds):
    log(s % kwds)
    return status


def executeScript(opts, dumpedScript, local=True):
    if local:
        executionCmd = "sh -e %(debug)s %(filename)s"
    else:
        executionCmd = "ssh < %(filename)s -p %(cmdPort)s %(cmdUser)s@%(cmdServer)s sh -e %(debug)s"
    # Run (or print-out) the script
    if not opts.pretend:
        fd, filename = mkstemp(".sh", "cmsBuildExecuted", opts.tempDirPrefix, True)
        f = os.fdopen(fd, "w")
    else:
        f = sys.stderr
    f.write(dumpedScript)
    f.close()
    if not opts.pretend:
        script = format(executionCmd,
                        debug=opts.debug and "-x" or "",
                        filename=filename,
                        cmdServer=opts.uploadServer,
                        cmdUser=opts.uploadUser,
                        cmdPort=opts.uploadPort)
        err, out = getstatusoutput(script)
    if opts.debug: log(out)
    return (err, out)


def allPackagesToUpload(args, factory):
    pkgs = [factory.createWithSpec(specName) for specName in args]
    if len(pkgs) != len(args):
        return statusAndLog(False, "ERROR: Error while parsing spec.")

    def allDeps(pkg, factory, dep_cache={}):
        if pkg in dep_cache: return dep_cache[pkg]
        deps = [pkg]
        for dep in getPackages(pkg.fullDependencies):
            for subdep in allDeps(dep, factory, dep_cache):
                if not subdep in deps: deps.append(subdep)
        dep_cache[pkg] = deps
        return deps

    fullPackageList = []
    dep_cache = {}
    for pkg in pkgs:
        for dep in allDeps(pkg, factory, dep_cache):
            if dep not in fullPackageList and exists(dep.rpmLocation()):
                fullPackageList.extend(factory.expandSubpackages([dep]))
    return fullPackageList


def deprecateLocalCommand(opts, fullPackageList):
    if not fullPackageList: return "true"
    deprecablePackages = " ".join([pkg.pkgName() for pkg in fullPackageList])
    deprecableRPMS = " ".join([p.rpmfilename for p in fullPackageList])
    deprecatedSrc = " ".join(["SOURCES/" + p.pkgdir for p in fullPackageList])
    deprecatedDir = " ".join([p.pkgrel for p in fullPackageList])
    deprecatedSRPM = " ".join(["SRPMS/cache/*/" + p.pkgName() + "*" for p in fullPackageList])
    deprecateLocal = format("%(rpmenv)s ; rpm -e %(deprecablePackages)s\n"
                            'cd %(workDir)s\n'
                            'rm -rf %(deprecatedDir)s\n'
                            "for x in %(deprecableRPMS)s; do\n"
                            '  [ -e RPMS/$x ] || continue\n'
                            '  realfile=`readlink RPMS/$x`\n'
                            '  rm -f RPMS/$x\n'
                            '  rm -f $realfile\n'
                            "done\n"
                            "for x in %(deprecatedSrc)s; do\n"
                            '  [ -d $x ] || continue\n'
                            "  for f in $x/*; do\n"
                            '    realfile=`readlink $f || true`\n'
                            '    [ "$realfile" ] || continue \n'
                            '    rm -f $realfile\n'
                            "  done\n"
                            '  rm -rf $x\n'
                            "done\n"
                            "rm -rf %(deprecatedSRPM)s\n",
                            rpmenv=rpmEnvironmentScript,
                            architecture=opts.architecture,
                            deprecableRPMS=deprecableRPMS,
                            deprecatedSrc=deprecatedSrc,
                            workDir=opts.workDir,
                            deprecatedDir=deprecatedDir,
                            deprecatedSRPM=deprecatedSRPM,
                            deprecablePackages=deprecablePackages)
    return deprecateLocal


def cleanup_server_upload(opts):
    global SERVER_TMP_UPLOAD_DIRECTORY
    if not SERVER_TMP_UPLOAD_DIRECTORY: return
    cleanupCmd = format("rm -rf %(tmpdir)s*", tmpdir=SERVER_TMP_UPLOAD_DIRECTORY)
    executeScript(opts, cleanupCmd, False)
    SERVER_TMP_UPLOAD_DIRECTORY = None


def upload(opts, args, factory):
    global SERVER_TMP_UPLOAD_DIRECTORY
    """New upload method. It uses the upload.sh server-side script for uploading
     https://github.com/cms-sw/cmspkg/blob/master/server/scripts/upload.sh"""

    if not args:
        upload_help()
        return False

    # A few helpers
    def getResult(s, k):
        return [x.replace(k, "") for x in s.split("\n") if x.startswith(k)][0]

    def logAndDieOnError(err, msg):
        if not err:
            return
        log(msg)
        cleanup_server_upload(opts)
        sys.exit(1)

    rpmCacheUpdate(opts)
    useDev = ""
    if opts.useDev: useDev = "-dev"
    cmspkg_upload_repo = opts.uploadTmpRepository if not opts.syncBack else ""
    migrateRepo = format(
        "/data/scripts%(useDev)s/upload.sh INIT '%(architecture)s' '%(repository)s' '%(cmspkg_upload_repo)s'",
        architecture=opts.architecture,
        repository=opts.repository,
        useDev=useDev,
        cmspkg_upload_repo=cmspkg_upload_repo)
    (err, uploadDir) = executeScript(opts, migrateRepo, False)
    logAndDieOnError(err, "Error while checking for parent repository and getting a temp area for upload.")

    uploadDir = getResult(uploadDir, "NEW_TEMP_REPOSITORY:")
    SERVER_TMP_UPLOAD_DIRECTORY = uploadDir

    # Once we have established the parent then we should update the apt/cmspkg and rpm cache
    tags_cache.update()
    rpmCacheUpdate(opts)
    fullPackageList = allPackagesToUpload(args, factory)
    if not fullPackageList:
        return statusAndLog(True, "Nothing needs to be uploaded")
    cmsplatf = fullPackageList[0].cmsplatf
    uploadablePackages = []
    for pkg in fullPackageList:
        checker = BuildChecker(pkg)
        if not checker.checkConsistency():
            statusAndLog(False, "ERROR: Build area not consistent. Not uploading.")
            executeScript(opts, deprecateLocalCommand(opts, fullPackageList))
            return False
        if not checker.checkIfUploadable():
            statusAndLog(True, "Nothing needs to be uploaded for %(name)s.",
                         name=pkg.pkgName())
            continue
        uploadablePackages.append(pkg)
    fullPackageList = uploadablePackages
    if not fullPackageList:
        return statusAndLog(True, "Nothing needs to be uploaded")
    fullUploadRepo = opts.repository if opts.syncBack else "%s.%s" % (opts.repository, opts.uploadTmpRepository)
    log("Ready to upload to %s." % fullUploadRepo)

    BootstrapPackage = ""
    CMSCommonPackage = ""
    BootstrapPackages = [pkg.pkgName() for pkg in fullPackageList if
                         pkg.pkgName().startswith("external+bootstrap-driver+")]
    CMSCommonPackages = [pkg.pkgName() for pkg in fullPackageList if pkg.pkgName().startswith("cms+cms-common+")]
    if BootstrapPackages: BootstrapPackage = "/".join(BootstrapPackages[0].split("+", 2))
    if CMSCommonPackage: CMSCommonPackage = "/".join(CMSCommonPackages[0].split("+", 2))

    packageNames = [pkg.pkgName() for pkg in fullPackageList]
    pkgChecksums = list(set([p.checksum for p in fullPackageList]))
    uploadSum = sha256("-".join(pkgChecksums)).hexdigest()
    tmpdir = join(opts.workDir, opts.tempDirPrefix, "upload")
    # Create an area locally which has to be merged with the remote repository.
    createEmptyRepository = format(
        "set -e\n"
        "rm -rf %(tmpdir)s\n"
        "mkdir -p %(tmpdir)s/%(uploadSum)s/RPMS\n",
        architecture=opts.architecture,
        tmpdir=tmpdir,
        uploadSum=uploadSum)
    # Hard-link packages.
    md5sum = "md5sum $r | awk '{print $1}'"
    if sys.platform == 'darwin': md5sum = "md5 -q $r"
    hardLinkPackages = format(
        "MD5CACHE=%(tmpdir)s/%(uploadSum)s/rpms.md5cache\n"
        "touch $MD5CACHE\n"
        "for h in %(includes)s ; do\n"
        "  hi=$(echo $h | sed 's|^\(..\).*|\\1|')\n"
        "  mkdir -p %(tmpdir)s/%(uploadSum)s/RPMS/$hi/$h\n"
        "  for r in $(find %(workdir)s/RPMS/cache/$h/%(architecture)s -name '*.rpm' -type f) ; do\n"
        "    ln $r %(tmpdir)s/%(uploadSum)s/RPMS/$hi/$h/$(echo $r | sed 's|.*/||')\n"
        "    echo $(basename $r)\" \"$(%(md5sum)s) >> $MD5CACHE\n"
        "  done\n"
        "done\n"
        "WEB_FILES=$(find %(workdir)s/WEB -type f | wc -l)\n"
        "if [ $WEB_FILES -gt 0 ] ; then\n"
        "  mkdir -p %(tmpdir)s/%(uploadSum)s/WEB\n"
        "  %(rsync)s -am --link-dest %(workdir)s/WEB/ %(workdir)s/WEB/ %(tmpdir)s/%(uploadSum)s/WEB/\n"
        "fi\n",
        rsync="rsync --chmod=a+rX",
        workdir=opts.workDir,
        tmpdir=tmpdir,
        includes=" ".join(pkgChecksums),
        architecture=opts.architecture,
        uploadSum=uploadSum,
        md5sum=md5sum)
    # Copy bootstrap-driver.txt, cmsos. Given we can rollback now
    # there is no risk of screwing up the repository by copying some unwanted
    # driver / cmsos.
    # FIXME: copy also some predefined web area, so that we have rollbackable web
    #        area?
    driverExt = "driver.txt"
    if (opts.repository == "comp") or (opts.repository.startswith("comp.")): driverExt = "driver-comp.txt"
    copyByProducts = format("echo Looking for local Bootstrap-driver\n"
                            "cd %(workdir)s/%(architecture)s\n"
                            "if [ 'X%(BootstrapPackage)s' != 'X' ] ; then\n"
                            "  mkdir -p %(tmpdir)s/%(uploadSum)s/drivers \n"
                            "  [ -f %(BootstrapPackage)s/%(architecture)s-%(driverExt)s ] && cp %(BootstrapPackage)s/%(architecture)s-%(driverExt)s %(tmpdir)s/%(uploadSum)s/drivers/%(architecture)s-driver.txt\n"
                            "fi\n"
                            "echo Looking for local cms common build\n"
                            "if [ 'X%(CMSCommonPackage)s' != 'X' ] ; then\n"
                            "  [ -f common/cmsos ] cp common/cmsos %(tmpdir)s/%(uploadSum)s\n"
                            "fi\n",
                            workdir=opts.workDir,
                            tmpdir=tmpdir,
                            architecture=opts.architecture,
                            uploadSum=uploadSum,
                            driverExt=driverExt,
                            BootstrapPackage=BootstrapPackage,
                            CMSCommonPackage=CMSCommonPackage)
    remoteSourceRE = re.compile(".*:.*/.*")
    sources = ""
    for pkg in [pkg for pkg in fullPackageList if exists(pkg.rpmLocation())]:
        # FIXME: this should really parse the url to determine the output filename
        #        rather than relying on the fact we always end up urls with
        #        /some-file.tar.gz
        sourceFiles = [(source.rsplit("/", 1)[1], getUrlChecksum(source))
                       for source in pkg.sources
                       if remoteSourceRE.match(source)]
        for filename, checksum in sourceFiles:
            checksum_in = checksum[0:2]
            if exists(join(opts.workDir, "SOURCES", "cache", checksum_in, checksum, ".no-cmsrep-upload")): continue
            sources += format(
                "SRC_DIR=%(tmpdir)s/%(uploadSum)s/SOURCES\n"
                "mkdir -p $SRC_DIR/cache/%(checksum_in)s/%(checksum)s\n"
                "mkdir -p $SRC_DIR/%(architecture)s/%(group)s/%(name)s/%(version)s\n"
                "ln -f %(workdir)s/SOURCES/cache/%(checksum_in)s/%(checksum)s/%(filename)s $SRC_DIR/cache/%(checksum_in)s/%(checksum)s/%(filename)s\n"
                "ln -sf ../../../../cache/%(checksum_in)s/%(checksum)s/%(filename)s $SRC_DIR/%(architecture)s/%(group)s/%(name)s/%(version)s/%(filename)s\n",
                workdir=opts.workDir,
                tmpdir=tmpdir,
                architecture=opts.architecture,
                group=pkg.group,
                name=pkg.name,
                version=pkg.version,
                filename=filename,
                uploadSum=uploadSum,
                checksum=checksum,
                checksum_in=checksum_in)

    (err, out) = executeScript(opts, "\n".join([createEmptyRepository, hardLinkPackages, copyByProducts, sources]))
    logAndDieOnError(err, "Error while creating the local repository.")

    repoInfo = {"uploadDir": uploadDir,
                "repository": opts.repository,
                "rsync": format("rsync -e 'ssh -p %(port)s' --rsync-path=/usr/bin/rsync --chmod=a+rX",
                                port=opts.uploadPort),
                "server": opts.uploadServer,
                "user": opts.uploadUser}

    upload = format(
        "%(rsync)s -a %(tmpdir)s/ %(user)s@%(server)s:%(uploadDir)s/upload/\n",
        tmpdir=tmpdir,
        **repoInfo)
    (err, msg) = executeScript(opts, upload, True)
    if err: logAndDieOnError(err, "Error while uploading to remote repository.")

    upload = format(
        "/data/scripts%(useDev)s/upload.sh CLONE '%(architecture)s' '%(repository)s' '%(cmspkg_upload_repo)s' '%(tmpUploadDir)s'\n",
        tmpdir=tmpdir,
        tmpUploadDir=basename(uploadDir),
        architecture=opts.architecture,
        cmspkg_upload_repo=cmspkg_upload_repo,
        useDev=useDev,
        **repoInfo)
    (err, msg) = executeScript(opts, upload, False)
    if err:
        if (err >> 8) != 19:
            log(
                "Parallel upload session succeded before us. Starting uploading procedure from scratch. This will check again build area consistency.")
        else:
            logAndDieOnError(err, "Error while uploading to remote repository.")
        return False
    log("Upload successfully finished to %s" % fullUploadRepo)
    return True


def remove_help():
    log("cmsBuild delete <package>")


allOk = lambda x, y: x and y
someOk = lambda x, y: x or y


def doDeprecateLocal(opts, args, factory):
    rpmCacheUpdate(opts)
    fullPackageList = allPackagesToUpload(args, factory)
    executeScript(opts, deprecateLocalCommand(opts, fullPackageList))


def getSpecRepository(url, options):
    destTmpDir = abspath(options.tempDirPrefix)
    destTgz = join(destTmpDir, "CMSDIST.tgz")
    destDir = abspath("CMSDIST")
    if exists(destTgz):
        unlink(destTgz)
    if "module=" not in url:
        url = url + "&module=" + DEFAULT_SPEC_REPOSITORY_MODULE
    if "strategy=" not in url:
        url = url + "&strategy=checkout"
    if "timestamp" not in url:
        url = url + "&timestamp=%s" % strftime("%Y%m%d%H%M%S")
    if "output=" not in url:
        url = url + "&output=/%s.tgz" % DEFAULT_SPEC_REPOSITORY_MODULE
    download(url, destTmpDir, options)
    command = "tar xzvf %(destTgz)s CMSDIST " % locals()
    message = "ERROR: Error while trying to download CMSDIST from a remote source:"
    ok = executeWithErrorCheck(command, message)
    if not ok:
        sys.exit(1)
    return destDir


def rpmCacheUpdate(opts, cache=None, rpm_env=None):
    if hasattr(opts, "bootstrap") and opts.bootstrap == True:
        if not rpm_env: rpm_env = rpmEnvironmentScript + "; "
        if cache is None: cache = rpm_db_cache
        cache.clear()
        rpmQueryCommand = "%s rpm -qa --queryformat '%%{NAME} %%{RELEASE} %%{SUMMARY}\n' | sed 's|CMS Experiment package SpecChecksum:||'" % rpm_env
        error, output = getstatusoutput(rpmQueryCommand)
        if error:
            die("Error while executing rpm -qa.\n%s" % output)
        for p in output.split("\n"):
            n, r, c = p.split(" ", 2)
            cache[n] = [r, c]
    return


def checkOptionsLocalSource(opts):
    """
    checks if opts.localSources is correct format `package:source=directory` and process it
    Could be made callback function in advancedBuildOptions.add_option
    """
    # check this option is given
    if opts.localSources is None:
        return  # opts.localSources is empty, return
    sourceOptionDict = {}
    for sourceOption in opts.localSources:
        # check if sourceOption in correct format
        if '=' not in sourceOption:
            fatal("ERROR: --source option is incorrectly given. Should be 'package:source=directory'.")
        pkg_and_source, source_path = sourceOption.split("=")
        pkg = source = None
        if ":" in pkg_and_source:
            pkg, source = pkg_and_source.split(":")
        else:
            pkg = pkg_and_source
            source = "Source"
        # check if given directory path is correct
        if not exists(source_path):
            fatal("The following path for package %s and source %s does not exist: %s" % (
                pkg, source, source_path))
        if not os.path.isdir(source_path) and not os.path.isfile(source_path):
            fatal("The given path for package %s and source %s is not a directory or a file: %s" % (
                pkg, source, source_path))
        # if it is an empty directory, fail
        if os.path.isdir(source_path) and len(os.listdir(source_path)) == 0:
            fatal("The following directory for package %s and source %s is empty: %s" % (
                pkg, source, source_path))
        # put extracted options to dictionary
        if pkg not in sourceOptionDict:
            sourceOptionDict[pkg] = {source: source_path}
        else:
            sourceOptionDict[pkg][source] = source_path

        # to solve inconsistent Source and Source0 naming in recipes
        if source is "Source":
            sourceOptionDict[pkg]["Source0"] = source_path
        elif source is "Source0":
            sourceOptionDict[pkg]["Source"] = source_path
        opts.localSources = sourceOptionDict


if __name__ == "__main__":
    # Stop processing if SCRAM runtime env is set to avoid picking up
    # python from cms external area
    if environ.has_key("SCRAMRT_SET"):
        fatal("You have SCRAM runtime environment set. Please run it from a fresh shell.")
    # Avoid locale related issues with gcc output.
    environ["LANG"] = "C"
    environ["_CMSBUILD_BUILD_ENV_"] = "1"
    opts, args = parseOptions()
    checkOptionsLocalSource(opts)

    packages = {}
    # tags_cache = TagCacheAptImpl (opts)
    try:
        # We only support three different workflows:
        #
        # * cmsBuild [--no-bootstrap] build <package> [<additional packages>]
        # * cmsBuild [--no-bootstrap] [--sync-back] upload <package> [<additional packages>]
        # * cmsBuild [--no-bootstrap] deprecate-local <package> [<additional packages>]
        #
        # where all workflows include a bootstrap step (unless --no-bootstrap) is
        # specified and upload implies building the same packages.
        commandSpec = []

        if opts.bootstrap:
            commandSpec.append("bootstrap")

        if not exists(abspath(opts.cmsdist)) and not "://" in opts.cmsdist:
            cmsdist = abspath(opts.cmsdist)
            fatal("Wrong path specified for CMSDIST: %s.\nNothing done." % cmsdist)

        if args[0] != "deprecate-local":
            commandSpec.append("build")

        if args[0] != "build":
            commandSpec.append(args[0])

        log("The following commands will be executed:\n %s" %
            "\n".join(["* %s" % spec for spec in commandSpec]), DEBUG)

        # Create the work area and a tmp dir for it it does not exists and cd to it.
        opts.tempdir = join(opts.workDir, opts.tempDirPrefix)
        getstatusoutput("rm -rf %s/cache; mkdir -p %s/{cache,specCache}" % (opts.tempdir, opts.tempdir))
        chdir(opts.workDir)
        CMSPKG_CMD = join(opts.workDir, "common", CMSPKG_CMD) + " --architecture %s" % opts.architecture

        # Process level lock: To make sure that there is only one cmsBuild process is running for this work area
        procLock = cmsLock(opts.workDir)
        if not procLock:
            fatal("There is already a cmsBuild process running for workdir %s." % opts.workDir)

        executeWithErrorCheck("rm -rf %s" % join(opts.workDir, opts.tempDirPrefix, "BUILDROOT"),
                              "Unable to remove BUILDROOT directory.")

        # Checkout if a tag is specified for CMSDIST. If it is checkout the package
        # in a temporary directory and keep track of the path to it.
        if "://" in opts.cmsdist:
            opts.cmsdist = getSpecRepository(opts.cmsdist, opts)

        # If cmsdist does not have opts.pipPackage then use system pip
        if opts.pipPackage and not exists(join(opts.cmsdist, opts.pipPackage + ".spec")):
            opts.pipPackage = None

        if not exists(opts.cmsdist):
            fatal("A CMSDIST checkout (or a tag) is required in order to build.")
        # Make sure that the build architecture and the actual platform we
        # are running on are compatible.
        if opts.architecture.startswith("osx"):
            if not sys.platform == "darwin":
                fatal("Cannot build architecture %s on linux. Did you mean %s?" % (
                    opts.architecture, opts.architecture.replace("osx106", "slc5")))
        if opts.architecture.startswith("slc"):
            if not sys.platform.startswith("linux"):
                fatal("Cannot build architecture %s on osx. Did you mean %s?" % (
                    opts.architecture, opts.architecture.replace("slc5", "osx106")))

        # Force the architecture and extract ancillary options like the compiler
        # version, the compiler name, whether to force 32 bit builds on linux and
        # whether the system compiler should being used.
        # Cross check that:
        # * If on macosx or in online, check that the system compiler has the same
        #   version as the one specified in the architecture string.
        # * If we are not using the system compiler, a spec file with the
        #   compiler name exists and matches the architecture.
        m = re.match("[^_]+_[^_]+_([a-z]+)([0-9]+)", opts.architecture)
        if not m:
            fatal("Malformed architecture string.")
        opts.compilerName, compactCompilerVersion = m.groups()
        opts.compilerVersion = ".".join([x for x in compactCompilerVersion])

        # Check validity of the system compiler.
        if opts.compilerName == "gcc" and sys.platform == "darwin":
            if detectCompilerVersion("gcc") == opts.compilerVersion:
                opts.systemCompiler = True
            else:
                opts.systemCompiler = False
        else:
            opts.systemCompiler = False

        # Check validity of the spec file.
        if not opts.systemCompiler:
            pathname = join(opts.cmsdist, "%s.spec" % opts.compilerName)
            try:
                lines = open(pathname).readlines()
            except IOError, e:
                fatal("The spec %s does not match the requested architecture %s." % (pathname, opts.architecture))
            (group, name, version) = parseRPMLine(lines, opts)
            version = version.split("-")[0]
            if name != opts.compilerName or version != opts.compilerVersion:
                msg = "The compiler %s-%s (specified in %s) differs from %s-%s (specified by the architecture %s)."
                fatal(msg % (name, version, pathname, opts.compilerName,
                             opts.compilerVersion, opts.architecture))

        arch_data = opts.architecture.split("_", 2)
        arch_data[2] = re.sub('^[a-z]+', '', arch_data[2])
        opts.rpmQueryDefines = '--define "cmscompilerv  %s" --define "cmsos %s"' % (
            arch_data[2], "_".join(arch_data[0:2]))
        environ["SCRAM_ARCH"] = opts.architecture
        environ["VO_CMS_SW_DIR"] = opts.workDir

        # Tags cache always needs to be there.
        tags_cache = TagCacheAptImpl(opts)
        successfulTransaction = False
        successfulBootstrapEnv = False
        while not successfulTransaction:
            successfulTransaction = True
            checksums_cache = {}
            PKGFactory = PackageFactory(opts)
            for command in commandSpec:
                if command == "bootstrap":
                    # If the apt-init.sh file is missing, do the bootstrap,
                    # parse the output to find the init.sh and link it to
                    # apt-init.sh, so that next time this stage will we skipped.
                    #
                    # Source the apt-init.sh file and setup the environment,
                    # update the apt cache.
                    rpmEnvironmentScript = join(opts.workDir, opts.architecture, "rpm-env.sh")
                    if not exists(rpmEnvironmentScript):
                        envSh = bootstrap(opts)
                        symlink(envSh.replace(opts.workDir + "/" + opts.architecture, "."), rpmEnvironmentScript)
                    rpmEnvironmentScript = "source " + rpmEnvironmentScript
                    tags_cache.update()
                    if opts.reference: check_reference(opts)
                elif command == "deprecate-local":
                    doDeprecateLocal(opts, args[1:], PKGFactory)
                elif command == "build":
                    build(opts, args[1:], PKGFactory)
                elif command == "upload":
                    # We continue trying unless some fatal error occurs (which exits
                    # immediately).  or the remote repository is not consistent with the
                    # current state.
                    successfulTransaction = upload(opts, args[1:], PKGFactory)
                    cleanup_server_upload(opts)
                    if not successfulTransaction:
                        log("Looks like repository changed while we were building. Trying again.")
    except KeyboardInterrupt:
        log("User requested to abort. Exiting.")
        sys.exit(1)
    except RpmBuildFailed, e:
        log("Package %s could not build. Final lines of the build log are: " % e.pkg.name)
        logfile = open("%s/log" % e.pkg.builddir).readlines()
        for line in logfile[-10:]:
            log(line)
        sys.exit(1)
    except RpmInstallFailed, e:
        log("The installation of %s could not be completed for the following reason:")
        log(e.why)
        sys.exit(1)
    except NotCorrectlyBootstrapped, e:
        log("""FATAL: While it seems that you have run bootstrap.sh, 
               the bootstrapped area actually looks broken for the following reason:""")
        log(e.why)
        sys.exit(1)
    except FileNotFound, e:
        log("""ERROR! File not found: %(filename)s""" % e.__dict__)
        sys.exit(1)
    except PlatformDetectionError, e:
        log("""ERROR: Unable to detect the architecture:""")
        log("%s" % e)
        sys.exit(1)
